{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d8d74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Functions import *\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numba import cuda\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28491062",
   "metadata": {},
   "source": [
    "## Display Frames in List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b58df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ThroughFrames(frames):\n",
    "    i = 0\n",
    "    while True:\n",
    "        cv2.imshow('Frame', frames[i])\n",
    "         # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i<0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i>(len(frames)-1):\n",
    "                i = len(frames)-1\n",
    "    # Release the video capture object\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e7447",
   "metadata": {},
   "source": [
    "##  Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b6a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Entropy(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the histogram of the grayscale image\n",
    "    hist, _ = np.histogram(gray_image, bins=256, range=(0, 256), density=True)\n",
    "    # Calculate the entropy\n",
    "    hist_entropy = entropy(hist, base=2)\n",
    "    return hist_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58163a1a",
   "metadata": {},
   "source": [
    "## Temporal Signal to Noise Ratio for Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c8fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def TSNR(image1, image2, image3):  \n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    frame_diff = cv2.absdiff(image1, image2)\n",
    "    mean_diff = np.mean(frame_diff)\n",
    "    std_diff = np.std(frame_diff)\n",
    "    tsnr = mean_diff / (std_diff + 1e-10)\n",
    "    return abs(1-tsnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026b809",
   "metadata": {},
   "source": [
    "## Absolute Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c901b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Abs_Dif(image1, image2, image3):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    frame_diff = cv2.absdiff(image1, image2)\n",
    "    tci = np.mean(frame_diff)\n",
    "    return tci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a7dcc2",
   "metadata": {},
   "source": [
    "## Optical Flow End Point Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3718306",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def OF_EPE(image1, image2, image3):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # EPE (End Point Error)\n",
    "    epe = np.linalg.norm(flow, axis=2).mean()\n",
    "    return epe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f81f08",
   "metadata": {},
   "source": [
    "## Oprical Flow Angular Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b8332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def OF_AE(image1, image2, image3):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # AE (Angular Error)\n",
    "    u, v = flow[:,:,0], flow[:,:,1]\n",
    "    magnitude, angle = cv2.cartToPolar(u, v)\n",
    "    ae = np.mean(angle)\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7b871",
   "metadata": {},
   "source": [
    "## Optical Flow Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def OF(img1, img2, img3):\n",
    "    # Check if images are the same size\n",
    "    if img1.shape != img2.shape or img2.shape != img3.shape:\n",
    "        raise ValueError(\"All images must be of the same size\")\n",
    "    # Apply Canny edge detection\n",
    "    edges1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    edges2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    edges3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute optical flow between the first and second images\n",
    "    flow1 = cv2.calcOpticalFlowFarneback(edges1, edges2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute optical flow between the second and third images\n",
    "    flow2 = cv2.calcOpticalFlowFarneback(edges2, edges3, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute the magnitude and angle of the optical flow vectors for both flows\n",
    "    magnitude1 = np.sqrt(flow1[..., 0]**2 + flow1[..., 1]**2)\n",
    "    angle1 = np.arctan2(flow1[..., 1], flow1[..., 0]) \n",
    "    magnitude2 = np.sqrt(flow2[..., 0]**2 + flow2[..., 1]**2)\n",
    "    angle2 = np.arctan2(flow2[..., 1], flow2[..., 0])\n",
    "    # Compute the difference between the two optical flows\n",
    "    magnitude_diff = np.abs(magnitude1 - magnitude2)\n",
    "    angle_diff = np.abs(angle1 - angle2)\n",
    "    # Normalize differences\n",
    "    magnitude_index = np.sum(magnitude_diff) / (magnitude1.size + 1e-6)  # Avoid division by zero\n",
    "    angle_index = np.sum(angle_diff) / (angle1.size + 1e-6)  # Avoid division by zero\n",
    "    # Combine magnitude and angle differences\n",
    "    difference_index = magnitude_index + angle_index\n",
    "    return difference_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9250a74",
   "metadata": {},
   "source": [
    "## Optical Flow Border Inconsistency Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def OF_B(img1, img2, img3):\n",
    "    # Check if images are the same size\n",
    "    if img1.shape != img2.shape or img2.shape != img3.shape:\n",
    "        raise ValueError(\"All images must be of the same size\")\n",
    "    # Apply Canny edge detection\n",
    "    edges1 = cv2.Canny(img1, 100, 200)\n",
    "    edges2 = cv2.Canny(img2, 100, 200)\n",
    "    edges3 = cv2.Canny(img3, 100, 200)\n",
    "    # Compute optical flow between the first and second images\n",
    "    flow1 = cv2.calcOpticalFlowFarneback(edges1, edges2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute optical flow between the second and third images\n",
    "    flow2 = cv2.calcOpticalFlowFarneback(edges2, edges3, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute the magnitude and angle of the optical flow vectors for both flows\n",
    "    magnitude1 = np.sqrt(flow1[..., 0]**2 + flow1[..., 1]**2)\n",
    "    angle1 = np.arctan2(flow1[..., 1], flow1[..., 0]) \n",
    "    magnitude2 = np.sqrt(flow2[..., 0]**2 + flow2[..., 1]**2)\n",
    "    angle2 = np.arctan2(flow2[..., 1], flow2[..., 0])\n",
    "    # Compute the difference between the two optical flows\n",
    "    magnitude_diff = np.abs(magnitude1 - magnitude2)\n",
    "    angle_diff = np.abs(angle1 - angle2)\n",
    "    # Normalize differences\n",
    "    magnitude_index = np.sum(magnitude_diff) / (magnitude1.size + 1e-6)  # Avoid division by zero\n",
    "    angle_index = np.sum(angle_diff) / (angle1.size + 1e-6)  # Avoid division by zero\n",
    "    # Combine magnitude and angle differences\n",
    "    difference_index = magnitude_index + angle_index\n",
    "    return difference_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a9c83",
   "metadata": {},
   "source": [
    "## Gray Scale Absolute Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c3c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Gray_Dif(image1, image2, image3):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92dd8db",
   "metadata": {},
   "source": [
    "## Temporal Structural Similarity Index Measure for Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c01063",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def TSSIM(image1, image2, image3):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    ssim_value = ssim(gray1, gray2,multichannel=True,win_size=3)\n",
    "    return abs(1-ssim_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef815a",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0f302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def MSE(image1, image2, image3):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    mse = np.mean((gray1 - gray2) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b05df1",
   "metadata": {},
   "source": [
    "## Border Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7c9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Border_Err(image1, image2, image3):\n",
    "    lower_threshold = 50\n",
    "    upper_threshold = 255\n",
    "    if len(image1.shape) > 1:\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    if len(image2.shape) > 1:\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Canny edge detection\n",
    "    canny1 = cv2.Canny(image1, lower_threshold, upper_threshold)\n",
    "    canny2 = cv2.Canny(image2, lower_threshold, upper_threshold)\n",
    "    # Calculate the absolute difference between the two Canny images\n",
    "    abs_diff = cv2.absdiff(canny1, canny2)\n",
    "    return np.mean(abs_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ee35c",
   "metadata": {},
   "source": [
    "## Color Range Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72335cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def CRC(image1, image2, image3):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    image1 = image1.astype(np.float64)\n",
    "    image2 = image2.astype(np.float64)\n",
    "    diff_r_min = abs(np.min(image1[:,:,2]) - np.min(image2[:,:,2]))  # Red channel min\n",
    "    diff_r_max = abs(np.max(image1[:,:,2]) - np.max(image2[:,:,2]))  # Red channel max\n",
    "    diff_g_min = abs(np.min(image1[:,:,1]) - np.min(image2[:,:,1]))  # Green channel min\n",
    "    diff_g_max = abs(np.max(image1[:,:,1]) - np.max(image2[:,:,1]))  # Green channel max\n",
    "    diff_b_min = abs(np.min(image1[:,:,0]) - np.min(image2[:,:,0]))  # Blue channel min\n",
    "    diff_b_max = abs(np.max(image1[:,:,0]) - np.max(image2[:,:,0]))  # Blue channel max\n",
    "    crci = (np.mean(diff_r_min) + np.mean(diff_r_max) + np.mean(diff_g_min) + np.mean(diff_g_max) + np.mean(diff_b_min) + np.mean(diff_b_max)) / 6\n",
    "    return crci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0507dc",
   "metadata": {},
   "source": [
    "## Entropy Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d195967",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Entropy_Dif(image1,image2, image3):\n",
    "    return abs(Entropy(image1)-Entropy(image2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53296afa",
   "metadata": {},
   "source": [
    "# Frequency Magnitude Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Freq_Dif(img1, img2, img3):\n",
    "    # Check if images are the same size\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Images must be of the same size\")\n",
    "    # Compute FFT\n",
    "    f1 = np.fft.fft2(img1)\n",
    "    f2 = np.fft.fft2(img2)\n",
    "    # Shift zero frequency component to the center\n",
    "    f1_shifted = np.fft.fftshift(f1)\n",
    "    f2_shifted = np.fft.fftshift(f2)\n",
    "    # Compute magnitude spectrum\n",
    "    magnitude1 = np.abs(f1_shifted)\n",
    "    magnitude2 = np.abs(f2_shifted)\n",
    "    # Compute the difference in magnitude spectra\n",
    "    magnitude_diff = np.abs(magnitude1 - magnitude2)\n",
    "    # Compute the difference index\n",
    "    difference_index = np.sum(magnitude_diff) / np.sum(magnitude1 + magnitude2)\n",
    "    return difference_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6fbb11",
   "metadata": {},
   "source": [
    "## Combined All Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f68cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combined_Metrics(image1, image2,op):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    tsnr = TSNR(image1,image2)\n",
    "    adif = Abs_Dif(image1,image2)\n",
    "    epe = OF_EPE(image1,image2)\n",
    "    ae = OF_AE(image1,image2)\n",
    "    gray = Gray_Dif(image1,image2)\n",
    "    ssim_value = TSSIM(image1,image2)\n",
    "    mse_value = MSE(image1,image2)\n",
    "    border_consistency_value = Border_Err(image1,image2)\n",
    "    crci_value = CRC(image1,image2)\n",
    "    ent = Entropy_Dif(image1,image2)\n",
    "    # Normalize and combine the metrics into a single consistency index\n",
    "    metrics = np.array([tsnr,adif, epe, ae, gray,ssim_value, mse_value, border_consistency_value, crci_value, ent])\n",
    "    normalized_metrics = (metrics - np.min(metrics)) / (np.max(metrics) - np.min(metrics))\n",
    "    combined_consistency_index = np.mean(normalized_metrics)\n",
    "    #print(metrics)\n",
    "    # Z-score normalization\n",
    "    mean = np.mean(metrics)\n",
    "    std = np.std(metrics)\n",
    "    Z_metrics = (metrics - mean) / std\n",
    "    \n",
    "    if op==\"norm\":\n",
    "        return combined_consistency_index\n",
    "    if op==\"mean\":\n",
    "        return np.mean(metrics)\n",
    "    if op==\"log\":\n",
    "        metrics[metrics <= 0] = 1e-10\n",
    "        return np.sum(np.log(metrics))\n",
    "    if op==\"Z\":\n",
    "        return np.mean(Z_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f548c0",
   "metadata": {},
   "source": [
    "## Mixed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18149c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Mix_Metrics(image1, image2,image3,op=\"mean\",M = [TSSIM,MSE],W=[1,1]):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    metrics = []\n",
    "    for i in range(len(M)):\n",
    "        #print(image1.shape,image2.shape)\n",
    "        metrics.append(W[i]*M[i](image1,image2,image3))\n",
    "    # Normalize and combine the metrics into a single consistency index\n",
    "    metrics = np.array(metrics)\n",
    "    normalized_metrics = (metrics - np.min(metrics)) / (np.max(metrics) - np.min(metrics))\n",
    "    combined_consistency_index = np.mean(normalized_metrics)\n",
    "    #print(metrics)\n",
    "    # Z-score normalization\n",
    "    mean = np.mean(metrics)\n",
    "    std = np.std(metrics)\n",
    "    Z_metrics = (metrics - mean) / std\n",
    "    \n",
    "    if op==\"norm\":\n",
    "        return combined_consistency_index\n",
    "    if op==\"mean\":\n",
    "        return np.mean(metrics)\n",
    "    if op==\"log\":\n",
    "        metrics[metrics <= 0] = 1e-10\n",
    "        return np.sum(np.log(metrics))\n",
    "    if op==\"Z\":\n",
    "        return np.mean(Z_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fdb0f4",
   "metadata": {},
   "source": [
    "## WIndowed Max Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "700e6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def WMax_Inconsistency(img1, img2, img3, wsize=(3,3), step=(3,3), Func=Combined_Metrics, op=\"mean\",M=[],Weights=[]):\n",
    "    kw,kh = wsize\n",
    "    H,W,_ = img1.shape\n",
    "    sw,sh = step\n",
    "    maxC = 0\n",
    "    maxR = [0,0,kw,kh]\n",
    "    # Calculate the output dimensions\n",
    "    output_height = (H - kh) // sh + 1\n",
    "    output_width = (W - kw) // sw + 1\n",
    "    # Initialize the output array\n",
    "    result = np.zeros((output_height, output_width))\n",
    "    # Perform the convolution\n",
    "    for i in range(0, output_height*sh, sh):\n",
    "        #print('Row: ',i,'/',output_height*sh,end='\\r')\n",
    "        for j in range(0, output_width*sw, sw):\n",
    "            # Extract the region of interest\n",
    "            region1 = img1[i:i + kh, j:j + kw]\n",
    "            region2 = img2[i:i + kh, j:j + kw]\n",
    "            region3 = img3[i:i + kh, j:j + kw]\n",
    "            # Perform element-wise multiplication and sum the result\n",
    "            if Func==Combined_Metrics or Func==Mix_Metrics:\n",
    "                if len(M)>0 and Func==Mix_Metrics:\n",
    "                    result[i // sh, j // sw] = Func(region1, region2, region3,op,M,Weights)\n",
    "                else:\n",
    "                    result[i // sh, j // sw] = Func(region1, region2,region3,op)\n",
    "            else:\n",
    "                result[i // sh, j // sw] = Func(region1, region2,region3)\n",
    "            if result[i//sh,j//sw]>=maxC:\n",
    "                maxR = [i,i+kh,j,j+kw] \n",
    "                maxC = result[i//sh,j//sw]\n",
    "            if (j+sw+kw)>W:\n",
    "                break\n",
    "        if (i+sh+kh)>H:\n",
    "            break\n",
    "    #print('')\n",
    "    return result,maxR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545f44b",
   "metadata": {},
   "source": [
    "## Video Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b431acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vid_consistency(F,Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    C = []\n",
    "    for i in range(len(F)-1):\n",
    "        if Func==Combined_Metrics or Func==Mix_Metrics:\n",
    "            if len(M)>0 and Func==Mix_Metrics:\n",
    "                C.append(Func(F[i],F[i+1],op,M,W))\n",
    "            else:\n",
    "                C.append(Func(F[i],F[i+1],op))\n",
    "        else:\n",
    "            C.append(Func(F[i],F[i+1]))\n",
    "    return np.mean(np.asarray(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427507a",
   "metadata": {},
   "source": [
    "## Windowd Video Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c0100c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vid_consistency_W(F,wsize=(3,3),step=(3,3),Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    C = []\n",
    "    for i in range(len(F)-1):\n",
    "        print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        Metrics,Region = WMax_Inconsistency(F[i],F[i+1],wsize,step,Func,op,W)\n",
    "        C.append(np.mean(Metrics))\n",
    "    return np.mean(np.asarray(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e4029",
   "metadata": {},
   "source": [
    "## Draw Window with Max Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a39d86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def DrawInconsistancy(F,wsize=(50,50),step=(50,50),Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    L = 3\n",
    "    DI = np.copy(F)\n",
    "    for i in range(len(F)-2):\n",
    "        print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        Metrics,Region = WMax_Inconsistency(F[i],F[i+1],F[i+2],wsize,step,Func,op,M,W)\n",
    "        #print((Region[0],Region[2]),(Region[1],Region[3]))\n",
    "        DI[i+1][Region[0]:Region[0]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[2]:Region[2]+L] = [0,255,0] \n",
    "        DI[i+1][Region[1]:Region[1]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[3]:Region[3]+L] = [0,255,0] \n",
    "        DI[i+1] = cv2.putText(DI[i+1],str(np.mean(Metrics)),(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.25,(0,0,255),1,cv2.LINE_AA) \n",
    "    return DI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c7848",
   "metadata": {},
   "source": [
    "## Draw Window with Max Inconsistency of Diffrent Window Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21d0d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@numba.jit\n",
    "def DrawInconsistancy1(F,Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    L = 3\n",
    "    DI = np.copy(F)\n",
    "    for i in range(len(F)-2):\n",
    "        print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        R = -1000\n",
    "        Region = [0,0,0,0]\n",
    "        for j in range(10,100,10):\n",
    "            Metrics,Reg= WMax_Inconsistency(F[i],F[i+1],F[i+2],(j,j),(j//2,j//2),Func,op,M,W)\n",
    "            if np.mean(Metrics)>R:\n",
    "                R = np.mean(Metrics)\n",
    "                Region = Reg\n",
    "        #print((Region[0],Region[2]),(Region[1],Region[3]))\n",
    "        \n",
    "        DI[i+1][Region[0]:Region[0]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[2]:Region[2]+L] = [0,255,0] \n",
    "        DI[i+1][Region[1]:Region[1]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[3]:Region[3]+L] = [0,255,0] \n",
    "        DI[i+1] = cv2.putText(DI[i+1],str(R),(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.25,(0,0,255),1,cv2.LINE_AA) \n",
    "    return DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1d709be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def InconsistentRegion(F,Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    L = 3\n",
    "    h,w,_ = F[0].shape\n",
    "    DI = [np.zeros((h,w)) for _ in F]\n",
    "    for i in range(len(F)-2):\n",
    "        #print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        R = -1000\n",
    "        Region = [0,0,0,0]\n",
    "        for j in range(20,100,20):\n",
    "            Metrics,Reg= WMax_Inconsistency(F[i],F[i+1],F[i+2],(j,j),(j//2,j//2),Func,op,M,W)\n",
    "            if np.mean(Metrics)>R:\n",
    "                R = np.mean(Metrics)\n",
    "                Region = Reg\n",
    "        #print((Region[0],Region[2]),(Region[1],Region[3]))\n",
    "        \n",
    "        DI[i+1][Region[0]:Region[1],Region[2]:Region[3]] = 255\n",
    "    return DI,R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a7d98",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51563922",
   "metadata": {},
   "source": [
    "F = read_images(\"saved_frames\")\n",
    "F[3] = F[3][:,:,:3]\n",
    "F[6] = F[6][:,:,:3]\n",
    "F[9] = F[9][:,:,:3]\n",
    "F[14] = F[14][:,:,:3]\n",
    "I = DrawInconsistancy(F[:13],(50,50),(10,10),Mix_Metrics,\"mean\",[CRC,Border_Err,Abs_Dif],[2,1.5,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03bfb1",
   "metadata": {},
   "source": [
    "ThroughFrames(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f061a08b",
   "metadata": {},
   "source": [
    "F = read_images(\"saved_frames\")\n",
    "F[3] = F[3][:,:,:3]\n",
    "F[6] = F[6][:,:,:3]\n",
    "F[9] = F[9][:,:,:3]\n",
    "F[14] = F[14][:,:,:3]\n",
    "I = DrawInconsistancy1(F[:13],Mix_Metrics,\"mean\",[CRC,Border_Err],[1.5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecba39",
   "metadata": {},
   "source": [
    "ThroughFrames(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2b54a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check which values with min mean consistency and which max mean consistency. Ex: 1-ssim\n",
    "#Weights of each metric\n",
    "#Which metrics are the best?\n",
    "#Look for change in entropy too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aba855b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscar origen del ruido\n",
    "#Checar si el ruido proviene desde el origen\n",
    "#Trabajar con fracuencias\n",
    "#DNN para cada tipo de error\n",
    "#Cambiar parametros de caricaturizacion por medio de DNN\n",
    "\n",
    "#Lista de parametros e indices para identificar cuales son los mejores valores\n",
    "#Algoritmos Geneticos\n",
    "#For x,y in zip(X,Y) \n",
    "\n",
    "#Para indices de inconsistencia y para caricaturizacion\n",
    "#CHecar con frames pasados (mean,var,etc) de cada parametro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae2f2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
