{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417a757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Functions import *\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numba import cuda\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda7dfe9",
   "metadata": {},
   "source": [
    "## Display Frames in List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b58db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ThroughFrames(frames):\n",
    "    i = 0\n",
    "    while True:\n",
    "        cv2.imshow('Frame', frames[i])\n",
    "         # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i<0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i>(len(frames)-1):\n",
    "                i = len(frames)-1\n",
    "    # Release the video capture object\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13ee614",
   "metadata": {},
   "source": [
    "##  Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8f3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Entropy(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the histogram of the grayscale image\n",
    "    hist, _ = np.histogram(gray_image, bins=256, range=(0, 256), density=True)\n",
    "    # Calculate the entropy\n",
    "    hist_entropy = entropy(hist, base=2)\n",
    "    return hist_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f82ec",
   "metadata": {},
   "source": [
    "## Temporal Signal to Noise Ratio for Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352e7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def TSNR(image1, image2):  \n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    frame_diff = cv2.absdiff(image1, image2)\n",
    "    mean_diff = np.mean(frame_diff)\n",
    "    std_diff = np.std(frame_diff)\n",
    "    tsnr = mean_diff / (std_diff + 1e-10)\n",
    "    return abs(1-tsnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708f0ad",
   "metadata": {},
   "source": [
    "## Absolute Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97259826",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Abs_Dif(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    frame_diff = cv2.absdiff(image1, image2)\n",
    "    tci = np.mean(frame_diff)\n",
    "    return tci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13970e6",
   "metadata": {},
   "source": [
    "## Optical Flow End Point Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808080b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def OF_EPE(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # EPE (End Point Error)\n",
    "    epe = np.linalg.norm(flow, axis=2).mean()\n",
    "    return epe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e7690",
   "metadata": {},
   "source": [
    "## Oprical Flow Angular Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f6558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def OF_AE(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # AE (Angular Error)\n",
    "    u, v = flow[:,:,0], flow[:,:,1]\n",
    "    magnitude, angle = cv2.cartToPolar(u, v)\n",
    "    ae = np.mean(angle)\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff927226",
   "metadata": {},
   "source": [
    "## Gray Scale Absolute Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d5e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Gray_Dif(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24963c06",
   "metadata": {},
   "source": [
    "## Temporal Structural Similarity Index Measure for Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede7da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def TSSIM(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    ssim_value = ssim(gray1, gray2,multichannel=True,win_size=3)\n",
    "    return abs(1-ssim_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04c7c8",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a8b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def MSE(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    mse = np.mean((gray1 - gray2) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac33844",
   "metadata": {},
   "source": [
    "## Border Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9afb767",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Border_Err(image1, image2):\n",
    "    lower_threshold = 50\n",
    "    upper_threshold = 255\n",
    "    if len(image1.shape) > 1:\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    if len(image2.shape) > 1:\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Canny edge detection\n",
    "    canny1 = cv2.Canny(image1, lower_threshold, upper_threshold)\n",
    "    canny2 = cv2.Canny(image2, lower_threshold, upper_threshold)\n",
    "    # Calculate the absolute difference between the two Canny images\n",
    "    abs_diff = cv2.absdiff(canny1, canny2)\n",
    "    return np.mean(abs_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e228a",
   "metadata": {},
   "source": [
    "## Color Range Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f54db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def CRC(image1, image2):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    image1 = image1.astype(np.float64)\n",
    "    image2 = image2.astype(np.float64)\n",
    "    diff_r_min = abs(np.min(image1[:,:,2]) - np.min(image2[:,:,2]))  # Red channel min\n",
    "    diff_r_max = abs(np.max(image1[:,:,2]) - np.max(image2[:,:,2]))  # Red channel max\n",
    "    diff_g_min = abs(np.min(image1[:,:,1]) - np.min(image2[:,:,1]))  # Green channel min\n",
    "    diff_g_max = abs(np.max(image1[:,:,1]) - np.max(image2[:,:,1]))  # Green channel max\n",
    "    diff_b_min = abs(np.min(image1[:,:,0]) - np.min(image2[:,:,0]))  # Blue channel min\n",
    "    diff_b_max = abs(np.max(image1[:,:,0]) - np.max(image2[:,:,0]))  # Blue channel max\n",
    "    crci = (np.mean(diff_r_min) + np.mean(diff_r_max) + np.mean(diff_g_min) + np.mean(diff_g_max) + np.mean(diff_b_min) + np.mean(diff_b_max)) / 6\n",
    "    return crci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee1691",
   "metadata": {},
   "source": [
    "## Entropy Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139800b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Entropy_Dif(image1,image2):\n",
    "    return abs(Entropy(image1)-Entropy(image2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2933256",
   "metadata": {},
   "source": [
    "# Frequency Magnitude Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83315125",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Freq_Dif(img1, img2):\n",
    "    # Check if images are the same size\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Images must be of the same size\")\n",
    "    # Compute FFT\n",
    "    f1 = np.fft.fft2(img1)\n",
    "    f2 = np.fft.fft2(img2)\n",
    "    # Shift zero frequency component to the center\n",
    "    f1_shifted = np.fft.fftshift(f1)\n",
    "    f2_shifted = np.fft.fftshift(f2)\n",
    "    # Compute magnitude spectrum\n",
    "    magnitude1 = np.abs(f1_shifted)\n",
    "    magnitude2 = np.abs(f2_shifted)\n",
    "    # Compute the difference in magnitude spectra\n",
    "    magnitude_diff = np.abs(magnitude1 - magnitude2)\n",
    "    # Compute the difference index\n",
    "    difference_index = np.sum(magnitude_diff) / np.sum(magnitude1 + magnitude2)\n",
    "    return difference_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373c766",
   "metadata": {},
   "source": [
    "## Combined All Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3156e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combined_Metrics(image1, image2,op):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    tsnr = TSNR(image1,image2)\n",
    "    adif = Abs_Dif(image1,image2)\n",
    "    epe = OF_EPE(image1,image2)\n",
    "    ae = OF_AE(image1,image2)\n",
    "    gray = Gray_Dif(image1,image2)\n",
    "    ssim_value = TSSIM(image1,image2)\n",
    "    mse_value = MSE(image1,image2)\n",
    "    border_consistency_value = Border_Err(image1,image2)\n",
    "    crci_value = CRC(image1,image2)\n",
    "    ent = Entropy_Dif(image1,image2)\n",
    "    # Normalize and combine the metrics into a single consistency index\n",
    "    metrics = np.array([tsnr,adif, epe, ae, gray,ssim_value, mse_value, border_consistency_value, crci_value, ent])\n",
    "    normalized_metrics = (metrics - np.min(metrics)) / (np.max(metrics) - np.min(metrics))\n",
    "    combined_consistency_index = np.mean(normalized_metrics)\n",
    "    #print(metrics)\n",
    "    # Z-score normalization\n",
    "    mean = np.mean(metrics)\n",
    "    std = np.std(metrics)\n",
    "    Z_metrics = (metrics - mean) / std\n",
    "    \n",
    "    if op==\"norm\":\n",
    "        return combined_consistency_index\n",
    "    if op==\"mean\":\n",
    "        return np.mean(metrics)\n",
    "    if op==\"log\":\n",
    "        metrics[metrics <= 0] = 1e-10\n",
    "        return np.sum(np.log(metrics))\n",
    "    if op==\"Z\":\n",
    "        return np.mean(Z_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01748e12",
   "metadata": {},
   "source": [
    "## Mixed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b371de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def Mix_Metrics(image1, image2,op=\"mean\",M = [TSSIM,MSE],W=[1,1]):\n",
    "    if image1 is None or image2 is None:\n",
    "        raise ValueError(\"One or both image paths are invalid\")\n",
    "    metrics = []\n",
    "    for i in range(len(M)):\n",
    "        #print(image1.shape,image2.shape)\n",
    "        metrics.append(W[i]*M[i](image1,image2))\n",
    "    # Normalize and combine the metrics into a single consistency index\n",
    "    metrics = np.array(metrics)\n",
    "    normalized_metrics = (metrics - np.min(metrics)) / (np.max(metrics) - np.min(metrics))\n",
    "    combined_consistency_index = np.mean(normalized_metrics)\n",
    "    #print(metrics)\n",
    "    # Z-score normalization\n",
    "    mean = np.mean(metrics)\n",
    "    std = np.std(metrics)\n",
    "    Z_metrics = (metrics - mean) / std\n",
    "    \n",
    "    if op==\"norm\":\n",
    "        return combined_consistency_index\n",
    "    if op==\"mean\":\n",
    "        return np.mean(metrics)\n",
    "    if op==\"log\":\n",
    "        metrics[metrics <= 0] = 1e-10\n",
    "        return np.sum(np.log(metrics))\n",
    "    if op==\"Z\":\n",
    "        return np.mean(Z_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da801a95",
   "metadata": {},
   "source": [
    "## WIndowed Max Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5832efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def WMax_Inconsistency(img1, img2, wsize=(3,3), step=(3,3), Func=Combined_Metrics, op=\"mean\",M=[],Weights=[]):\n",
    "    kw,kh = wsize\n",
    "    H,W,_ = img1.shape\n",
    "    sw,sh = step\n",
    "    maxC = 0\n",
    "    maxR = [0,0,kw,kh]\n",
    "    # Calculate the output dimensions\n",
    "    output_height = (H - kh) // sh + 1\n",
    "    output_width = (W - kw) // sw + 1\n",
    "    # Initialize the output array\n",
    "    result = np.zeros((output_height, output_width))\n",
    "    # Perform the convolution\n",
    "    for i in range(0, output_height*sh, sh):\n",
    "        #print('Row: ',i,'/',output_height*sh,end='\\r')\n",
    "        for j in range(0, output_width*sw, sw):\n",
    "            # Extract the region of interest\n",
    "            region1 = img1[i:i + kh, j:j + kw]\n",
    "            region2 = img2[i:i + kh, j:j + kw]\n",
    "            # Perform element-wise multiplication and sum the result\n",
    "            if Func==Combined_Metrics or Func==Mix_Metrics:\n",
    "                if len(M)>0 and Func==Mix_Metrics:\n",
    "                    result[i // sh, j // sw] = Func(region1, region2,op,M,Weights)\n",
    "                else:\n",
    "                    result[i // sh, j // sw] = Func(region1, region2,op)\n",
    "            else:\n",
    "                result[i // sh, j // sw] = Func(region1, region2)\n",
    "            if result[i//sh,j//sw]>=maxC:\n",
    "                maxR = [i,i+kh,j,j+kw] \n",
    "                maxC = result[i//sh,j//sw]\n",
    "            if (j+sw+kw)>W:\n",
    "                break\n",
    "        if (i+sh+kh)>H:\n",
    "            break\n",
    "    #print('')\n",
    "    return result,maxR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294338f",
   "metadata": {},
   "source": [
    "## Video Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfb53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vid_consistency(F,Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    C = []\n",
    "    for i in range(len(F)-1):\n",
    "        if Func==Combined_Metrics or Func==Mix_Metrics:\n",
    "            if len(M)>0 and Func==Mix_Metrics:\n",
    "                C.append(Func(F[i],F[i+1],op,M,W))\n",
    "            else:\n",
    "                C.append(Func(F[i],F[i+1],op))\n",
    "        else:\n",
    "            C.append(Func(F[i],F[i+1]))\n",
    "    return np.mean(np.asarray(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd30883",
   "metadata": {},
   "source": [
    "## Windowd Video Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a83f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vid_consistency_W(F,wsize=(3,3),step=(3,3),Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    C = []\n",
    "    for i in range(len(F)-1):\n",
    "        print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        Metrics,Region = WMax_Inconsistency(F[i],F[i+1],wsize,step,Func,op,W)\n",
    "        C.append(np.mean(Metrics))\n",
    "    return np.mean(np.asarray(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c1897",
   "metadata": {},
   "source": [
    "## Draw Window with Max Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb25dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def DrawInconsistancy(F,wsize=(50,50),step=(50,50),Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    L = 3\n",
    "    DI = np.copy(F)\n",
    "    for i in range(len(F)-1):\n",
    "        print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        Metrics,Region = WMax_Inconsistency(F[i],F[i+1],wsize,step,Func,op,M,W)\n",
    "        #print((Region[0],Region[2]),(Region[1],Region[3]))\n",
    "        DI[i+1][Region[0]:Region[0]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[2]:Region[2]+L] = [0,255,0] \n",
    "        DI[i+1][Region[1]:Region[1]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[3]:Region[3]+L] = [0,255,0] \n",
    "        DI[i+1] = cv2.putText(DI[i+1],str(np.mean(Metrics)),(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.25,(0,0,255),1,cv2.LINE_AA) \n",
    "    return DI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d5f8f",
   "metadata": {},
   "source": [
    "## Draw Window with Max Inconsistency of Diffrent Window Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c65c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def DrawInconsistancy1(F,Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    L = 3\n",
    "    DI = np.copy(F)\n",
    "    for i in range(len(F)-1):\n",
    "        print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        R = -1000\n",
    "        Region = [0,0,0,0]\n",
    "        for j in range(10,100,10):\n",
    "            Metrics,Reg= WMax_Inconsistency(F[i],F[i+1],(j,j),(j//2,j//2),Func,op,M,W)\n",
    "            if np.mean(Metrics)>R:\n",
    "                R = np.mean(Metrics)\n",
    "                Region = Reg\n",
    "        #print((Region[0],Region[2]),(Region[1],Region[3]))\n",
    "        \n",
    "        DI[i+1][Region[0]:Region[0]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[2]:Region[2]+L] = [0,255,0] \n",
    "        DI[i+1][Region[1]:Region[1]+L,Region[2]:Region[3]] = [0,255,0] \n",
    "        DI[i+1][Region[0]:Region[1],Region[3]:Region[3]+L] = [0,255,0] \n",
    "        DI[i+1] = cv2.putText(DI[i+1],str(R),(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.25,(0,0,255),1,cv2.LINE_AA) \n",
    "    return DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "422a4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def InconsistentRegion(F,Func=Combined_Metrics,op=\"mean\",M=[],W=[]):\n",
    "    L = 3\n",
    "    h,w,_ = F[0].shape\n",
    "    DI = [np.zeros((h,w)) for _ in F]\n",
    "    for i in range(len(F)-1):\n",
    "        #print('Frame: ',i+1,'/',len(F)-1,end='\\r')\n",
    "        R = -1000\n",
    "        Region = [0,0,0,0]\n",
    "        for j in range(10,100,10):\n",
    "            Metrics,Reg= WMax_Inconsistency(F[i],F[i+1],(j,j),(j//2,j//2),Func,op,M,W)\n",
    "            if np.mean(Metrics)>R:\n",
    "                R = np.mean(Metrics)\n",
    "                Region = Reg\n",
    "        #print((Region[0],Region[2]),(Region[1],Region[3]))\n",
    "        \n",
    "        DI[i+1][Region[0]:Region[1],Region[2]:Region[3]] = 255\n",
    "    return DI,R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824f1c1",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5843b",
   "metadata": {},
   "source": [
    "F = read_images(\"saved_frames\")\n",
    "F[3] = F[3][:,:,:3]\n",
    "F[6] = F[6][:,:,:3]\n",
    "F[9] = F[9][:,:,:3]\n",
    "F[14] = F[14][:,:,:3]\n",
    "I = DrawInconsistancy(F[:13],(50,50),(10,10),Mix_Metrics,\"mean\",[CRC,Border_Err,Abs_Dif],[2,1.5,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0bf171",
   "metadata": {},
   "source": [
    "ThroughFrames(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3322e05",
   "metadata": {},
   "source": [
    "F = read_images(\"saved_frames\")\n",
    "F[3] = F[3][:,:,:3]\n",
    "F[6] = F[6][:,:,:3]\n",
    "F[9] = F[9][:,:,:3]\n",
    "F[14] = F[14][:,:,:3]\n",
    "I = DrawInconsistancy1(F[:13],Mix_Metrics,\"mean\",[CRC,Border_Err],[1.5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf8bb6",
   "metadata": {},
   "source": [
    "ThroughFrames(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd75a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check which values with min mean consistency and which max mean consistency. Ex: 1-ssim\n",
    "#Weights of each metric\n",
    "#Which metrics are the best?\n",
    "#Look for change in entropy too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f244558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscar origen del ruido\n",
    "#Checar si el ruido proviene desde el origen\n",
    "#Trabajar con fracuencias\n",
    "#DNN para cada tipo de error\n",
    "#Cambiar parametros de caricaturizacion por medio de DNN\n",
    "\n",
    "#Lista de parametros e indices para identificar cuales son los mejores valores\n",
    "#Algoritmos Geneticos\n",
    "#For x,y in zip(X,Y) \n",
    "\n",
    "#Para indices de inconsistencia y para caricaturizacion\n",
    "#CHecar con frames pasados (mean,var,etc) de cada parametro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ac274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
