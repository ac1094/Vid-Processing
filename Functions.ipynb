{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a90f2a6",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30b531",
   "metadata": {},
   "source": [
    "Import libraries needed in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81663fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  #For image and video processing and visualization\n",
    "import os   #To interact with operating system and files\n",
    "import numpy as np  #For matrix operations\n",
    "import random   #To generate random numbers\n",
    "from sklearn.mixture import GaussianMixture  #For clustering\n",
    "from sklearn.cluster import DBSCAN   #For clustering\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth  #For clustering\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3c1e5",
   "metadata": {},
   "source": [
    "# Open Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ed5ca",
   "metadata": {},
   "source": [
    "This function recieves a video path and returns a capture stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0036d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_vid(input_file): #Video path\n",
    "    cap = cv2.VideoCapture(input_file) #Open capture stream\n",
    "    if not cap.isOpened(): #Check if is available\n",
    "        print(\"Error: Could not open video.\")\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547448a",
   "metadata": {},
   "source": [
    "# Get Video Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83147ee5",
   "metadata": {},
   "source": [
    "This function gets the video's properties for its width and height in pixels, frames per second (fps) and frame count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c94b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_props(cap, display=1): #Video capture stream and flag to display properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) #Get Width\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) #Get Height\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) #Get FPS\n",
    "    count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #Get Frame Count\n",
    "    if display==1:  #If flag is 1, display properties\n",
    "        print(\"Width: \",width)\n",
    "        print(\"Height: \",height)\n",
    "        print(\"FPS: \",fps)\n",
    "        print(\"Frame Count: \",count)\n",
    "    return width,height,fps,count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5208f82",
   "metadata": {},
   "source": [
    "# Get Frames from Video as a List "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d63ff",
   "metadata": {},
   "source": [
    "This function takes the capture stream of a video and saves its frames in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe13c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(cap): #Video capture stream\n",
    "    frames = [] #Frames list\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #Get Frame count\n",
    "    for i in range(frame_count): #For each frame\n",
    "        ret, frame = cap.read() # Read a frame from the video\n",
    "        if not ret: #If couldn't read frame\n",
    "            print(\"Error: Could not read frame.\") #Display error message and return read frames\n",
    "            return frames\n",
    "        frames.append(frame) # Save the frame to the list\n",
    "    if not frames: #If list is empty\n",
    "        print(\"No frames were saved.\") #Display error message \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6fb9a",
   "metadata": {},
   "source": [
    "# Delete PNG Files in Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c769c",
   "metadata": {},
   "source": [
    "This function deletes all PNG image files in the specified directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d705a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_png_files(directory_path): #Directory path to delete all PNG files\n",
    "    for filename in os.listdir(directory_path): # List all files in the specified directory\n",
    "        file_path = os.path.join(directory_path, filename) # Construct full file path\n",
    "        try:\n",
    "            if os.path.isfile(file_path) and filename.lower().endswith('.png'): # Check if it's a PNG file and remove it\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')  #If not, display message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f423c3a",
   "metadata": {},
   "source": [
    "# Save Frames as Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba9058",
   "metadata": {},
   "source": [
    "This function saves a list of frames as images in the given directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da08eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(frames, frame_folder): #Frame list, directory path to be saved\n",
    "    if not os.path.exists(frame_folder):  # Create the folder to save frames if it doesn't exist\n",
    "        os.makedirs(frame_folder)\n",
    "    frame_count = 0 #frame index\n",
    "    for i in range(len(frames)): #for each frame\n",
    "        frame_filename = os.path.join(frame_folder, f'frame_{frame_count:03d}.png') #directory path and file name\n",
    "        cv2.imwrite(frame_filename, frames[i]) # Save the frame as an image file\n",
    "        frame_count += 1 #Next frame index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74531fa6",
   "metadata": {},
   "source": [
    "# Read Images in a Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f2666",
   "metadata": {},
   "source": [
    "This function reads and stores images from a given directory path to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "650619a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(directory_path):\n",
    "    images = []\n",
    "    # List all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the file has a PNG extension\n",
    "        if filename.lower().endswith('.png'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Read the image using OpenCV\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)  # cv2.IMREAD_UNCHANGED to keep the alpha channel if present\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "            else:\n",
    "                print(f\"Failed to read image: {file_path}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a2304",
   "metadata": {},
   "source": [
    "# Create Video with List of Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2690cbf5",
   "metadata": {},
   "source": [
    "This function creates and saves the frames in a list into a video file in the specified directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1906ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vid(frames,output_file,fps): #List of frames, directory path to be saved, fps\n",
    "    height, width, _ = frames[0].shape     # Get frame dimensions\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Define the codec and create VideoWriter object\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (width, height)) \n",
    "    [out.write(frame) for frame in frames]; # Write the frames to the new video file\n",
    "    out.release() # Release the video writer object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c8db8",
   "metadata": {},
   "source": [
    "# Display Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc262dc4",
   "metadata": {},
   "source": [
    "This function displays a given image in a window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2a878ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(I): #Image to display\n",
    "    cv2.imshow('I', I)  #Display Image\n",
    "    cv2.waitKey(0) #Press any key to stop displaying\n",
    "    cv2.destroyAllWindows() #Close all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1f35a",
   "metadata": {},
   "source": [
    "This function display a list of images at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a80450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images):\n",
    "    for i, img in enumerate(images):\n",
    "        window_name = f'Image {i+1}'\n",
    "        cv2.imshow(window_name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9fbe7",
   "metadata": {},
   "source": [
    "# Play Frames in a Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a090ca",
   "metadata": {},
   "source": [
    "This function displays a video made out of a list of frames with the specified FPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f79fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_frames(frames,fps): #list of frames, fps\n",
    "    delay = int(1000/fps) #Delay between frames\n",
    "    print(\"Delay: \",delay)\n",
    "    for frame in frames:\n",
    "        cv2.imshow('Video Playback', frame) # Display the frame\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'): # Exit the playback if 'q' is pressed\n",
    "            break\n",
    "    cv2.destroyAllWindows() #Close all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166150b7",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c7d80a",
   "metadata": {},
   "source": [
    "Optical Flow can be seen as a vector field that describes the movement between two consecutive images or frames in a video. There are many ways to calculate the oprical flow. Some of the methods to solve optical flow are:\n",
    "- Ferneback\n",
    "- Lucas - Kanade\n",
    "- Phase Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f247187",
   "metadata": {},
   "source": [
    "## Farneback Magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be9997",
   "metadata": {},
   "source": [
    "This function take a list of frames to return a list of the optical flow's vector fields and display the magnitude of these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a7bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFM(frames): #List of frames\n",
    "    OF = []  #List of optical flow's vector field\n",
    "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY) #Convert to Grayscale\n",
    "    i = 0  #frame's index\n",
    "    while True:\n",
    "        print(i,end='\\r') #Print frame index\n",
    "        next_gray=cv2.cvtColor(frames[(i+1)%len(frames)],cv2.COLOR_BGR2GRAY)#Convert current & next frame to grayscale\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 10, 10, 5, 1.2, 0)\n",
    "                                            # prev     next      flow  dist lvl win it smooth std  flag\n",
    "        # Visualize the optical flow\n",
    "        hsv = np.zeros_like(frames[i]) #Matrix with shape like frames with zeros\n",
    "        if len(hsv.shape) != 3 or hsv.shape[2] != 3: #If color image\n",
    "            hsv = np.zeros((frames[i].shape[0], frames[i].shape[1], 3)) #Matrix of size of frame with 3 color channels\n",
    "        hsv[..., 1] = 255 # ch1 Saturation (Full)\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1]) # Cartesian to Polar\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2  #Angle\n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX) #Normalize from 0 to 255\n",
    "        flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)   #Convert to RGB\n",
    "        OF.append(flow) #Add to list of Optical Flow\n",
    "        flow_M  = flow[...,0] + flow[...,1] #Add components of vectors\n",
    "        flow_M = flow_M/np.max(flow_M)*255 #Calculate Magnitude of vectors     \n",
    "        # Display the original frames and the optical flow magnitudes\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[(i+1) % len(frames)])\n",
    "        cv2.imshow('Optical Flow', flow_rgb)\n",
    "        cv2.imshow('Optical Flow Mag', flow_M)\n",
    "        # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key to move backwards\n",
    "            i = i - 1\n",
    "            if i<0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key to move forwards\n",
    "            i = i + 1\n",
    "            if i>(len(frames)-1):\n",
    "                i = len(frames)-1\n",
    "        prev_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY) # Update the previous frame and grayscale image\n",
    "    cv2.destroyAllWindows() # Release the video capture object and close all OpenCV windows\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a83be",
   "metadata": {},
   "source": [
    "## Draw Optical Flow Vector Field and Sum of all Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847ec84",
   "metadata": {},
   "source": [
    "These functions recieve the optical flow and the frame to draw onto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25913a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_optical_flow_vectors(flow, frame, step): #Optical flow, frame, window size\n",
    "    h, w = frame.shape[:2] #frame size\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int) #Grid of window centers\n",
    "    fx, fy = flow[y, x].T #Separate flow components\n",
    "    mask = np.zeros_like(frame) # Create a mask to draw the vectors  \n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2) # Create line endpoints\n",
    "    lines = np.int32(lines + 0.5) # Add space between\n",
    "    # Draw lines and circles for each vector\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.line(mask, (x2, y2), (x1, y1), (0, 255, 0), 1)\n",
    "        cv2.circle(frame, (x2, y2), 1, (0, 255, 0), -1)\n",
    "    return cv2.add(frame, mask) #Draw mask on top of frame\n",
    "\n",
    "def draw_sum_vector(flow, frame):\n",
    "    h, w = frame.shape[:2] #Frame size\n",
    "    # Compute the sum of all flow vectors by components\n",
    "    sum_fx = np.sum(flow[..., 0])\n",
    "    sum_fy = np.sum(flow[..., 1])\n",
    "    center_x, center_y = w // 2, h // 2 # Calculate the center point of the frame\n",
    "    # Normalize the sum vector to fit within the image\n",
    "    max_length = min(w, h) // 2\n",
    "    vector_length = np.sqrt(sum_fx**2 + sum_fy**2)\n",
    "    if vector_length > 0:\n",
    "        scale = max_length / vector_length #scale factor\n",
    "        end_x = int(center_x + sum_fx * scale)\n",
    "        end_y = int(center_y + sum_fy * scale)\n",
    "    else:\n",
    "        end_x, end_y = center_x, center_y\n",
    "    # Draw the sum vector as a red arrow\n",
    "    frame_with_vector = np.copy(frame) #copy original frame\n",
    "    cv2.arrowedLine(frame_with_vector, (center_x, center_y), (end_x, end_y), (0, 0, 255), 2, tipLength=0.2) \n",
    "    return frame_with_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6751e",
   "metadata": {},
   "source": [
    "## Farneack with Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb1dcb",
   "metadata": {},
   "source": [
    "The function OFV take a list of frames to return and display the optical flow's vector fields as well as the sum of all vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d97a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFV(frames, step=15): #Frame list, window size\n",
    "    OF = [] #List of Optical flow's vector fields\n",
    "    i = 0 #Frame's index\n",
    "    while True:\n",
    "        #convert it to grayscale\n",
    "        prev_gray = cv2.cvtColor(np.copy(frames[i]), cv2.COLOR_BGR2GRAY)\n",
    "        next_gray = cv2.cvtColor(np.copy(frames[i+1]), cv2.COLOR_BGR2GRAY)\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        # Draw the optical flow vectors on the frame\n",
    "        flow_frame = draw_optical_flow_vectors(flow, cv2.addWeighted(frames[i], 0.5, frames[i+1], 0.5, 0), step)\n",
    "        OF.append(flow) #Add flow to list\n",
    "        # Draw the sum vector on the frame\n",
    "        frame_with_sum_vector = draw_sum_vector(flow, flow_frame)\n",
    "        # Display the original frame with optical flow vectors and sum vector\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        #cv2.imshow('Optical Flow Vectors', flow_frame)\n",
    "        cv2.imshow('Sum Vector', frame_with_sum_vector)\n",
    "        key = cv2.waitKeyEx(0) #Read pressed key\n",
    "        if key == ord('q'): #Stop if pressed\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key for previous frames\n",
    "            i = i - 1\n",
    "            if i < 0: #prevent non existent frames\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key for next frames\n",
    "            i = i + 1\n",
    "            if i > (len(frames) - 2): #prevent non existent frames\n",
    "                i = len(frames) - 2\n",
    "    cv2.destroyAllWindows() #Close all windows\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9689d16b",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b909d5d",
   "metadata": {},
   "source": [
    "This function utilizes the Lukas-Kanade method to solve and display the optical flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e6cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFLK(frames, step_size=15): #Video Frames, window size\n",
    "    OF = [] #List of optical flow\n",
    "    lk_params=dict(winSize=(step_size,step_size),maxLevel=10,criteria=(cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_COUNT,30,0.01))\n",
    "    #lucas-kanade parameters  #window Size        #PyramidLevel   #End Criteria\n",
    "    i = 0 #Frame index\n",
    "    while i < len(frames) - 1:\n",
    "        #Convert to Grayscale\n",
    "        old_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY) \n",
    "        frame_gray = cv2.cvtColor(frames[i + 1], cv2.COLOR_BGR2GRAY)\n",
    "        #Neighborhood grid centers\n",
    "        grid_y, grid_x = np.mgrid[step_size//2:old_gray.shape[0]:step_size, step_size//2:old_gray.shape[1]:step_size]\n",
    "        p0 = np.vstack((grid_x.ravel(), grid_y.ravel())).T.astype(np.float32).reshape(-1, 1, 2)\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) #Calculate Optical Flow\n",
    "        #Set to 1 if change has been found\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "        #Frames average\n",
    "        frame = cv2.addWeighted(frames[i], 0.5, frames[i + 1], 0.5, 0)\n",
    "        #Calculate Vector Field\n",
    "        flow = np.zeros((old_gray.shape[0], old_gray.shape[1], 2))\n",
    "        flow[good_old[:, 1].astype(int), good_old[:, 0].astype(int), 0] = good_new[:, 0] - good_old[:, 0]\n",
    "        flow[good_old[:, 1].astype(int), good_old[:, 0].astype(int), 1] = good_new[:, 1] - good_old[:, 1]\n",
    "        #Draw Vectors\n",
    "        frame_with_vectors = draw_optical_flow_vectors(flow, frame, step_size)\n",
    "        frame_with_sum_vector = draw_sum_vector(flow, frame_with_vectors)\n",
    "        OF.append(flow) #add to flow list\n",
    "        #Display Frames and Flow\n",
    "        cv2.imshow('Previous Frame',frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        #cv2.imshow('Optical Flow Vectors', frame_with_vectors)\n",
    "        cv2.imshow('Sum Vector', frame_with_sum_vector)\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key to move backward\n",
    "            i = max(0, i - 1)\n",
    "        if key == 2555904:  # Right arrow key to move forward\n",
    "            i = min(len(frames) - 2, i + 1)\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81f12d",
   "metadata": {},
   "source": [
    "## Phase Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b0271",
   "metadata": {},
   "source": [
    "The PhaseC function calculates and displays the optical flow of the given frames by using Phase Correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f76f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sum_vector_phase_c(sum_dx, sum_dy, frame): #Y component, X component, frame to drawn on\n",
    "    h, w = frame.shape[:2] #Size\n",
    "    center_x, center_y = w // 2, h // 2 # Calculate the center point of the frame\n",
    "    # Normalize the sum vector to fit within the image\n",
    "    max_length = min(w, h) // 2\n",
    "    vector_length = np.sqrt(sum_dx**2 + sum_dy**2)\n",
    "    if vector_length > 0:\n",
    "        scale = 0.1#max_length / vector_length #Scale factor\n",
    "        end_x = int(center_x + sum_dx * scale)\n",
    "        end_y = int(center_y + sum_dy * scale)\n",
    "    else:\n",
    "        end_x, end_y = center_x, center_y\n",
    "    # Draw the sum vector as a red arrow\n",
    "    frame_with_vector = np.copy(frame)\n",
    "    cv2.arrowedLine(frame_with_vector, (center_x, center_y), (end_x, end_y), (0, 0, 255), 2, tipLength=0.2)\n",
    "    return frame_with_vector\n",
    "\n",
    "def PhaseC(frames, block_size=15, grid_step=15):\n",
    "    OF = [] #Optical Flow List\n",
    "    i = 0 #Frame index\n",
    "    while True:\n",
    "        prev_frame = np.copy(frames[i])\n",
    "        next_frame = np.copy(frames[i + 1])\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Create an image to visualize the flow\n",
    "        flow_img = cv2.cvtColor(prev_gray, cv2.COLOR_GRAY2BGR)\n",
    "        frame = cv2.addWeighted(frames[i], 0.5, frames[i+1], 0.5, 0)\n",
    "\n",
    "        sum_dx, sum_dy = 0, 0\n",
    "\n",
    "        # Iterate over the grid\n",
    "        for y in range(0, prev_gray.shape[0] - block_size, grid_step):\n",
    "            for x in range(0, prev_gray.shape[1] - block_size, grid_step):\n",
    "                # Extract the blocks\n",
    "                prev_block = prev_gray[y:y + block_size, x:x + block_size]\n",
    "                next_block = next_gray[y:y + block_size, x:x + block_size]\n",
    "\n",
    "                # Compute phase correlation\n",
    "                shift, _ = cv2.phaseCorrelate(prev_block.astype(np.float32), next_block.astype(np.float32))\n",
    "                dx, dy = shift\n",
    "\n",
    "                # Sum the vectors\n",
    "                sum_dx += dx\n",
    "                sum_dy += dy\n",
    "\n",
    "                # Scale down the length of the arrows and size of the tips\n",
    "                scale = 1\n",
    "                tip_length = 0.2\n",
    "\n",
    "                # Draw the vector on the flow image\n",
    "                cv2.arrowedLine(frame, (x + block_size // 2, y + block_size // 2),\n",
    "                                (int(x + block_size // 2 + dx * scale), int(y + block_size // 2 + dy * scale)),\n",
    "                                (0, 255, 0), 1, tipLength=tip_length)\n",
    "\n",
    "        # Draw the sum vector on the frame\n",
    "        frame_with_sum_vector = draw_sum_vector_phase_c(sum_dx, sum_dy, frame)\n",
    "\n",
    "        OF.append(flow_img)\n",
    "\n",
    "        # Display the frames and the flow\n",
    "        cv2.imshow('Previous Frame', prev_frame)\n",
    "        cv2.imshow('Next Frame', next_frame)\n",
    "        #cv2.imshow('Optical Flow', frame)\n",
    "        cv2.imshow('Sum Vector', frame_with_sum_vector)\n",
    "\n",
    "        # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i < 0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i > (len(frames) - 2):\n",
    "                i = len(frames) - 2\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a57432",
   "metadata": {},
   "source": [
    "# Real Time Optical Flow with Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d535606",
   "metadata": {},
   "source": [
    "This function captures video from a camera and displays it with the optical flow using Furneback's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76338ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_optical_flow(frame, flow, step=16, max_magnitude=100):\n",
    "    h, w = frame.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    vis = frame.copy()\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.arrowedLine(vis, (x1, y1), (x2, y2), (0, 255, 0), 1, tipLength=0.4)\n",
    "\n",
    "    # Compute the sum of all flow vectors\n",
    "    sum_fx = np.sum(fx)\n",
    "    sum_fy = np.sum(fy)\n",
    "    \n",
    "    # Normalize the sum vector\n",
    "    norm = np.sqrt(sum_fx**2 + sum_fy**2)\n",
    "    if norm > 0:\n",
    "        sum_fx /= norm\n",
    "        sum_fy /= norm\n",
    "\n",
    "    # Scale the normalized vector by the maximum magnitude\n",
    "    sum_fx *= min(norm, max_magnitude)\n",
    "    sum_fy *= min(norm, max_magnitude)\n",
    "    \n",
    "    # Draw the red vector representing the normalized sum of all flow vectors\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "    end_x = int(center_x + sum_fx)  # Scale for better visualization\n",
    "    end_y = int(center_y + sum_fy)\n",
    "    cv2.arrowedLine(vis, (center_x, center_y), (end_x, end_y), (0, 0, 255), 2, tipLength=0.4)\n",
    "    \n",
    "    return vis\n",
    "\n",
    "def cap_of():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read initial frame.\")\n",
    "        return\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, \n",
    "                                            0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        prev_gray = gray\n",
    "\n",
    "        # Draw the optical flow vectors on the RGB frame\n",
    "        optical_flow_frame = draw_optical_flow(frame, flow)\n",
    "        \n",
    "        # Display the resulting frame with optical flow\n",
    "        cv2.imshow('Webcam Video with Optical Flow', optical_flow_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7d3cf",
   "metadata": {},
   "source": [
    "# Frames Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf410e1",
   "metadata": {},
   "source": [
    "This function takes a list of frames of a video and calculates the absolute diffences between two consecutive frames with a threshold to display a binary image with the regions where the most differences are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d7e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_dif(frames, threshold=30): #List of frames, threshold\n",
    "    D = [] #Differences List\n",
    "    i = 0 #Frame index\n",
    "    while True:\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(np.copy(frames[i]),cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(np.copy(frames[i+1]), cv2.COLOR_BGR2GRAY)\n",
    "        # Compute absolute difference between frames\n",
    "        diff = cv2.absdiff(prev_gray, curr_gray) \n",
    "        # Create a mask to highlight pixels with significant changes\n",
    "        mask = np.zeros_like(diff)\n",
    "        mask[diff > threshold] = 255 #Apply Threshold\n",
    "        D.append(mask) #Add to list\n",
    "        # Show original frame and mask\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        cv2.imshow('Pixels with Most Changes', mask)\n",
    "         # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i<0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i>(len(frames)-2):\n",
    "                i = len(frames)-2\n",
    "        prev_frame = frames[i]\n",
    "    # Release the video capture object\n",
    "    cv2.destroyAllWindows()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec3ce3",
   "metadata": {},
   "source": [
    "This function takes a list of frames and calculates the normalized absolute difference between 2 consecutive frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_dif1(frames): #List of frames, threshold\n",
    "    D = [] #Differences List\n",
    "    i = 0 #Frame index\n",
    "    while True:\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(np.copy(frames[i]), cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(np.copy(frames[i+1]), cv2.COLOR_BGR2GRAY)\n",
    "        # Compute absolute difference between frames\n",
    "        diff = abs(prev_gray-curr_gray) #Absolute difference\n",
    "        dif = (1/diff.max())*diff*255 #Normalize\n",
    "        D.append(diff) #Add to list\n",
    "        # Show original frame and mask\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        cv2.imshow('Pixels with Most Changes', diff)\n",
    "         # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i<0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i>(len(frames)-2):\n",
    "                i = len(frames)-2\n",
    "        prev_frame = frames[i]\n",
    "    # Release the video capture object\n",
    "    cv2.destroyAllWindows()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601e7b9",
   "metadata": {},
   "source": [
    "# Alter Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1c16d",
   "metadata": {},
   "source": [
    "The next fucntions are used to alter the frames in a video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace157a",
   "metadata": {},
   "source": [
    "## Change Color Channel's Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56ee9f",
   "metadata": {},
   "source": [
    "This function changes the range of each individual color channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831a882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_range_colors(image, min_vals=(0, 0, 0), max_vals=(255, 255, 255)):\n",
    "    # Split the image into its BGR channels\n",
    "    b, g, r = cv2.split(image)\n",
    "    # Clip each channel to its respective range\n",
    "    b = np.clip(b, min_vals[0], max_vals[0])\n",
    "    g = np.clip(g, min_vals[1], max_vals[1])\n",
    "    r = np.clip(r, min_vals[2], max_vals[2])\n",
    "    # Merge the channels back together\n",
    "    new_image = cv2.merge((b, g, r))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679705a4",
   "metadata": {},
   "source": [
    "## Add Occlusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e5264",
   "metadata": {},
   "source": [
    "This function adds occlusions in the shape of rectangles and/or circles into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a829d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusions(image, num_occlusions=1,loc=[],sizes=[],shapes=['rectangle','circle'], colors=(-1,-1,-1)):    \n",
    "    output_image = np.copy(image) #Copy of frame\n",
    "    height, width = image.shape[:2] #Gets size\n",
    "    num_occlusions = num_occlusions if len(loc)==0 else len(loc) #number of occlusions\n",
    "    # Draw occlusions on the image\n",
    "    for i in range(num_occlusions):\n",
    "        shape_type = random.choice(shapes)\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) if colors==(-1,-1,-1) else colors  # Random color\n",
    "        if shape_type == 'rectangle':\n",
    "            x = random.randint(0, width - 1) if len(loc)==0 else loc[i][0]\n",
    "            y = random.randint(0, height - 1) if len(loc)==0 else loc[i][1]\n",
    "            width_rect = random.randint(5, width//2) if len(sizes)==0 else loc[i][0]\n",
    "            height_rect = random.randint(5, height//2) if len(sizes)==0 else loc[i][1]\n",
    "            cv2.rectangle(output_image, (x, y), (x + width_rect, y + height_rect), color, -1)  # Filled rectangle\n",
    "        elif shape_type == 'circle':\n",
    "            center = (random.randint(0, width - 1), random.randint(0, height - 1)) if len(loc)==0 else (loc[i][0],loc[i][1])\n",
    "            radius = 50#random.randint(5, 100)\n",
    "            cv2.circle(output_image, center, radius, color, -1)  # Filled circle\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bd0a5",
   "metadata": {},
   "source": [
    "## Draw Random Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842f3b8",
   "metadata": {},
   "source": [
    "This functions draws straight lines in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d95fe62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_lines(image, num_lines):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "    for _ in range(num_lines):\n",
    "        # Generate random start point\n",
    "        start_point = (random.randint(0, width-1), random.randint(0, height-1))\n",
    "        # Generate a random angle and length for the line\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "        length = random.randint(1, min(width, height) // 2)  # Limit length to half of the smallest dimension\n",
    "        # Calculate the end point using the angle and length\n",
    "        end_point = (int(start_point[0] + length * np.cos(angle)), \n",
    "                     int(start_point[1] + length * np.sin(angle)))\n",
    "        # Ensure the end point is within the image boundaries\n",
    "        end_point = (min(max(end_point[0], 0), width-1), min(max(end_point[1], 0), height-1))\n",
    "        # Generate a random color (BGR format)\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        # Generate a random thickness for the line\n",
    "        thickness = random.randint(1, 10)\n",
    "        # Draw the line on the image\n",
    "        cv2.line(output_image, start_point, end_point, color, thickness)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c369cd9",
   "metadata": {},
   "source": [
    "## Random Region's Color Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487861e",
   "metadata": {},
   "source": [
    "This function changes the color channel's range in a certain number of rectangle or ellipse regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e794f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_regions(image, num_regions):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "    for _ in range(num_regions):\n",
    "        # Generate random region shape and size\n",
    "        region_shape = random.choice(['rectangle', 'ellipse'])\n",
    "        if region_shape == 'rectangle':\n",
    "            region_width = random.randint(10, width // 3)\n",
    "            region_height = random.randint(10, height // 3)\n",
    "            top_left_x = random.randint(0, width - region_width)\n",
    "            top_left_y = random.randint(0, height - region_height)\n",
    "            # Define the region\n",
    "            region = output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width]\n",
    "        elif region_shape == 'ellipse':\n",
    "            center_x = random.randint(width // 3, width - width // 3)\n",
    "            center_y = random.randint(height // 3, height - height // 3)\n",
    "            axis_length = (random.randint(10, width // 3), random.randint(10, height // 3))\n",
    "            angle = random.randint(0, 360)\n",
    "            start_angle = 0\n",
    "            end_angle = 360\n",
    "            # Create a mask for the ellipse\n",
    "            mask = np.zeros((height, width), dtype=np.uint8)\n",
    "            cv2.ellipse(mask, (center_x, center_y), axis_length, angle, start_angle, end_angle, 255, -1)\n",
    "            # Extract the region using the mask\n",
    "            region = cv2.bitwise_and(output_image, output_image, mask=mask)\n",
    "        # Change color channels within the region\n",
    "        for channel in range(3):  # Assuming BGR format\n",
    "            # Generate random ranges for the color channel\n",
    "            low = random.randint(0, 255)\n",
    "            high = random.randint(low, 255)\n",
    "            if region_shape == 'rectangle':\n",
    "                region[..., channel] = np.clip(region[..., channel], low, high)\n",
    "            elif region_shape == 'ellipse':\n",
    "                # Apply changes to the region using the mask\n",
    "                channel_region = output_image[..., channel]\n",
    "                channel_region[mask == 255] = np.clip(channel_region[mask == 255], low, high)\n",
    "                output_image[..., channel] = channel_region\n",
    "        if region_shape == 'rectangle':\n",
    "            # Place the modified region back into the image for rectangles\n",
    "            output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width] = region\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c4388",
   "metadata": {},
   "source": [
    "# Simple Image Cartoonization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129817c8",
   "metadata": {},
   "source": [
    "The next functions are used to cartoonize an image pixel wise by using different algorithms and tecniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a066baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize_image(img, k=10, it = 10, t1 = 150, t2 = 255, ks = 1 , kc=1):\n",
    "    # Apply bilateral filter to smooth the image\n",
    "    img_color = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply Gaussian Blur\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (kc, kc), 0)\n",
    "    # Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(img_blur, threshold1=t1, threshold2=t2)\n",
    "    # Dilate the edges to make them more prominent\n",
    "    kernel = np.ones((ks, ks), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    # Invert the edges\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "    # Convert edges back to color, so we can combine with color image\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    # Perform K-means clustering\n",
    "    img_data = np.float32(img_color).reshape((-1, 3))\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, it, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(img_data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    img_clustered = centers[labels.flatten()]\n",
    "    img_clustered = img_clustered.reshape(img_color.shape)\n",
    "    # Combine edge and clustered image\n",
    "    cartoon = cv2.bitwise_and(img_clustered, edges_colored)\n",
    "    return cartoon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc107c0",
   "metadata": {},
   "source": [
    "# Image Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda7c0f1",
   "metadata": {},
   "source": [
    "The following functions calculate different variability indexes of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfedf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_luminance(image):\n",
    "    b, g, r = cv2.split(image)\n",
    "    luminance = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "    #return np.mean(luminance)\n",
    "    return luminance.sum()/(image.shape[0]*image.shape[1]*255)\n",
    "\n",
    "def color_variance(image):\n",
    "    variance_b = np.var(image[:, :, 0])\n",
    "    variance_g = np.var(image[:, :, 1])\n",
    "    variance_r = np.var(image[:, :, 2])\n",
    "    return ((variance_b+variance_g+variance_r)/3)/(image.shape[0]*image.shape[1])\n",
    "\n",
    "def calculate_variability(image,kernel_size=3):\n",
    "    kernel = np.ones((kernel_size,kernel_size))/(kernel_size**2-1)\n",
    "    kernel[kernel_size//2,kernel_size//2] = -1\n",
    "    V = cv2.filter2D(image,-1,kernel)\n",
    "    return abs(V).sum()/image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7470d79",
   "metadata": {},
   "source": [
    "# Color Limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c2887d",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Open the image with PIL\n",
    "img_pil = Image.open(\"therock.jpg\")\n",
    "\n",
    "# Convert PIL image to NumPy array (if needed for other processing)\n",
    "img_np = np.array(img_pil)\n",
    "\n",
    "# Quantize the image (convert to 16 colors)\n",
    "img_pil_quantized = img_pil.quantize(colors=20)\n",
    "\n",
    "# Convert quantized PIL image back to NumPy array\n",
    "img_quantized_np = np.array(img_pil_quantized)\n",
    "\n",
    "# Convert RGB to BGR (OpenCV uses BGR format)\n",
    "img_quantized_np_bgr = cv2.cvtColor(img_quantized_np, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d975b1",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Open the image with PIL\n",
    "#img_pil = Image.open(\"therock.jpg\")\n",
    "\n",
    "# Convert PIL image to NumPy array (if needed for other processing)\n",
    "img_np = np.array(img_pil)\n",
    "\n",
    "# Quantize the image (convert to 20 colors)\n",
    "img_pil_quantized = img_pil.quantize(colors=20)\n",
    "\n",
    "# Convert quantized PIL image back to NumPy array\n",
    "img_quantized_np = np.array(img_pil_quantized)\n",
    "\n",
    "# Convert RGB to BGR (OpenCV uses BGR format)\n",
    "img_quantized_np_bgr = cv2.cvtColor(img_quantized_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Add black lines to borders (5 pixels wide)\n",
    "border_thickness = 5\n",
    "img_with_border = cv2.copyMakeBorder(img_quantized_np_bgr, border_thickness, border_thickness, border_thickness, border_thickness, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cde322",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "\n",
    "palette = [\n",
    "    (0, 0, 0),   # Black\n",
    "    (255, 255, 255),  # White\n",
    "    (255, 0, 0),   # Red\n",
    "    (0, 255, 0),   # Green\n",
    "    (0, 0, 255),   # Blue\n",
    "    # Add more colors as needed\n",
    "]\n",
    "\n",
    "def apply_palette(img, palette):\n",
    "    img = img.convert(\"RGB\")\n",
    "    palette_img = Image.new(\"P\", (1, 1))\n",
    "    palette_img.putpalette(sum(palette, ()))\n",
    "    return img.quantize(palette=palette_img)\n",
    "\n",
    "img = Image.open(\"saitama.jpg\")\n",
    "img = apply_palette(img, palette)\n",
    "\n",
    "# Convert image back to RGB mode before saving\n",
    "img = img.convert(\"RGB\")\n",
    "\n",
    "# Save the image as JPEG\n",
    "img.save(\"palette_reduced_image.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba6fc04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0102fcee2350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mnumba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mAddInc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mInc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mBin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numba' is not defined"
     ]
    }
   ],
   "source": [
    "def AddInc(F):\n",
    "    Inc = []\n",
    "    Bin = [np.zeros(F[0].shape[:2],dtype=np.uint8) for _ in F]\n",
    "    for i in range(len(F)):\n",
    "        if i%3==0 and i!=0:\n",
    "            I = F[i].copy()\n",
    "            x,y = random.randint(0,2*I.shape[0]//3),random.randint(0,2*I.shape[1]//3)\n",
    "            l = random.randint(10,I.shape[1]//8)\n",
    "            Op = random.randint(0,2)\n",
    "            if Op==0:\n",
    "                I[x:x+l,y:y+l] = change_range_colors(I[x:x+l,y:y+l],(random.randint(30,140),random.randint(30,140),random.randint(30,140)),(random.randint(150,255),random.randint(150,255),random.randint(150,255)))\n",
    "                Bin[i][x:x+l,y:y+l]=255\n",
    "            elif Op==1:\n",
    "                R,G,B = random.randint(0,255),random.randint(0,255),random.randint(0,255)\n",
    "                I[x:x+l,y:y+l] = change_range_colors(I[x:x+l,y:y+l],(R,G,B),(R,G,B))\n",
    "                Bin[i][x:x+l,y:y+l]=255\n",
    "            elif Op==2:\n",
    "                Thick = random.randint(1,10)\n",
    "                l2 = random.randint(10,I.shape[1]//8)\n",
    "                I = cv2.line(I,(x,y),(x+l,y+l2),(random.randint(0,255),random.randint(0,255),random.randint(0,255)),Thick)\n",
    "                Bin[i] = cv2.line(Bin[i],(x,y),(x+l,y+l),255,Thick)\n",
    "            Inc.append(I)\n",
    "        else:\n",
    "            Inc.append(F[i])\n",
    "    return Inc,Bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ed436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
