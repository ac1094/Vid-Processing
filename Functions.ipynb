{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9287bf39",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02962c3f",
   "metadata": {},
   "source": [
    "Import libraries needed in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f0c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  #For image and video processing and visualization\n",
    "import os   #To interact with operating system and files\n",
    "import numpy as np  #For matrix operations\n",
    "import random   #To generate random numbers\n",
    "from sklearn.mixture import GaussianMixture  #For clustering\n",
    "from sklearn.cluster import DBSCAN   #For clustering\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth  #For clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0465610",
   "metadata": {},
   "source": [
    "# Open Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b97879",
   "metadata": {},
   "source": [
    "This function recieves a video path and returns a capture stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fb715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_vid(input_file): #Video path\n",
    "    cap = cv2.VideoCapture(input_file) #Open capture stream\n",
    "    if not cap.isOpened(): #Check if is available\n",
    "        print(\"Error: Could not open video.\")\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e45d40",
   "metadata": {},
   "source": [
    "# Get Video Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aec20a",
   "metadata": {},
   "source": [
    "This function gets the video's properties for its width and height in pixels, frames per second (fps) and frame count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ba8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_props(cap, display=1): #Video capture stream and flag to display properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) #Get Width\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) #Get Height\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) #Get FPS\n",
    "    count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #Get Frame Count\n",
    "    if display==1:  #If flag is 1, display properties\n",
    "        print(\"Width: \",width)\n",
    "        print(\"Height: \",height)\n",
    "        print(\"FPS: \",fps)\n",
    "        print(\"Frame Count: \",count)\n",
    "    return width,height,fps,count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3522b5d",
   "metadata": {},
   "source": [
    "# Get Frames from Video as a List "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52e3202",
   "metadata": {},
   "source": [
    "This function takes the capture stream of a video and saves its frames in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc28bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(cap): #Video capture stream\n",
    "    frames = [] #Frames list\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #Get Frame count\n",
    "    for i in range(frame_count): #For each frame\n",
    "        ret, frame = cap.read() # Read a frame from the video\n",
    "        if not ret: #If couldn't read frame\n",
    "            print(\"Error: Could not read frame.\") #Display error message and return read frames\n",
    "            return frames\n",
    "        frames.append(frame) # Save the frame to the list\n",
    "    if not frames: #If list is empty\n",
    "        print(\"No frames were saved.\") #Display error message \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd63d0",
   "metadata": {},
   "source": [
    "# Delete PNG Files in Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60544bb8",
   "metadata": {},
   "source": [
    "This function deletes all PNG image files in the specified directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9d3c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_png_files(directory_path): #Directory path to delete all PNG files\n",
    "    for filename in os.listdir(directory_path): # List all files in the specified directory\n",
    "        file_path = os.path.join(directory_path, filename) # Construct full file path\n",
    "        try:\n",
    "            if os.path.isfile(file_path) and filename.lower().endswith('.png'): # Check if it's a PNG file and remove it\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')  #If not, display message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a3e33",
   "metadata": {},
   "source": [
    "# Save Frames as Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38315602",
   "metadata": {},
   "source": [
    "This function saves a list of frames as images in the given directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8d62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(frames, frame_folder): #Frame list, directory path to be saved\n",
    "    if not os.path.exists(frame_folder):  # Create the folder to save frames if it doesn't exist\n",
    "        os.makedirs(frame_folder)\n",
    "    frame_count = 0 #frame index\n",
    "    for i in range(len(frames)): #for each frame\n",
    "        frame_filename = os.path.join(frame_folder, f'frame_{frame_count:03d}.png') #directory path and file name\n",
    "        cv2.imwrite(frame_filename, frames[i]) # Save the frame as an image file\n",
    "        frame_count += 1 #Next frame index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cccbff",
   "metadata": {},
   "source": [
    "# Create Video with List of Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452d421",
   "metadata": {},
   "source": [
    "This function creates and saves the frames in a list into a video file in the specified directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57f5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vid(frames,output_file,fps): #List of frames, directory path to be saved, fps\n",
    "    height, width, _ = frames[0].shape     # Get frame dimensions\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Define the codec and create VideoWriter object\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (width, height)) \n",
    "    [out.write(frame) for frame in frames]; # Write the frames to the new video file\n",
    "    out.release() # Release the video writer object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122348a9",
   "metadata": {},
   "source": [
    "# Display Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e3612",
   "metadata": {},
   "source": [
    "This function displays a given image in a window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49857eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(I): #Image to display\n",
    "    cv2.imshow('I', I)  #Display Image\n",
    "    cv2.waitKey(0) #Press any key to stop displaying\n",
    "    cv2.destroyAllWindows() #Close all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5f4df",
   "metadata": {},
   "source": [
    "# Play Frames in a Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b74cc",
   "metadata": {},
   "source": [
    "This function displays a video made out of a list of frames with the specified FPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa69818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_frames(frames,fps): #list of frames, fps\n",
    "    delay = int(1000/fps) #Delay between frames\n",
    "    print(\"Delay: \",delay)\n",
    "    for frame in frames:\n",
    "        cv2.imshow('Video Playback', frame) # Display the frame\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'): # Exit the playback if 'q' is pressed\n",
    "            break\n",
    "    cv2.destroyAllWindows() #Close all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27099b1d",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6688b04",
   "metadata": {},
   "source": [
    "Optical Flow can be seen as a vector field that describes the movement between two consecutive images or frames in a video. There are many ways to calculate the oprical flow. Some of the methods to solve optical flow are:\n",
    "- Ferneback\n",
    "- Lucas - Kanade\n",
    "- Phase Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b845f",
   "metadata": {},
   "source": [
    "## Farneback Magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6a96c",
   "metadata": {},
   "source": [
    "This function take a list of frames to return a list of the optical flow's vector fields and display the magnitude of these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1e5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFM(frames): #List of frames\n",
    "    OF = []  #List of optical flow's vector field\n",
    "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY) #Convert to Grayscale\n",
    "    i = 0  #frame's index\n",
    "    while True:\n",
    "        print(i,end='\\r') #Print frame index\n",
    "        next_gray=cv2.cvtColor(frames[(i+1)%len(frames)],cv2.COLOR_BGR2GRAY)#Convert current & next frame to grayscale\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 10, 10, 5, 1.2, 0)\n",
    "                                            # prev     next      flow  dist lvl win it smooth std  flag\n",
    "        # Visualize the optical flow\n",
    "        hsv = np.zeros_like(frames[i]) #Matrix with shape like frames with zeros\n",
    "        if len(hsv.shape) != 3 or hsv.shape[2] != 3: #If color image\n",
    "            hsv = np.zeros((frames[i].shape[0], frames[i].shape[1], 3)) #Matrix of size of frame with 3 color channels\n",
    "        hsv[..., 1] = 255 # ch1 Saturation (Full)\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1]) # Cartesian to Polar\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2  #Angle\n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX) #Normalize from 0 to 255\n",
    "        flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)   #Convert to RGB\n",
    "        OF.append(flow) #Add to list of Optical Flow\n",
    "        flow_M  = flow[...,0] + flow[...,1] #Add components of vectors\n",
    "        flow_M = flow_M/np.max(flow_M)*255 #Calculate Magnitude of vectors     \n",
    "        # Display the original frames and the optical flow magnitudes\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[(i+1) % len(frames)])\n",
    "        cv2.imshow('Optical Flow', flow_rgb)\n",
    "        cv2.imshow('Optical Flow Mag', flow_M)\n",
    "        # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i<0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i>(len(frames)-1):\n",
    "                i = len(frames)-1\n",
    "        prev_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY) # Update the previous frame and grayscale image\n",
    "    cv2.destroyAllWindows() # Release the video capture object and close all OpenCV windows\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98494ce3",
   "metadata": {},
   "source": [
    "## Farneack with Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bad20b",
   "metadata": {},
   "source": [
    "The function OFV take a list of frames to return and display the optical flow's vector fields as well as the sum of all vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abf61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_optical_flow_vectors(flow, frame, step): #Optical flow, frame, window size\n",
    "    h, w = frame.shape[:2] #frame size\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int) #Grid of window centers\n",
    "    fx, fy = flow[y, x].T #Separate flow components\n",
    "    mask = np.zeros_like(frame) # Create a mask to draw the vectors  \n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2) # Create line endpoints\n",
    "    lines = np.int32(lines + 0.5) # Add space between\n",
    "    # Draw lines and circles for each vector\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.line(mask, (x2, y2), (x1, y1), (0, 255, 0), 1)\n",
    "        cv2.circle(frame, (x2, y2), 1, (0, 255, 0), -1)\n",
    "    return cv2.add(frame, mask) #Draw mask on top of frame\n",
    "\n",
    "def draw_sum_vector(flow, frame):\n",
    "    h, w = frame.shape[:2] #Frame size\n",
    "    # Compute the sum of all flow vectors by components\n",
    "    sum_fx = np.sum(flow[..., 0])\n",
    "    sum_fy = np.sum(flow[..., 1])\n",
    "    center_x, center_y = w // 2, h // 2 # Calculate the center point of the frame\n",
    "    # Normalize the sum vector to fit within the image\n",
    "    max_length = min(w, h) // 2\n",
    "    vector_length = np.sqrt(sum_fx**2 + sum_fy**2)\n",
    "    if vector_length > 0:\n",
    "        scale = 0.001#max_length / vector_length #scale factor\n",
    "        end_x = int(center_x + sum_fx * scale)\n",
    "        end_y = int(center_y + sum_fy * scale)\n",
    "    else:\n",
    "        end_x, end_y = center_x, center_y\n",
    "    # Draw the sum vector as a red arrow\n",
    "    frame_with_vector = np.copy(frame) #copy original frame\n",
    "    cv2.arrowedLine(frame_with_vector, (center_x, center_y), (end_x, end_y), (0, 0, 255), 2, tipLength=0.2) \n",
    "    return frame_with_vector\n",
    "\n",
    "def OFV(frames, step): #Frame list, window size\n",
    "    OF = [] #List of Optical flow's vector fields\n",
    "    i = 0 #Frame's index\n",
    "    while True:\n",
    "        #convert it to grayscale\n",
    "        prev_gray = cv2.cvtColor(np.copy(frames[i]), cv2.COLOR_BGR2GRAY)\n",
    "        next_gray = cv2.cvtColor(np.copy(frames[i+1]), cv2.COLOR_BGR2GRAY)\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        # Draw the optical flow vectors on the frame\n",
    "        flow_frame = draw_optical_flow_vectors(flow, cv2.addWeighted(frames[i], 0.5, frames[i+1], 0.5, 0), step)\n",
    "        OF.append(flow) #Add flow to list\n",
    "        # Draw the sum vector on the frame\n",
    "        frame_with_sum_vector = draw_sum_vector(flow, flow_frame)\n",
    "        # Display the original frame with optical flow vectors and sum vector\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        #cv2.imshow('Optical Flow Vectors', flow_frame)\n",
    "        cv2.imshow('Sum Vector', frame_with_sum_vector)\n",
    "        key = cv2.waitKeyEx(0) #Read pressed key\n",
    "        if key == ord('q'): #Stop if pressed\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key for next frames\n",
    "            i = i - 1\n",
    "            if i < 0: #prevent non existent frames\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key for previous frames\n",
    "            i = i + 1\n",
    "            if i > (len(frames) - 2): #prevent non existent frames\n",
    "                i = len(frames) - 2\n",
    "    cv2.destroyAllWindows() #Close all windows\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020f5f6",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c885fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sum_vector_lk(good_new, good_old, frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Compute the sum of all flow vectors\n",
    "    sum_fx = np.sum(good_new[:, 0] - good_old[:, 0])\n",
    "    sum_fy = np.sum(good_new[:, 1] - good_old[:, 1])\n",
    "\n",
    "    # Calculate the center point of the frame\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "    \n",
    "    # Normalize the sum vector to fit within the image\n",
    "    max_length = min(w, h) // 2\n",
    "    vector_length = np.sqrt(sum_fx**2 + sum_fy**2)\n",
    "    if vector_length > 0:\n",
    "        scale = 0.1#max_length / vector_length\n",
    "        end_x = int(center_x + sum_fx * scale)\n",
    "        end_y = int(center_y + sum_fy * scale)\n",
    "    else:\n",
    "        end_x, end_y = center_x, center_y\n",
    "    \n",
    "    # Draw the sum vector as a red arrow\n",
    "    frame_with_vector = np.copy(frame)\n",
    "    cv2.arrowedLine(frame_with_vector, (center_x, center_y), (end_x, end_y), (0, 0, 255), 2, tipLength=0.2)\n",
    "    \n",
    "    return frame_with_vector\n",
    "\n",
    "def OFLK(frames, step_size):\n",
    "    OF = []\n",
    "    # Parameters for the Lucas-Kanade optical flow\n",
    "    lk_params = dict(winSize=(step_size, step_size), maxLevel=10, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "\n",
    "    # Create a grid of points to track\n",
    "    grid_y, grid_x = np.mgrid[0:frames[0].shape[0]:step_size, 0:frames[0].shape[1]:step_size]\n",
    "    p0 = np.vstack((grid_x.ravel(), grid_y.ravel())).T.astype(np.float32).reshape(-1, 1, 2)\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # Take the first frame and convert it to grayscale\n",
    "        old_frame = np.copy(frames[i])\n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = np.copy(frames[i+1])\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "\n",
    "        frame = cv2.addWeighted(frames[i], 0.5, frames[i+1], 0.5, 0)\n",
    "        # Draw the normalized vectors\n",
    "        for j, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            # Calculate vector components\n",
    "            dx = a - c\n",
    "            dy = b - d\n",
    "            # Normalize vector\n",
    "            magnitude = np.sqrt(dx**2 + dy**2)\n",
    "            if magnitude > 0:\n",
    "                dx /= magnitude\n",
    "                dy /= magnitude\n",
    "            # Scale vector for visualization\n",
    "            scale = 10  # Adjust this value for smaller or larger arrows\n",
    "            a = int(c + dx * scale)\n",
    "            b = int(d + dy * scale)\n",
    "            frame = cv2.arrowedLine(frame, (int(c), int(d)), (a, b), (0, 255, 0), 1, tipLength=0.3)\n",
    "\n",
    "        # Draw the sum vector on the frame\n",
    "        frame_with_sum_vector = draw_sum_vector_lk(good_new, good_old, frame)\n",
    "        \n",
    "        OF.append(frame)\n",
    "        cv2.imshow('Prev', frames[i])\n",
    "        cv2.imshow('Next', frames[i+1])\n",
    "        #cv2.imshow('Optical Flow Vectors', frame)\n",
    "        cv2.imshow('Sum Vector', frame_with_sum_vector)\n",
    "\n",
    "        # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i < 0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i > (len(frames) - 2):\n",
    "                i = len(frames) - 2\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82465a3a",
   "metadata": {},
   "source": [
    "## Phase Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab419dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sum_vector_phase_c(sum_dx, sum_dy, frame):\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # Calculate the center point of the frame\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "\n",
    "    # Normalize the sum vector to fit within the image\n",
    "    max_length = min(w, h) // 2\n",
    "    vector_length = np.sqrt(sum_dx**2 + sum_dy**2)\n",
    "    if vector_length > 0:\n",
    "        scale = max_length / vector_length\n",
    "        end_x = int(center_x + sum_dx * scale)\n",
    "        end_y = int(center_y + sum_dy * scale)\n",
    "    else:\n",
    "        end_x, end_y = center_x, center_y\n",
    "\n",
    "    # Draw the sum vector as a red arrow\n",
    "    frame_with_vector = np.copy(frame)\n",
    "    cv2.arrowedLine(frame_with_vector, (center_x, center_y), (end_x, end_y), (0, 0, 255), 2, tipLength=0.2)\n",
    "\n",
    "    return frame_with_vector\n",
    "\n",
    "def PhaseC(frames, block_size=20, grid_step=20):\n",
    "    OF = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        prev_frame = np.copy(frames[i])\n",
    "        next_frame = np.copy(frames[i + 1])\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Create an image to visualize the flow\n",
    "        flow_img = cv2.cvtColor(prev_gray, cv2.COLOR_GRAY2BGR)\n",
    "        frame = cv2.addWeighted(frames[i], 0.5, frames[i+1], 0.5, 0)\n",
    "\n",
    "        sum_dx, sum_dy = 0, 0\n",
    "\n",
    "        # Iterate over the grid\n",
    "        for y in range(0, prev_gray.shape[0] - block_size, grid_step):\n",
    "            for x in range(0, prev_gray.shape[1] - block_size, grid_step):\n",
    "                # Extract the blocks\n",
    "                prev_block = prev_gray[y:y + block_size, x:x + block_size]\n",
    "                next_block = next_gray[y:y + block_size, x:x + block_size]\n",
    "\n",
    "                # Compute phase correlation\n",
    "                shift, _ = cv2.phaseCorrelate(prev_block.astype(np.float32), next_block.astype(np.float32))\n",
    "                dx, dy = shift\n",
    "\n",
    "                # Sum the vectors\n",
    "                sum_dx += dx\n",
    "                sum_dy += dy\n",
    "\n",
    "                # Scale down the length of the arrows and size of the tips\n",
    "                scale = 1\n",
    "                tip_length = 0.2\n",
    "\n",
    "                # Draw the vector on the flow image\n",
    "                cv2.arrowedLine(frame, (x + block_size // 2, y + block_size // 2),\n",
    "                                (int(x + block_size // 2 + dx * scale), int(y + block_size // 2 + dy * scale)),\n",
    "                                (0, 255, 0), 1, tipLength=tip_length)\n",
    "\n",
    "        # Draw the sum vector on the frame\n",
    "        frame_with_sum_vector = draw_sum_vector_phase_c(sum_dx, sum_dy, frame)\n",
    "\n",
    "        OF.append(flow_img)\n",
    "\n",
    "        # Display the frames and the flow\n",
    "        cv2.imshow('Previous Frame', prev_frame)\n",
    "        cv2.imshow('Next Frame', next_frame)\n",
    "        #cv2.imshow('Optical Flow', frame)\n",
    "        cv2.imshow('Sum Vector', frame_with_sum_vector)\n",
    "\n",
    "        # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i < 0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i > (len(frames) - 2):\n",
    "                i = len(frames) - 2\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a69a1",
   "metadata": {},
   "source": [
    "# Frames Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916ac321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_dif(frames, threshold=30):\n",
    "    D = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        prev_frame = np.copy(frames[i])\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(np.copy(frames[i+1]), cv2.COLOR_BGR2GRAY)\n",
    "        # Compute absolute difference between frames\n",
    "        diff = cv2.absdiff(prev_gray, curr_gray)\n",
    "              \n",
    "        # Create a mask to highlight pixels with significant changes\n",
    "        mask = np.zeros_like(diff)\n",
    "        mask[diff > threshold] = 255\n",
    "        D.append(mask)\n",
    "        # Show original frame and mask\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        cv2.imshow('Pixels with Most Changes', mask)\n",
    "         # Wait for a key press to move to the next frame\n",
    "        key = cv2.waitKeyEx(0)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == 2424832:  # Left arrow key\n",
    "            i = i - 1\n",
    "            if i<0:\n",
    "                i = 0\n",
    "        if key == 2555904:  # Right arrow key\n",
    "            i = i + 1\n",
    "            if i>(len(frames)-2):\n",
    "                i = len(frames)-2\n",
    "\n",
    "        prev_frame = frames[i]\n",
    "\n",
    "    # Release the video capture object\n",
    "    cv2.destroyAllWindows()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d54d949",
   "metadata": {},
   "source": [
    "# Change Color Channel's Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b706d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_range_colors(image, min_vals=(0, 0, 0), max_vals=(255, 255, 255)):\n",
    "    # Split the image into its BGR channels\n",
    "    b, g, r = cv2.split(image)\n",
    "    \n",
    "    # Clip each channel to its respective range\n",
    "    b = np.clip(b, min_vals[0], max_vals[0])\n",
    "    g = np.clip(g, min_vals[1], max_vals[1])\n",
    "    r = np.clip(r, min_vals[2], max_vals[2])\n",
    "    \n",
    "    # Merge the channels back together\n",
    "    new_image = cv2.merge((b, g, r))\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5bd9e2",
   "metadata": {},
   "source": [
    "# Add Occlusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b7dec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusions(image, num_occlusions=1,loc=[],sizes=[],shapes=['rectangle','circle'], colors=(-1,-1,-1)):    \n",
    "    output_image = np.copy(image)\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    num_occlusions = num_occlusions if len(loc)==0 else len(loc)\n",
    "    \n",
    "    # Draw occlusions on the image\n",
    "    for i in range(num_occlusions):\n",
    "        shape_type = random.choice(shapes)\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) if colors==(-1,-1,-1) else colors  # Random color\n",
    "        \n",
    "        if shape_type == 'rectangle':\n",
    "            x = random.randint(0, width - 1) if len(loc)==0 else loc[i][0]\n",
    "            y = random.randint(0, height - 1) if len(loc)==0 else loc[i][1]\n",
    "            width_rect = random.randint(5, width//2) if len(sizes)==0 else loc[i][0]\n",
    "            height_rect = random.randint(5, height//2) if len(sizes)==0 else loc[i][1]\n",
    "            cv2.rectangle(output_image, (x, y), (x + width_rect, y + height_rect), color, -1)  # Filled rectangle\n",
    "        \n",
    "        elif shape_type == 'circle':\n",
    "            center = (random.randint(0, width - 1), random.randint(0, height - 1)) if len(loc)==0 else (loc[i][0],loc[i][1])\n",
    "            radius = 50#random.randint(5, 100)\n",
    "            cv2.circle(output_image, center, radius, color, -1)  # Filled circle\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367e0fd",
   "metadata": {},
   "source": [
    "# Read Images in a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a107d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(directory_path):\n",
    "    images = []\n",
    "    # List all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the file has a PNG extension\n",
    "        if filename.lower().endswith('.png'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Read the image using OpenCV\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)  # cv2.IMREAD_UNCHANGED to keep the alpha channel if present\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "            else:\n",
    "                print(f\"Failed to read image: {file_path}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77814136",
   "metadata": {},
   "source": [
    "# Draw Random Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66df5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_lines(image, num_lines):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "\n",
    "    for _ in range(num_lines):\n",
    "        # Generate random start point\n",
    "        start_point = (random.randint(0, width-1), random.randint(0, height-1))\n",
    "        \n",
    "        # Generate a random angle and length for the line\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "        length = random.randint(1, min(width, height) // 2)  # Limit length to half of the smallest dimension\n",
    "        \n",
    "        # Calculate the end point using the angle and length\n",
    "        end_point = (int(start_point[0] + length * np.cos(angle)), \n",
    "                     int(start_point[1] + length * np.sin(angle)))\n",
    "        \n",
    "        # Ensure the end point is within the image boundaries\n",
    "        end_point = (min(max(end_point[0], 0), width-1), min(max(end_point[1], 0), height-1))\n",
    "        \n",
    "        # Generate a random color (BGR format)\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        \n",
    "        # Generate a random thickness for the line\n",
    "        thickness = random.randint(1, 10)\n",
    "        \n",
    "        # Draw the line on the image\n",
    "        cv2.line(output_image, start_point, end_point, color, thickness)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70d5c3",
   "metadata": {},
   "source": [
    "# Random Region's Color Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "351b525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_regions(image, num_regions):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "\n",
    "    for _ in range(num_regions):\n",
    "        # Generate random region shape and size\n",
    "        region_shape = random.choice(['rectangle', 'ellipse'])\n",
    "        \n",
    "        if region_shape == 'rectangle':\n",
    "            region_width = random.randint(10, width // 3)\n",
    "            region_height = random.randint(10, height // 3)\n",
    "            top_left_x = random.randint(0, width - region_width)\n",
    "            top_left_y = random.randint(0, height - region_height)\n",
    "            \n",
    "            # Define the region\n",
    "            region = output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width]\n",
    "        \n",
    "        elif region_shape == 'ellipse':\n",
    "            center_x = random.randint(width // 3, width - width // 3)\n",
    "            center_y = random.randint(height // 3, height - height // 3)\n",
    "            axis_length = (random.randint(10, width // 3), random.randint(10, height // 3))\n",
    "            angle = random.randint(0, 360)\n",
    "            start_angle = 0\n",
    "            end_angle = 360\n",
    "\n",
    "            # Create a mask for the ellipse\n",
    "            mask = np.zeros((height, width), dtype=np.uint8)\n",
    "            cv2.ellipse(mask, (center_x, center_y), axis_length, angle, start_angle, end_angle, 255, -1)\n",
    "            \n",
    "            # Extract the region using the mask\n",
    "            region = cv2.bitwise_and(output_image, output_image, mask=mask)\n",
    "\n",
    "        # Change color channels within the region\n",
    "        for channel in range(3):  # Assuming BGR format\n",
    "            # Generate random ranges for the color channel\n",
    "            low = random.randint(0, 255)\n",
    "            high = random.randint(low, 255)\n",
    "            if region_shape == 'rectangle':\n",
    "                region[..., channel] = np.clip(region[..., channel], low, high)\n",
    "            elif region_shape == 'ellipse':\n",
    "                # Apply changes to the region using the mask\n",
    "                channel_region = output_image[..., channel]\n",
    "                channel_region[mask == 255] = np.clip(channel_region[mask == 255], low, high)\n",
    "                output_image[..., channel] = channel_region\n",
    "\n",
    "        if region_shape == 'rectangle':\n",
    "            # Place the modified region back into the image for rectangles\n",
    "            output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width] = region\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254d8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize_image(img, k=50, it = 5, t1 = 150, t2 = 255, ks = 1):\n",
    "\n",
    "    # Apply bilateral filter to smooth the image\n",
    "    img_color = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian Blur\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (1, 1), 0)\n",
    "\n",
    "    # Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(img_blur, threshold1=t1, threshold2=t2)\n",
    "    \n",
    "    # Dilate the edges to make them more prominent\n",
    "    kernel = np.ones((ks, ks), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Invert the edges\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "\n",
    "    # Convert edges back to color, so we can combine with color image\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    img_data = np.float32(img_color).reshape((-1, 3))\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, it, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(img_data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    centers = np.uint8(centers)\n",
    "    img_clustered = centers[labels.flatten()]\n",
    "    img_clustered = img_clustered.reshape(img_color.shape)\n",
    "\n",
    "    # Combine edge and clustered image\n",
    "    cartoon = cv2.bitwise_and(img_clustered, edges_colored)\n",
    "\n",
    "    return cartoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27eeb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize_image1(img, k=8, it = 10):\n",
    "\n",
    "    # Apply bilateral filter to smooth the image\n",
    "    img_color = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    img_data = np.float32(img_color).reshape((-1, 3))\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, it, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(img_data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    img_clustered = centers[labels.flatten()]\n",
    "    img_clustered = img_clustered.reshape(img_color.shape)\n",
    "\n",
    "    # Convert clustered image to grayscale\n",
    "    img_gray = cv2.cvtColor(img_clustered, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian Blur\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "\n",
    "    # Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(img_blur, threshold1=0, threshold2=255)\n",
    "    \n",
    "    # Dilate the edges to make them more prominent\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Invert the edges\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "\n",
    "    # Convert edges back to color, so we can combine with clustered image\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Combine edge and clustered image\n",
    "    cartoon = cv2.bitwise_and(img_clustered, edges_colored)\n",
    "\n",
    "    return cartoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c2655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize_image2(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply median blur to smoothen the image\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Detect edges using adaptive thresholding\n",
    "    edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)\n",
    "\n",
    "    # Apply bilateral filter to smooth the image while keeping edges sharp\n",
    "    color = cv2.bilateralFilter(img, 9, 300, 300)\n",
    "\n",
    "    # Combine edges and color image\n",
    "    cartoon = cv2.bitwise_and(color, color, mask=edges)\n",
    "\n",
    "    return cartoon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0bd8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize_image3(img, k=8, it=10):\n",
    "    # Apply bilateral filter to smooth the image\n",
    "    img_color = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian Blur\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (1, 1), 0)\n",
    "\n",
    "    # Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(img_blur, threshold1=200, threshold2=200)\n",
    "    \n",
    "    # Dilate the edges to make them more prominent\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Invert the edges\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "\n",
    "    # Convert edges back to color, so we can combine with color image\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Perform Gaussian Mixture Model clustering\n",
    "    img_data = np.float32(img_color).reshape((-1, 3))\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=k, max_iter=it, random_state=0)\n",
    "    labels = gmm.fit_predict(img_data)\n",
    "    centers = gmm.means_\n",
    "\n",
    "    centers = np.uint8(centers)\n",
    "    img_clustered = centers[labels]\n",
    "    img_clustered = img_clustered.reshape(img_color.shape)\n",
    "\n",
    "    # Combine edge and clustered image\n",
    "    cartoon = cv2.bitwise_and(img_clustered, edges_colored)\n",
    "\n",
    "    return cartoon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fb3807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize_image4(img, bandwidth=None):\n",
    "    # Apply bilateral filter to smooth the image\n",
    "    img_color = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian Blur\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (1, 1), 0)\n",
    "\n",
    "    # Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(img_blur, threshold1=200, threshold2=200)\n",
    "    \n",
    "    # Dilate the edges to make them more prominent\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Invert the edges\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "\n",
    "    # Convert edges back to color, so we can combine with color image\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Perform Mean Shift clustering\n",
    "    img_data = np.float32(img_color.reshape(-1, 3))\n",
    "    \n",
    "    if bandwidth is None:\n",
    "        bandwidth = estimate_bandwidth(img_data, quantile=0.2, n_samples=500)\n",
    "\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(img_data)\n",
    "    labels = ms.labels_\n",
    "    centers = ms.cluster_centers_\n",
    "\n",
    "    centers = np.uint8(centers)\n",
    "    img_clustered = centers[labels].reshape(img_color.shape)\n",
    "\n",
    "    # Combine edge and clustered image\n",
    "    cartoon = cv2.bitwise_and(img_clustered, edges_colored)\n",
    "\n",
    "    return cartoon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94e4c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize_image5(img, eps=30, min_samples=100):\n",
    "    # Apply bilateral filter to smooth the image\n",
    "    img_color = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian Blur\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (1, 1), 0)\n",
    "\n",
    "    # Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(img_blur, threshold1=200, threshold2=200)\n",
    "    \n",
    "    # Dilate the edges to make them more prominent\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Invert the edges\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "\n",
    "    # Convert edges back to color, so we can combine with color image\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Perform DBSCAN clustering\n",
    "    img_data = np.float32(img_color.reshape(-1, 3))\n",
    "\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(img_data)\n",
    "    unique_labels = np.unique(labels)\n",
    "    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)  # Number of clusters, ignoring noise (-1)\n",
    "\n",
    "    # Assign random colors to clusters\n",
    "    centers = np.zeros((n_clusters, 3), dtype=np.uint8)\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        if label == -1:\n",
    "            continue  # Skip noise points\n",
    "        mask = (labels == label)\n",
    "        centers[i] = np.mean(img_data[mask], axis=0)\n",
    "\n",
    "    img_clustered = np.zeros_like(img_color)\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        if label == -1:\n",
    "            continue  # Skip noise points\n",
    "        mask = (labels == label)\n",
    "        img_clustered[mask] = centers[i]\n",
    "\n",
    "    # Combine edge and clustered image\n",
    "    cartoon = cv2.bitwise_and(img_clustered, edges_colored)\n",
    "\n",
    "    return cartoon\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
