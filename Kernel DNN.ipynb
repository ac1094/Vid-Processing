{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c54ec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ConsistencyIndexes.ipynb\n",
      "importing Jupyter notebook from Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from ConsistencyIndexes import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch import nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75833401",
   "metadata": {},
   "source": [
    "# DNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b0e65",
   "metadata": {},
   "source": [
    "Loss Function:<br>\n",
    "<center>$L = MSE\\left(T,\\sum_{i=0}^{N} W_i*Conv(I,K_i)\\right)$</center><br>\n",
    "Where:<br>\n",
    "<ul>\n",
    "    <li><b>$L$</b> is the loss function.\n",
    "    <li><b>$T$</b> is the target image.\n",
    "    <li><b>$I$</b> is the original image.\n",
    "    <li><b>$N$</b> is the number of kernels and weights.\n",
    "    <li><b>$K_i$</b> is the ith kernel.\n",
    "    <li><b>$W_i$</b> is the weight for the kernel $K_i$.\n",
    "    <li><b>$Conv$</b> is the convolution function.\n",
    "    <li><b>$MSE$</b> is the mean squared error function.\n",
    "</ul>\n",
    "The gradients and parameters are calculated and updated in every pair of images for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c5f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kernels(input_image, kernels1, kernels2=None):\n",
    "    out = input_image.clone()\n",
    "    for k in kernels1:\n",
    "        out = F.conv2d(out, k, padding='same', stride=1)  \n",
    "    if kernels2 is not None:\n",
    "        out2 = input_image.clone()\n",
    "        for k in kernels2:\n",
    "            out2 = F.conv2d(out2, k, padding='same', stride=1)\n",
    "        out = (out+out2)/2\n",
    "    return out\n",
    "\n",
    "def predict(input_image, kernels1, kernels2):\n",
    "    input_image = torch.tensor(input_image / 255.0, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output_image = apply_kernels(input_image, kernels1, kernels2) * 255\n",
    "    return output_image.squeeze(0).permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "def generate_kernels(Nk):\n",
    "    K = []\n",
    "    for i in range(Nk):\n",
    "        r = random.randint(3, 9)\n",
    "        while r % 2 > 0:\n",
    "            r = random.randint(3, 5)\n",
    "        K.append(torch.rand(3, 3, r, r, requires_grad=True))  # Changed kernel size to 3x3 to match input channels\n",
    "    return K\n",
    "\n",
    "def train_model(input_images, target_images, kernels1, kernels2, num_kernels=1, epochs=10, lr=0.01):\n",
    "    oimg = input_images.copy()\n",
    "    L = []\n",
    "    # Normalize input and target images (to 0-1)\n",
    "    input_images = [img / 255.0 for img in input_images]\n",
    "    target_images = [img / 255.0 for img in target_images]    \n",
    "    # Convert input and target images to tensors\n",
    "    input_images = torch.stack([torch.tensor(img, dtype=torch.float32) for img in input_images])\n",
    "    target_images = torch.stack([torch.tensor(img, dtype=torch.float32) for img in target_images])  \n",
    "    # Initialize kernels\n",
    "    if kernels1 is None:\n",
    "        kernels1 = generate_kernels(num_kernels)\n",
    "    if kernels2 is None:\n",
    "        kernels2 = generate_kernels(num_kernels)\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(kernels1 + kernels2, lr=lr)\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for input_image, target_image, o in zip(input_images, target_images, oimg):\n",
    "            cv2.imshow(\"Predicted\", np.clip(predict(o, kernels1, kernels2), 0, 255))  # Display Image\n",
    "            input_image = input_image.permute(2, 0, 1).unsqueeze(0)  # Add batch dimension\n",
    "            target_image = target_image.permute(2, 0, 1).unsqueeze(0)         \n",
    "            optimizer.zero_grad()   \n",
    "            output_image = apply_kernels(input_image, kernels1, kernels2)\n",
    "            loss = F.mse_loss(output_image,target_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()          \n",
    "            total_loss += loss.item() \n",
    "            cv2.waitKey(10)\n",
    "        L.append(total_loss)\n",
    "        clear_output()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(input_images):.4f}')\n",
    "        if len(L) > 2:\n",
    "            if abs(L[-2] - L[-1]) < 1e-6:\n",
    "                break\n",
    "    print('Training complete.')\n",
    "    cv2.destroyAllWindows()\n",
    "    return kernels1, kernels2, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ba2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## L = w1*mse(t_border,R_border)+w2*mse(t_discrete,R_discrete)+w3*mse(t_all,R_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea2ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_10_frames_from_videos(directory,N):\n",
    "    video_frames = []  # Dictionary to store video names and their first 10 frames\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mp4\"):  # Check for video file extensions\n",
    "            video_path = os.path.join(directory, filename)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frames = []\n",
    "            frame_count = 0\n",
    "            while frame_count < N and cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break  # If the video ends before 10 frames\n",
    "                frames.append(frame)\n",
    "                frame_count += 1\n",
    "            cap.release()  # Release the video capture object\n",
    "            video_frames += frames  # Store the frames with the video name\n",
    "    return video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d8fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'Uncartoonized/'\n",
    "org = read_first_10_frames_from_videos(directory_path,3)\n",
    "#ThroughFrames(orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e96dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'Cartoonized/'\n",
    "cart = read_first_10_frames_from_videos(directory_path,3)\n",
    "#ThroughFrames(carts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06749040",
   "metadata": {},
   "outputs": [],
   "source": [
    "org = [cv2.resize(o,(640,320)) for o in org]\n",
    "cart = [cv2.resize(o,(640,320)) for o in cart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a830dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(org),len(cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93790424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0282\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "kernels1, kernels2, Losses = train_model(org, cart, kernels1,kernels2,num_kernels=2,epochs=100, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48e4576a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x181b8dba448>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97e67396",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted = [predict(o,kernels1,kernels2) for o in org[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37681aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThroughFrames(Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abc26e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vid(Predicted,\"Predicted/org_pred.mp4\",24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb8970e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kernels(kernels1, kernels2, file_path):\n",
    "    torch.save({'kernels1': kernels1, 'kernels2': kernels2}, file_path)\n",
    "    print(f'Kernels saved to {file_path}')\n",
    "def load_kernels(file_path):\n",
    "    checkpoint = torch.load(file_path)\n",
    "    kernels1 = checkpoint['kernels1']\n",
    "    kernels2 = checkpoint['kernels2']\n",
    "    print(f'Kernels loaded from {file_path}')\n",
    "    return kernels1, kernels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deb47328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels saved to trained_kernels.pth\n",
      "Kernels loaded from trained_kernels.pth\n"
     ]
    }
   ],
   "source": [
    "save_kernels(kernels1, kernels2, 'trained_kernels.pth')\n",
    "kernels1, kernels2 = load_kernels('trained_kernels.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "751f3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap0 = open_vid(\"VDB/U.mp4\")\n",
    "org0 = get_frames(cap0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4904e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted0 = [predict(o,kernels1,kernels2) for o in org0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b8845c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThroughFrames(Predicted0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6857eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vid(Predicted0,\"Predicted/UU_pred.mp4\",24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply kernels over filtered image\n",
    "## Border detector and Smoother\n",
    "## Different kernel sizes\n",
    "## Border detector small\n",
    "## Smoother larger\n",
    "## Check what happens if a kernel is omited\n",
    "## Use past and future frames\n",
    "## Formalize the problem\n",
    "## What's the main objective of project?\n",
    "## Other DNN strictures: GAN, Graphic Transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
