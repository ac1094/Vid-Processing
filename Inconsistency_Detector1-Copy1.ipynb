{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74260a5",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ac1094/Vid-Processing/blob/main/Inconsistency_Detector1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6792001",
   "metadata": {
    "id": "a48ed841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a3b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = 100,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2986417f",
   "metadata": {
    "id": "6fcb9d30"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define the Optimized Transformer Model with Convolutional Layers\n",
    "class OptimizedTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedTransformer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(17, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 25, 512)  # Adjusted size\n",
    "        self.fc2 = nn.Linear(512, w * h)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"conv1_in: \", x.size())\n",
    "        x = self.conv1(x)  # (N, 32, 50, 100)\n",
    "        print(\"pool_in: \", x.size())\n",
    "        x = self.pool(x)  # (N, 32, 25, 50)\n",
    "        print(\"conv2_in: \", x.size())\n",
    "        x = self.conv2(x) # (N, 64, 25, 50)\n",
    "        print(\"pool1_in: \", x.size())\n",
    "        x = self.pool1(x) # (N, 64, 12, 25)\n",
    "        print(\"fc1_in: \", x.size())\n",
    "        x = x.view(-1, 32 * 6 * 25)  # Flatten\n",
    "        x = self.fc1(x)  # (N, 512)\n",
    "        print(\"fc2_in: \", x.size())\n",
    "        x = self.fc2(x)  # (N, 50 * 100)\n",
    "        print(\"sig_in: \", x.size())\n",
    "        x = self.sigmoid(x)  # (N, 50 * 100)\n",
    "        print(\"view_in: \", x.size())\n",
    "        x = x.view(1, h, w)  # Reshape to the desired output size\n",
    "        return x\n",
    "\n",
    "# Custom Dataset to handle lists of tensors\n",
    "class TensorListDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = [torch.tensor(i) if isinstance(i, np.ndarray) else i for i in inputs]\n",
    "        self.targets = [torch.tensor(t) if isinstance(t, np.ndarray) else t for t in targets]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, num_epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            target = target.squeeze(1)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader)}')\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, input_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        binary_output = (output > 0.5).float()\n",
    "    return binary_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001da579",
   "metadata": {
    "id": "f68c1bc4"
   },
   "outputs": [],
   "source": [
    "F = read_images(\"saved_frames\")\n",
    "F = [cv2.resize(f,(h,w)) for f in F]\n",
    "F = F[:20]\n",
    "D = np.asarray([abs(F[i]-F[i+1]) for i in range(len(F)-1)],dtype=np.uint8)\n",
    "D0 = np.asarray(D[:-1],dtype=np.uint8)\n",
    "D2 = np.asarray(D[1:],dtype=np.uint8)\n",
    "down = 0\n",
    "up = 255\n",
    "B = np.asarray([abs(cv2.Canny(cv2.cvtColor(F[i],cv2.COLOR_BGR2GRAY),down,up)-cv2.Canny(cv2.cvtColor(F[i+1],cv2.COLOR_BGR2GRAY),down,up)) for i in range(len(F)-1)],dtype=np.uint8)\n",
    "B0 = np.asarray(B[:-1],dtype=np.uint8)\n",
    "B2 = np.asarray(B[1:],dtype=np.uint8)\n",
    "F0 = np.asarray(F[:-2],dtype=np.uint8)\n",
    "F2 = np.asarray(F[2:],dtype=np.uint8)\n",
    "F = np.asarray(F[1:-1],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb5aaf2",
   "metadata": {
    "id": "4781bcc8"
   },
   "outputs": [],
   "source": [
    "Input = [np.asarray((F0[i][:,:,0],F0[i][:,:,1],F0[i][:,:,2],\n",
    "                    F[i][:,:,0],F[i][:,:,1],F[i][:,:,2],\n",
    "                    F2[i][:,:,0],F2[i][:,:,1],F2[i][:,:,2],\n",
    "                    D0[i][:,:,0],D0[i][:,:,1],D0[i][:,:,2],\n",
    "                    D2[i][:,:,0],D2[i][:,:,1],D2[i][:,:,2],\n",
    "                    B0[i],\n",
    "                    B2[i]\n",
    "                     )) for i in range(len(F))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb2a0f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b7b05c3",
    "outputId": "c3113465-9644-4040-9631-fe4c03fada05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 200, 100)\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(Input[0].shape)\n",
    "print(len(Input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d19e84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf8a9813",
    "outputId": "3b55daf3-386d-4d1f-dc3c-eac72d6da673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 torch.Size([17, 200, 100])\n"
     ]
    }
   ],
   "source": [
    "input_arrays = [torch.tensor(i,dtype=torch.float32) for i in Input[:12]]\n",
    "print(len(input_arrays),input_arrays[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe267e25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a1aa97f",
    "outputId": "468f8980-8bc1-4c91-d5bb-674256cfa4a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 torch.Size([1, 100, 200])\n"
     ]
    }
   ],
   "source": [
    "target_arrays = [torch.zeros(1,h,w,dtype=torch.float32) for _ in range(len(Input[:12]))]\n",
    "print(len(target_arrays),target_arrays[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddbcfdc1",
   "metadata": {
    "id": "1dbcdec2"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-82a167d4462a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mMasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMasks\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Resize before normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mMasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMasks\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Normalize pixel values to [0, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtarget_arrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtarget_arrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtarget_arrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "Masks = read_images(\"Masks\")\n",
    "Masks = [cv2.cvtColor(m[:,:,:3],cv2.COLOR_RGB2GRAY) for m in Masks]\n",
    "Masks = [cv2.resize(m,(h,w)) for m in Masks] # Resize before normalization\n",
    "Masks = [torch.tensor(m / 255.0, dtype=torch.float32) for m in Masks] # Normalize pixel values to [0, 1]\n",
    "target_arrays[3] = Masks[0].reshape((1,h,w))\n",
    "target_arrays[6] = Masks[1].reshape((1,h,w))\n",
    "target_arrays[9] = Masks[2].reshape((1,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00c4fcfc",
   "metadata": {
    "id": "uGkA3eMS3Bdu"
   },
   "outputs": [],
   "source": [
    "dataset = TensorListDataset(input_arrays, target_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44fd4a09",
   "metadata": {
    "id": "lgraoJuj3Ec9"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc0f03bc",
   "metadata": {
    "id": "a1e3367e"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = OptimizedTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a234f3ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7a858cf",
    "outputId": "5e67054c-125a-4782-9cd2-4aaac482fb18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_in:  torch.Size([2, 17, 200, 100])\n",
      "pool_in:  torch.Size([2, 32, 200, 100])\n",
      "conv2_in:  torch.Size([2, 32, 100, 50])\n",
      "pool1_in:  torch.Size([2, 64, 100, 50])\n",
      "fc1_in:  torch.Size([2, 64, 50, 25])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 4800]' is invalid for input of size 160000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-afe5440777c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model on the random data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-5ee47e6efdd8>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-5ee47e6efdd8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (N, 64, 12, 25)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fc1_in: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m6\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (N, 512)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fc2_in: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 4800]' is invalid for input of size 160000"
     ]
    }
   ],
   "source": [
    "# Train the model on the random data\n",
    "train_model(model, train_loader, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3fecf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4bd6eeb",
    "outputId": "9dc266e6-baaa-4d6c-e6e6-719c0a989a33"
   },
   "outputs": [],
   "source": [
    "# Create a new random input tensor for prediction\n",
    "new_input = torch.tensor(Input[12:14],dtype=torch.float32)\n",
    "print(new_input.shape)\n",
    "# Predict using the trained model\n",
    "predicted_output = predict(model, new_input)\n",
    "\n",
    "# Print the shape of the predicted output\n",
    "print(predicted_output.size())  # Should output torch.Size([1, 320, 640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6cc9b",
   "metadata": {
    "id": "0286c78d"
   },
   "outputs": [],
   "source": [
    "resize_arr0 = cv2.resize(np.asarray(predicted_output[0]),(640,320))\n",
    "resize_arr0[resize_arr0 >= 0.5] = 255\n",
    "resize_arr0[resize_arr0 < 0.5] = 0\n",
    "resize_arr1 = cv2.resize(np.asarray(predicted_output[1]),(640,320))\n",
    "resize_arr1[resize_arr1 >= 0.5] = 255\n",
    "resize_arr1[resize_arr1 < 0.5] = 0\n",
    "In = read_images(\"saved_frames\")\n",
    "display_images([resize_arr0,resize_arr1,In[13],In[14]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279b078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
