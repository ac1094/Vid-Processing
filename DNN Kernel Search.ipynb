{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac4bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ConsistencyIndexes.ipynb\n",
      "importing Jupyter notebook from Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from ConsistencyIndexes import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe48d47",
   "metadata": {},
   "source": [
    "### Get Original Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35809236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width:  640\n",
      "Height:  320\n",
      "FPS:  24.0\n",
      "Frame Count:  36\n"
     ]
    }
   ],
   "source": [
    "cap = open_vid(\"VDB/X.mp4\")\n",
    "org = get_frames(cap)\n",
    "_,_,fps,_ = get_props(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bb800",
   "metadata": {},
   "source": [
    "### Get Cartoonized Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102711ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width:  640\n",
      "Height:  320\n",
      "FPS:  24.0\n",
      "Frame Count:  36\n"
     ]
    }
   ],
   "source": [
    "cap = open_vid(\"Cartoonized/Xtoon.mp4\")\n",
    "car = get_frames(cap)\n",
    "_,_,fps,_ = get_props(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7a556",
   "metadata": {},
   "source": [
    "### Calculate 2D Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d7aa132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2Dkernel(input_images, target_images, kernel_size=3, epochs=1000, learning_rate=1e-3):\n",
    "    # Normalize input and target images (to 0-1)\n",
    "    input_images = [img / 255.0 for img in input_images]\n",
    "    target_images = [img / 255.0 for img in target_images]\n",
    "    # Convert input and target images to tensors\n",
    "    input_images = torch.stack([torch.tensor(img, dtype=torch.float32) for img in input_images])\n",
    "    target_images = torch.stack([torch.tensor(img, dtype=torch.float32) for img in target_images])\n",
    "    # Image Size\n",
    "    height = input_images[0].shape[0]\n",
    "    width = input_images[0].shape[1]\n",
    "    # Use an optimizer to update the kernel\n",
    "    optimizer = torch.optim.SGD([kernel], lr=learning_rate)\n",
    "    # List of Loss over time\n",
    "    L = []\n",
    "    # Iterate over epochs\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()  # Clear the gradients from the previous iteration\n",
    "        # Iterate through each image and calculate the total loss\n",
    "        for i in range(len(input_images)):\n",
    "            # Separate each color channel\n",
    "            r = input_images[i][:,:,0].view(1, 1, height, width)\n",
    "            g = input_images[i][:,:,1].view(1, 1, height, width)\n",
    "            b = input_images[i][:,:,2].view(1, 1, height, width)\n",
    "            # Apply convolution to each channel\n",
    "            cr = F.conv2d(r, kernel, padding=1)\n",
    "            cg = F.conv2d(g, kernel, padding=1)\n",
    "            cb = F.conv2d(b, kernel, padding=1)\n",
    "            # Calculate the loss\n",
    "            loss = (F.mse_loss(cr, target_images[i][:,:,0].unsqueeze(0).unsqueeze(0)) +\n",
    "                    F.mse_loss(cg, target_images[i][:,:,1].unsqueeze(0).unsqueeze(0)) +\n",
    "                    F.mse_loss(cb, target_images[i][:,:,2].unsqueeze(0).unsqueeze(0)))\n",
    "            # Add to total loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update the kernel with the computed gradients\n",
    "        # Add total loss to list over ecpochs\n",
    "        L.append(total_loss)\n",
    "        # Print loss every 10 iterations\n",
    "        if iteration % 1 == 0:\n",
    "            print(f\"Iteration {epoch+1}/{epochs}, Total Loss: {total_loss}\",end='\\r')\n",
    "    # Return the optimized kernel and list of loss over epochs\n",
    "    return kernel.detach().numpy(),L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9ab331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000/1000, Total Loss: 1.9789092317223549\r"
     ]
    }
   ],
   "source": [
    "k,l = find_2Dkernel(org,car,3,1000,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ad6f56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.4491005  -0.34302577  0.20977691]\n",
      "   [ 0.11876388 -0.21754417  0.28502595]\n",
      "   [-0.3968136   1.1985881  -0.36275345]]]]\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2423ba",
   "metadata": {},
   "source": [
    "[[[[ 0.4491005  -0.34302577  0.20977691]\n",
    "   [ 0.11876388 -0.21754417  0.28502595]\n",
    "   [-0.3968136   1.1985881  -0.36275345]]]]\n",
    "<br>\n",
    "For X.mp4 and Xtoon.mp4 with 3x3 kernel, 1000 epochs and 1e-3 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a7c51487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f004e5c2c8>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l[200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7c0b5",
   "metadata": {},
   "source": [
    "### Apply Calculated Karnel to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64c89bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kernel(input_image, kernel):\n",
    "    # Ensure input image is a float tensor and normalize it\n",
    "    input_image = torch.tensor(input_image, dtype=torch.float32) / 255.0\n",
    "    # Convert the kernel to a PyTorch tensor if it is not already\n",
    "    if not isinstance(kernel, torch.Tensor):\n",
    "        kernel = torch.tensor(kernel, dtype=torch.float32)\n",
    "    # Get the dimensions of the input image\n",
    "    height, width, channels = input_image.shape\n",
    "    # Ensure size of image for convolution\n",
    "    r = input_image[:,:,0].view(1, 1, height, width)\n",
    "    g = input_image[:,:,1].view(1, 1, height, width)\n",
    "    b = input_image[:,:,2].view(1, 1, height, width)\n",
    "    # Apply the kernel to each channel\n",
    "    cr = F.conv2d(r, kernel, padding=1)\n",
    "    cg = F.conv2d(g, kernel, padding=1)\n",
    "    cb = F.conv2d(b, kernel, padding=1)\n",
    "    # Stack the channels back together\n",
    "    output_image = torch.cat([cr, cg, cb], dim=1).squeeze(0).permute(1, 2, 0).detach().numpy()\n",
    "    # Denormalize the output image (from 0-1 back to 0-255) and clip values to valid range\n",
    "    output_image = (output_image * 255.0).clip(0, 255).astype('uint8')\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9f7d5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [apply_kernel(o,k) for o in org]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4d773164",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThroughFrames(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bb40e",
   "metadata": {},
   "source": [
    "#### Differences (Black is zero difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [np.abs(car[i]-apply_kernel(org[i],k)) for i in range(len(car))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "74a11fb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-8301cf484a04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mThroughFrames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Video Processing\\ConsistencyIndexes.ipynb\u001b[0m in \u001b[0;36mThroughFrames\u001b[1;34m(frames)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ThroughFrames(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2Dkernel(input_images, target_images, kernel_size=3, epochs=1000, learning_rate=1e-3):\n",
    "    # Normalize input and target images (to 0-1)\n",
    "    input_images = [img / 255.0 for img in input_images]\n",
    "    target_images = [img / 255.0 for img in target_images]\n",
    "    # Convert input and target images to tensors\n",
    "    input_images = torch.stack([torch.tensor(img, dtype=torch.float32) for img in input_images])\n",
    "    target_images = torch.stack([torch.tensor(img, dtype=torch.float32) for img in target_images])\n",
    "    # Image Size\n",
    "    height = input_images[0].shape[0]\n",
    "    width = input_images[0].shape[1]\n",
    "    # Use an optimizer to update the kernel\n",
    "    optimizer = torch.optim.SGD([kernel], lr=learning_rate)\n",
    "    # List of Loss over time\n",
    "    L = []\n",
    "    # Iterate over epochs\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()  # Clear the gradients from the previous iteration\n",
    "        # Iterate through each image and calculate the total loss\n",
    "        for i in range(len(input_images)):\n",
    "            # Separate each color channel\n",
    "            r = input_images[i][:,:,0].view(1, 1, height, width)\n",
    "            g = input_images[i][:,:,1].view(1, 1, height, width)\n",
    "            b = input_images[i][:,:,2].view(1, 1, height, width)\n",
    "            # Apply convolution to each channel\n",
    "            cr = F.conv2d(r, kernel, padding=1)\n",
    "            cg = F.conv2d(g, kernel, padding=1)\n",
    "            cb = F.conv2d(b, kernel, padding=1)\n",
    "            # Calculate the loss\n",
    "            loss = (F.mse_loss(cr, target_images[i][:,:,0].unsqueeze(0).unsqueeze(0)) +\n",
    "                    F.mse_loss(cg, target_images[i][:,:,1].unsqueeze(0).unsqueeze(0)) +\n",
    "                    F.mse_loss(cb, target_images[i][:,:,2].unsqueeze(0).unsqueeze(0)))\n",
    "            # Add to total loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update the kernel with the computed gradients\n",
    "        # Add total loss to list over ecpochs\n",
    "        L.append(total_loss)\n",
    "        # Print loss every 10 iterations\n",
    "        if iteration % 1 == 0:\n",
    "            print(f\"Iteration {epoch+1}/{epochs}, Total Loss: {total_loss}\",end='\\r')\n",
    "    # Return the optimized kernel and list of loss over epochs\n",
    "    return kernel.detach().numpy(),L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel for each channel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
