{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc5dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "input_file = 'VDB\\D.mp4'   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac9aa31",
   "metadata": {},
   "source": [
    "# Open Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9039a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_vid(input_file):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bb8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = open_vid(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058b50d",
   "metadata": {},
   "source": [
    "# Get Video Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5cd655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width:  640\n",
      "Height:  358\n",
      "Original FPS:  30.0\n",
      "Frame Count:  2834\n"
     ]
    }
   ],
   "source": [
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Width: \",width)\n",
    "print(\"Height: \",height)\n",
    "print(\"Original FPS: \",original_fps)\n",
    "print(\"Frame Count: \",frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037b6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(cap):\n",
    "    frames = []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for i in range(frame_count):\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            return frames\n",
    "\n",
    "        # Save the frame to the list\n",
    "        frames.append(frame)\n",
    "        \n",
    "    if not frames:\n",
    "        print(\"No frames were saved.\")\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b583199",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "Frames = get_frames(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebe817",
   "metadata": {},
   "source": [
    "# Delete PNG Files in Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d6ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_png_files(directory_path):\n",
    "    # List all files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            # Check if it's a PNG file and remove it\n",
    "            if os.path.isfile(file_path) and filename.lower().endswith('.png'):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede69437",
   "metadata": {},
   "source": [
    "# Read and Save Frames in Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b194d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames_as_vid(frames, frame_folder):\n",
    "    # Create the folder to save frames if it doesn't exist\n",
    "    if not os.path.exists(frame_folder):\n",
    "        os.makedirs(frame_folder)\n",
    "\n",
    "    frame_count = 0\n",
    "    for i in range(len(frames)):\n",
    "        # Save the frame as an image file\n",
    "        frame_filename = os.path.join(frame_folder, f'frame_{frame_count:03d}.png')\n",
    "        cv2.imwrite(frame_filename, frames[i])\n",
    "        frame_count += 1\n",
    "\n",
    "    #if not frames:\n",
    "         #print(\"No frames were saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b8834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_png_files('saved_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdfecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_frames_as_vid(Frames[50:100],\"saved_frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2226b4f",
   "metadata": {},
   "source": [
    "# Create Video with Set of Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02382bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vid(frames,output_file,fps):\n",
    "    # Get frame dimensions\n",
    "    height, width, _ = frames[0].shape\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "    # Write the frames to the new video file\n",
    "    [out.write(frame) for frame in frames];\n",
    "\n",
    "    # Release the video writer object\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ae5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_vid(Frames[100:150], \"slice_vid.mp4\", original_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b77b38",
   "metadata": {},
   "source": [
    "# Change FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0048804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_vid(Frames[100:150],\"slice_vid_new_fps.mp4\",12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043aa120",
   "metadata": {},
   "source": [
    "# Play Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3606cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_frames(frames,fps):\n",
    "    \n",
    "    delay = int(1000/fps)\n",
    "    print(\"Delay: \",delay)\n",
    "\n",
    "    for frame in frames:\n",
    "        # Display the frame\n",
    "        cv2.imshow('Video Playback', frame)\n",
    "        # Exit the playback if 'q' is pressed\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "655f7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_frames(Frames[:100],24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b240f8bb",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2f62d",
   "metadata": {},
   "source": [
    "## Farneback Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c4096e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFM(frames):\n",
    "    \n",
    "    OF = [] \n",
    "    #Convert to Grayscale\n",
    "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for i in range(len(frames)-1):\n",
    "        #Convert the next frame to grayscale\n",
    "        next_gray = cv2.cvtColor(frames[i+1], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5,  3,  10,  10,    5,    1.2,   0)\n",
    "                                            #prev      next       flow  dist lvl  win  it  smooth  std   flag \n",
    " \n",
    "        # Visualize the optical flow\n",
    "        hsv = np.zeros_like(frames[i]) #[ch0,ch1,ch2]\n",
    "        hsv[..., 1] = 255 #ch1 Saturation (Full)\n",
    "\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1]) #Cartesian to Polar\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2  \n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX) #Normalize from 0 to 255\n",
    "        flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)   #Convert to RBG\n",
    "        OF.append(flow_rgb)\n",
    "        \n",
    "        flow_M  = flow[...,0]+flow[...,1]\n",
    "        \n",
    "        # Display the original frame and the optical flow\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        cv2.imshow('Optical Flow', flow_rgb)\n",
    "        cv2.imshow('Optical Flow Mag',flow_M)\n",
    "\n",
    "        # Wait for a key press to move to the next frame\n",
    "        if cv2.waitKey(0) & 0xFF==ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update the previous frame and grayscale image\n",
    "        prev_gray = next_gray\n",
    "\n",
    "    # Release the video capture object and close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c56a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optical_R = OFM(Frames[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61010af4",
   "metadata": {},
   "source": [
    "## Farneack with Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "365002c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_optical_flow_vectors(flow, frame, step):\n",
    "    h, w = frame.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    # Create a mask to draw the vectors\n",
    "    mask = np.zeros_like(frame)\n",
    "    \n",
    "    # Create line endpoints\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    # Draw lines and circles\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.line(mask, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "        cv2.circle(frame, (x1, y1), 1, (0, 255, 0), -1)\n",
    "\n",
    "    return cv2.add(frame, mask)\n",
    "\n",
    "def OFV(frames,step):\n",
    "    OF = []\n",
    "    \n",
    "    #convert it to grayscale\n",
    "    prev_gray = cv2.cvtColor(np.copy(frames[0]), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for i in range(1,len(frames)):\n",
    "        # next frame convert it to grayscale\n",
    "        next_gray = cv2.cvtColor(np.copy(frames[i]), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # Draw the optical flow vectors on the frame\n",
    "        flow_frame = draw_optical_flow_vectors(flow, np.copy(frames[i]),step)\n",
    "        OF.append(flow)\n",
    "        \n",
    "        # Display the original frame with optical flow vectors\n",
    "        cv2.imshow('Prev Frame',frames[i-1])\n",
    "        cv2.imshow('Next Frame',frames[i])\n",
    "        cv2.imshow('Optical Flow Vectors', flow_frame)\n",
    "\n",
    "        # Wait for a key press to move to the next frame\n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update the previous frame and grayscale image\n",
    "        prev_gray = next_gray\n",
    "\n",
    "    # Release the video capture object and close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f531435",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optical_V = OFV(Frames[100:150],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36773838",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "162a20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFLK(frames,step_size):\n",
    "    OF = []\n",
    "    # Parameters for the Lucas-Kanade optical flow\n",
    "    lk_params = dict(winSize=(step_size, step_size), maxLevel=3, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Take the first frame and convert it to grayscale\n",
    "    old_frame = np.copy(frames[0])\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create a grid of points to track\n",
    "    grid_y, grid_x = np.mgrid[0:old_gray.shape[0]:step_size, 0:old_gray.shape[1]:step_size]\n",
    "    p0 = np.vstack((grid_x.ravel(), grid_y.ravel())).T.astype(np.float32).reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "    for i in range(1, len(frames)):\n",
    "        frame = np.copy(frames[i])\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "\n",
    "        # Draw the normalized vectors\n",
    "        for j, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            # Calculate vector components\n",
    "            dx = a - c\n",
    "            dy = b - d\n",
    "            # Normalize vector\n",
    "            magnitude = np.sqrt(dx**2 + dy**2)\n",
    "            if magnitude > 0:\n",
    "                dx /= magnitude\n",
    "                dy /= magnitude\n",
    "            # Scale vector for visualization\n",
    "            scale = 10  # Adjust this value for smaller or larger arrows\n",
    "            a = int(c + dx * scale)\n",
    "            b = int(d + dy * scale)\n",
    "            frame = cv2.arrowedLine(frame, (int(c), int(d)), (a, b), (0, 255, 0), 1, tipLength=0.5)\n",
    "            OF.append(frame)\n",
    "        \n",
    "        cv2.imshow('Prev',frames[i-1])\n",
    "        cv2.imshow('Next',frames[i])\n",
    "        cv2.imshow('Optical Flow Vectors', frame)\n",
    "        \n",
    "        if cv2.waitKey(0) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0cd14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optical_KL = OFLK(Frames[100:150],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3476b65",
   "metadata": {},
   "source": [
    "## Phase Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db8b5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PhaseC(frames, block_size=20, grid_step=20):\n",
    "    OF = []\n",
    "\n",
    "    for i in range(len(frames) - 1):\n",
    "        prev_frame = frames[i]\n",
    "        next_frame = frames[i + 1]\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Create an image to visualize the flow\n",
    "        flow_img = cv2.cvtColor(prev_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Iterate over the grid\n",
    "        for y in range(0, prev_gray.shape[0] - block_size, grid_step):\n",
    "            for x in range(0, prev_gray.shape[1] - block_size, grid_step):\n",
    "                # Extract the blocks\n",
    "                prev_block = prev_gray[y:y + block_size, x:x + block_size]\n",
    "                next_block = next_gray[y:y + block_size, x:x + block_size]\n",
    "\n",
    "                # Compute phase correlation\n",
    "                shift, _ = cv2.phaseCorrelate(prev_block.astype(np.float32), next_block.astype(np.float32))\n",
    "                dx, dy = shift\n",
    "\n",
    "                # Scale down the length of the arrows and size of the tips\n",
    "                scale = 5\n",
    "                tip_length = 0.2\n",
    "\n",
    "                # Draw the vector on the flow image\n",
    "                cv2.arrowedLine(flow_img, (x + block_size // 2, y + block_size // 2), \n",
    "                                (int(x + block_size // 2 + dx * scale), int(y + block_size // 2 + dy * scale)), \n",
    "                                (0, 255, 0), 1, tipLength=tip_length)\n",
    "\n",
    "        OF.append(flow_img)\n",
    "\n",
    "        # Display the frames and the flow\n",
    "        cv2.imshow('Previous Frame', prev_frame)\n",
    "        cv2.imshow('Next Frame', next_frame)\n",
    "        cv2.imshow('Optical Flow', flow_img)\n",
    "\n",
    "        # Wait for key press to proceed to the next frame\n",
    "        if cv2.waitKey(0) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c33dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optical_PC = PhaseC(Frames[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a49c1",
   "metadata": {},
   "source": [
    "# Frames Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee32b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_dif(frames, threshold=30):\n",
    "    D = []\n",
    "    prev_frame = frames[0]\n",
    "\n",
    "    for i in range(1,len(frames)):\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "        # Compute absolute difference between frames\n",
    "        diff = cv2.absdiff(prev_gray, curr_gray)\n",
    "              \n",
    "        # Create a mask to highlight pixels with significant changes\n",
    "        mask = np.zeros_like(diff)\n",
    "        mask[diff > threshold] = 255\n",
    "        D.append(mask)\n",
    "        # Show original frame and mask\n",
    "        cv2.imshow('Original Frame', frames[i])\n",
    "        cv2.imshow('Pixels with Most Changes', mask)\n",
    "        if cv2.waitKey(0) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "        prev_frame = frames[i]\n",
    "\n",
    "    # Release the video capture object\n",
    "    cv2.destroyAllWindows()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf9b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dif = frame_dif(Frames[200:250],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56cc4c",
   "metadata": {},
   "source": [
    "# Change Color Channel's Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93021814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_range_colors(image, min_vals=(0, 0, 0), max_vals=(255, 255, 255)):\n",
    "    # Split the image into its BGR channels\n",
    "    b, g, r = cv2.split(image)\n",
    "    \n",
    "    # Clip each channel to its respective range\n",
    "    b = np.clip(b, min_vals[0], max_vals[0])\n",
    "    g = np.clip(g, min_vals[1], max_vals[1])\n",
    "    r = np.clip(r, min_vals[2], max_vals[2])\n",
    "    \n",
    "    # Merge the channels back together\n",
    "    new_image = cv2.merge((b, g, r))\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "429eac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nframe = change_range_colors(Frames[100],(0,50,100),(250,200,250))\n",
    "cv2.imshow('original',Frames[100])\n",
    "cv2.imshow('changed',Nframe)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff713494",
   "metadata": {},
   "source": [
    "# Add Occlusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c499259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusions(image, num_occlusions):    \n",
    "    output_image = np.copy(image)\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Draw random occlusions on the image\n",
    "    for _ in range(num_occlusions):\n",
    "        shape_type = random.choice(['rectangle', 'circle'])\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))  # Random color\n",
    "        \n",
    "        if shape_type == 'rectangle':\n",
    "            x = random.randint(0, width - 1)\n",
    "            y = random.randint(0, height - 1)\n",
    "            width_rect = random.randint(10, 100)\n",
    "            height_rect = random.randint(10, 100)\n",
    "            cv2.rectangle(output_image, (x, y), (x + width_rect, y + height_rect), color, -1)  # Filled rectangle\n",
    "        \n",
    "        elif shape_type == 'circle':\n",
    "            center = (random.randint(0, width - 1), random.randint(0, height - 1))\n",
    "            radius = random.randint(5, 50)\n",
    "            cv2.circle(output_image, center, radius, color, -1)  # Filled circle\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9588f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_img = occlusions(Frames[100], 1)\n",
    "\n",
    "cv2.imshow('Original Image', Frames[100])\n",
    "cv2.imshow('Image with Occlusions', cv2.cvtColor(New_img,cv2.COLOR_BGR2RGB))\n",
    "cv2.imshow('Image with Occlusions1', New_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c41b9",
   "metadata": {},
   "source": [
    "# Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5761f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(I):\n",
    "    cv2.imshow('I', I)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23828fc",
   "metadata": {},
   "source": [
    "# Read Images in a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6fec59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(directory_path):\n",
    "    images = []\n",
    "    # List all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the file has a PNG extension\n",
    "        if filename.lower().endswith('.png'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Read the image using OpenCV\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)  # cv2.IMREAD_UNCHANGED to keep the alpha channel if present\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "            else:\n",
    "                print(f\"Failed to read image: {file_path}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767dfb2",
   "metadata": {},
   "source": [
    "# Draw Random Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1173e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_lines(image, num_lines):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "\n",
    "    for _ in range(num_lines):\n",
    "        # Generate random start point\n",
    "        start_point = (random.randint(0, width-1), random.randint(0, height-1))\n",
    "        \n",
    "        # Generate a random angle and length for the line\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "        length = random.randint(1, min(width, height) // 2)  # Limit length to half of the smallest dimension\n",
    "        \n",
    "        # Calculate the end point using the angle and length\n",
    "        end_point = (int(start_point[0] + length * np.cos(angle)), \n",
    "                     int(start_point[1] + length * np.sin(angle)))\n",
    "        \n",
    "        # Ensure the end point is within the image boundaries\n",
    "        end_point = (min(max(end_point[0], 0), width-1), min(max(end_point[1], 0), height-1))\n",
    "        \n",
    "        # Generate a random color (BGR format)\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        \n",
    "        # Generate a random thickness for the line\n",
    "        thickness = random.randint(1, 10)\n",
    "        \n",
    "        # Draw the line on the image\n",
    "        cv2.line(output_image, start_point, end_point, color, thickness)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b24219",
   "metadata": {},
   "source": [
    "# Random Region's Color Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "376660c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_regions(image, num_regions):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "\n",
    "    for _ in range(num_regions):\n",
    "        # Generate random region shape and size\n",
    "        region_shape = random.choice(['rectangle', 'ellipse'])\n",
    "        \n",
    "        if region_shape == 'rectangle':\n",
    "            region_width = random.randint(10, width // 3)\n",
    "            region_height = random.randint(10, height // 3)\n",
    "            top_left_x = random.randint(0, width - region_width)\n",
    "            top_left_y = random.randint(0, height - region_height)\n",
    "            \n",
    "            # Define the region\n",
    "            region = output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width]\n",
    "        \n",
    "        elif region_shape == 'ellipse':\n",
    "            center_x = random.randint(width // 3, width - width // 3)\n",
    "            center_y = random.randint(height // 3, height - height // 3)\n",
    "            axis_length = (random.randint(10, width // 3), random.randint(10, height // 3))\n",
    "            angle = random.randint(0, 360)\n",
    "            start_angle = 0\n",
    "            end_angle = 360\n",
    "\n",
    "            # Create a mask for the ellipse\n",
    "            mask = np.zeros((height, width), dtype=np.uint8)\n",
    "            cv2.ellipse(mask, (center_x, center_y), axis_length, angle, start_angle, end_angle, 255, -1)\n",
    "            \n",
    "            # Extract the region using the mask\n",
    "            region = cv2.bitwise_and(output_image, output_image, mask=mask)\n",
    "\n",
    "        # Change color channels within the region\n",
    "        for channel in range(3):  # Assuming BGR format\n",
    "            # Generate random ranges for the color channel\n",
    "            low = random.randint(0, 255)\n",
    "            high = random.randint(low, 255)\n",
    "            if region_shape == 'rectangle':\n",
    "                region[..., channel] = np.clip(region[..., channel], low, high)\n",
    "            elif region_shape == 'ellipse':\n",
    "                # Apply changes to the region using the mask\n",
    "                channel_region = output_image[..., channel]\n",
    "                channel_region[mask == 255] = np.clip(channel_region[mask == 255], low, high)\n",
    "                output_image[..., channel] = channel_region\n",
    "\n",
    "        if region_shape == 'rectangle':\n",
    "            # Place the modified region back into the image for rectangles\n",
    "            output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width] = region\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30302f",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b9565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width:  640\n",
      "Height:  360\n",
      "Original FPS:  23.976023976023978\n",
      "Frame Count:  3458\n"
     ]
    }
   ],
   "source": [
    "file = 'VDB\\J.mp4'\n",
    "cap = open_vid(file)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Width: \",width)\n",
    "print(\"Height: \",height)\n",
    "print(\"Original FPS: \",original_fps)\n",
    "print(\"Frame Count: \",frame_count)\n",
    "Frames = get_frames(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f9cca",
   "metadata": {},
   "source": [
    "## With Oclussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e117e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = cv2.cvtColor(occlusions(F[115],1),cv2.COLOR_BGR2RGB)\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cffacc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  41\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],original_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9bf0014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  100\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e910932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  20\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c420e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9684ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66c5a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b6e9a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e2efe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(F[100:130])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc23f4c",
   "metadata": {},
   "source": [
    "## With Color Change in Whole Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7fd1af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = change_range_colors(F[115],(0,50,100),(250,200,250))\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08af9cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  41\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],original_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d403d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  100\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "716e9963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  20\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79e18714",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51c02cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5a211b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d8dc9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4c77a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(F[100:130])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4753991",
   "metadata": {},
   "source": [
    "## With Color Change in Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "56c968a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = rnd_regions(F[115],1)\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aae0d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "60cdb434",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d41ea313",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a22b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    " _ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "138f08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(F[100:130])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3786f87",
   "metadata": {},
   "source": [
    "# With Random Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ad68a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = rnd_lines(F[115],1)\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1474e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e4b1a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a2488f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "275fd160",
   "metadata": {},
   "outputs": [],
   "source": [
    " _ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b5499f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38ad9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
