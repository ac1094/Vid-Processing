{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e7874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "input_file = 'VDB\\D.mp4'   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f80d2",
   "metadata": {},
   "source": [
    "# Open Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e346cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_vid(input_file):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e86d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = open_vid(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be1cee",
   "metadata": {},
   "source": [
    "# Get Video Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941d154c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\\noriginal_fps = cap.get(cv2.CAP_PROP_FPS)\\nframe_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\\nprint(\"Width: \",width)\\nprint(\"Height: \",height)\\nprint(\"Original FPS: \",original_fps)\\nprint(\"Frame Count: \",frame_count)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Width: \",width)\n",
    "print(\"Height: \",height)\n",
    "print(\"Original FPS: \",original_fps)\n",
    "print(\"Frame Count: \",frame_count)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b91732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(cap):\n",
    "    frames = []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for i in range(frame_count):\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            return frames\n",
    "\n",
    "        # Save the frame to the list\n",
    "        frames.append(frame)\n",
    "        \n",
    "    if not frames:\n",
    "        print(\"No frames were saved.\")\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d63d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "#Frames = get_frames(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfadad5",
   "metadata": {},
   "source": [
    "# Delete PNG Files in Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4fd597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_png_files(directory_path):\n",
    "    # List all files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            # Check if it's a PNG file and remove it\n",
    "            if os.path.isfile(file_path) and filename.lower().endswith('.png'):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc80d16",
   "metadata": {},
   "source": [
    "# Read and Save Frames in Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0eb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(frames, frame_folder):\n",
    "    # Create the folder to save frames if it doesn't exist\n",
    "    if not os.path.exists(frame_folder):\n",
    "        os.makedirs(frame_folder)\n",
    "\n",
    "    frame_count = 0\n",
    "    for i in range(len(frames)):\n",
    "        # Save the frame as an image file\n",
    "        frame_filename = os.path.join(frame_folder, f'frame_{frame_count:03d}.png')\n",
    "        cv2.imwrite(frame_filename, frames[i])\n",
    "        frame_count += 1\n",
    "\n",
    "    #if not frames:\n",
    "         #print(\"No frames were saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b936e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_png_files('saved_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2b24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_frames(Frames[50:100],\"saved_frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7250164",
   "metadata": {},
   "source": [
    "# Create Video with Set of Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1aba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vid(frames,output_file,fps):\n",
    "    # Get frame dimensions\n",
    "    height, width, _ = frames[0].shape\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "    # Write the frames to the new video file\n",
    "    [out.write(frame) for frame in frames];\n",
    "\n",
    "    # Release the video writer object\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "073bb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_vid(Frames[100:150], \"slice_vid.mp4\", original_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2289c62",
   "metadata": {},
   "source": [
    "# Change FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32caf760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_vid(Frames[100:150],\"slice_vid_new_fps.mp4\",12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44b37a",
   "metadata": {},
   "source": [
    "# Play Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f8dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_frames(frames,fps):\n",
    "    \n",
    "    delay = int(1000/fps)\n",
    "    print(\"Delay: \",delay)\n",
    "\n",
    "    for frame in frames:\n",
    "        # Display the frame\n",
    "        cv2.imshow('Video Playback', frame)\n",
    "        # Exit the playback if 'q' is pressed\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63c1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_frames(Frames[:100],24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1350bef",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0c903",
   "metadata": {},
   "source": [
    "## Farneback Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35cc4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFM(frames):\n",
    "    \n",
    "    OF = [] \n",
    "    #Convert to Grayscale\n",
    "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for i in range(len(frames)-1):\n",
    "        #Convert the next frame to grayscale\n",
    "        next_gray = cv2.cvtColor(frames[i+1], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5,  3,  10,  10,    5,    1.2,   0)\n",
    "                                            #prev      next       flow  dist lvl  win  it  smooth  std   flag \n",
    " \n",
    "        # Visualize the optical flow\n",
    "        hsv = np.zeros_like(frames[i]) #[ch0,ch1,ch2]\n",
    "        if len(hsv.shape) != 3 or  hsv.shape[2] != 3:\n",
    "            hsv = np.zeros(frames[i].shape[0],frames[i].shape[1],3)\n",
    "        hsv[..., 1] = 255 #ch1 Saturation (Full)\n",
    "\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1]) #Cartesian to Polar\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2  \n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX) #Normalize from 0 to 255\n",
    "        flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)   #Convert to RBG\n",
    "        OF.append(flow_rgb)\n",
    "        \n",
    "        flow_M  = flow[...,0]+flow[...,1]\n",
    "        \n",
    "        # Display the original frame and the optical flow\n",
    "        cv2.imshow('Prev Frame', frames[i])\n",
    "        cv2.imshow('Next Frame', frames[i+1])\n",
    "        cv2.imshow('Optical Flow', flow_rgb)\n",
    "        cv2.imshow('Optical Flow Mag',flow_M)\n",
    "\n",
    "        # Wait for a key press to move to the next frame\n",
    "        if cv2.waitKey(0) & 0xFF==ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update the previous frame and grayscale image\n",
    "        prev_gray = next_gray\n",
    "\n",
    "    # Release the video capture object and close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b54f51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optical_R = OFM(Frames[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63f1b0",
   "metadata": {},
   "source": [
    "## Farneack with Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e64a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_optical_flow_vectors(flow, frame, step):\n",
    "    h, w = frame.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    # Create a mask to draw the vectors\n",
    "    mask = np.zeros_like(frame)\n",
    "    \n",
    "    # Create line endpoints\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    # Draw lines and circles\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.line(mask, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "        cv2.circle(frame, (x1, y1), 1, (0, 255, 0), -1)\n",
    "\n",
    "    return cv2.add(frame, mask)\n",
    "\n",
    "def OFV(frames,step):\n",
    "    OF = []\n",
    "    \n",
    "    #convert it to grayscale\n",
    "    prev_gray = cv2.cvtColor(np.copy(frames[0]), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for i in range(1,len(frames)):\n",
    "        # next frame convert it to grayscale\n",
    "        next_gray = cv2.cvtColor(np.copy(frames[i]), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate the dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # Draw the optical flow vectors on the frame\n",
    "        flow_frame = draw_optical_flow_vectors(flow, np.copy(frames[i]),step)\n",
    "        OF.append(flow)\n",
    "        \n",
    "        # Display the original frame with optical flow vectors\n",
    "        cv2.imshow('Prev Frame',frames[i-1])\n",
    "        cv2.imshow('Next Frame',frames[i])\n",
    "        cv2.imshow('Optical Flow Vectors', flow_frame)\n",
    "\n",
    "        # Wait for a key press to move to the next frame\n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update the previous frame and grayscale image\n",
    "        prev_gray = next_gray\n",
    "\n",
    "    # Release the video capture object and close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c255b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optical_V = OFV(Frames[100:150],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2eb4c4",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ef32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFLK(frames,step_size):\n",
    "    OF = []\n",
    "    # Parameters for the Lucas-Kanade optical flow\n",
    "    lk_params=dict(winSize=(step_size,step_size),maxLevel=3,criteria=(cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_COUNT,10, 0.03))\n",
    "\n",
    "    # Take the first frame and convert it to grayscale\n",
    "    old_frame = np.copy(frames[0])\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create a grid of points to track\n",
    "    grid_y, grid_x = np.mgrid[0:old_gray.shape[0]:step_size, 0:old_gray.shape[1]:step_size]\n",
    "    p0 = np.vstack((grid_x.ravel(), grid_y.ravel())).T.astype(np.float32).reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "    for i in range(1, len(frames)):\n",
    "        frame = np.copy(frames[i])\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "\n",
    "        # Draw the normalized vectors\n",
    "        for j, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            # Calculate vector components\n",
    "            dx = a - c\n",
    "            dy = b - d\n",
    "            # Normalize vector\n",
    "            magnitude = np.sqrt(dx**2 + dy**2)\n",
    "            if magnitude > 0:\n",
    "                dx /= magnitude\n",
    "                dy /= magnitude\n",
    "            # Scale vector for visualization\n",
    "            scale = 10  # Adjust this value for smaller or larger arrows\n",
    "            a = int(c + dx * scale)\n",
    "            b = int(d + dy * scale)\n",
    "            frame = cv2.arrowedLine(frame, (int(c), int(d)), (a, b), (0, 255, 0), 1, tipLength=0.5)\n",
    "            OF.append(frame)\n",
    "        \n",
    "        cv2.imshow('Prev',frames[i-1])\n",
    "        cv2.imshow('Next',frames[i])\n",
    "        cv2.imshow('Optical Flow Vectors', frame)\n",
    "        \n",
    "        if cv2.waitKey(0) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f53fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optical_KL = OFLK(Frames[100:150],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b0f07",
   "metadata": {},
   "source": [
    "## Phase Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "720847e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PhaseC(frames, block_size=20, grid_step=20):\n",
    "    OF = []\n",
    "\n",
    "    for i in range(len(frames) - 1):\n",
    "        prev_frame = frames[i]\n",
    "        next_frame = frames[i + 1]\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Create an image to visualize the flow\n",
    "        flow_img = cv2.cvtColor(prev_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Iterate over the grid\n",
    "        for y in range(0, prev_gray.shape[0] - block_size, grid_step):\n",
    "            for x in range(0, prev_gray.shape[1] - block_size, grid_step):\n",
    "                # Extract the blocks\n",
    "                prev_block = prev_gray[y:y + block_size, x:x + block_size]\n",
    "                next_block = next_gray[y:y + block_size, x:x + block_size]\n",
    "\n",
    "                # Compute phase correlation\n",
    "                shift, _ = cv2.phaseCorrelate(prev_block.astype(np.float32), next_block.astype(np.float32))\n",
    "                dx, dy = shift\n",
    "\n",
    "                # Scale down the length of the arrows and size of the tips\n",
    "                scale = 5\n",
    "                tip_length = 0.2\n",
    "\n",
    "                # Draw the vector on the flow image\n",
    "                cv2.arrowedLine(flow_img, (x + block_size // 2, y + block_size // 2), \n",
    "                                (int(x + block_size // 2 + dx * scale), int(y + block_size // 2 + dy * scale)), \n",
    "                                (0, 255, 0), 1, tipLength=tip_length)\n",
    "\n",
    "        OF.append(flow_img)\n",
    "\n",
    "        # Display the frames and the flow\n",
    "        cv2.imshow('Previous Frame', prev_frame)\n",
    "        cv2.imshow('Next Frame', next_frame)\n",
    "        cv2.imshow('Optical Flow', flow_img)\n",
    "\n",
    "        # Wait for key press to proceed to the next frame\n",
    "        if cv2.waitKey(0) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dcb0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optical_PC = PhaseC(Frames[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ac9b4",
   "metadata": {},
   "source": [
    "# Frames Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7f2c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_dif(frames, threshold=30):\n",
    "    D = []\n",
    "    prev_frame = frames[0]\n",
    "\n",
    "    for i in range(1,len(frames)):\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "        # Compute absolute difference between frames\n",
    "        diff = cv2.absdiff(prev_gray, curr_gray)\n",
    "              \n",
    "        # Create a mask to highlight pixels with significant changes\n",
    "        mask = np.zeros_like(diff)\n",
    "        mask[diff > threshold] = 255\n",
    "        D.append(mask)\n",
    "        # Show original frame and mask\n",
    "        cv2.imshow('Original Frame', frames[i])\n",
    "        cv2.imshow('Pixels with Most Changes', mask)\n",
    "        if cv2.waitKey(0) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "        prev_frame = frames[i]\n",
    "\n",
    "    # Release the video capture object\n",
    "    cv2.destroyAllWindows()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b5f8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dif = frame_dif(Frames[200:250],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d0993",
   "metadata": {},
   "source": [
    "# Change Color Channel's Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1a5da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_range_colors(image, min_vals=(0, 0, 0), max_vals=(255, 255, 255)):\n",
    "    # Split the image into its BGR channels\n",
    "    b, g, r = cv2.split(image)\n",
    "    \n",
    "    # Clip each channel to its respective range\n",
    "    b = np.clip(b, min_vals[0], max_vals[0])\n",
    "    g = np.clip(g, min_vals[1], max_vals[1])\n",
    "    r = np.clip(r, min_vals[2], max_vals[2])\n",
    "    \n",
    "    # Merge the channels back together\n",
    "    new_image = cv2.merge((b, g, r))\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17954056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Nframe = change_range_colors(Frames[100],(0,50,100),(250,200,250))\\ncv2.imshow(\\'original\\',Frames[100])\\ncv2.imshow(\\'changed\\',Nframe)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"Nframe = change_range_colors(Frames[100],(0,50,100),(250,200,250))\n",
    "cv2.imshow('original',Frames[100])\n",
    "cv2.imshow('changed',Nframe)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713e7d8",
   "metadata": {},
   "source": [
    "# Add Occlusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0df1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusions(image, num_occlusions):    \n",
    "    output_image = np.copy(image)\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Draw random occlusions on the image\n",
    "    for _ in range(num_occlusions):\n",
    "        shape_type = random.choice(['rectangle', 'circle'])\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))  # Random color\n",
    "        \n",
    "        if shape_type == 'rectangle':\n",
    "            x = random.randint(0, width - 1)\n",
    "            y = random.randint(0, height - 1)\n",
    "            width_rect = random.randint(10, 100)\n",
    "            height_rect = random.randint(10, 100)\n",
    "            cv2.rectangle(output_image, (x, y), (x + width_rect, y + height_rect), color, -1)  # Filled rectangle\n",
    "        \n",
    "        elif shape_type == 'circle':\n",
    "            center = (random.randint(0, width - 1), random.randint(0, height - 1))\n",
    "            radius = random.randint(5, 50)\n",
    "            cv2.circle(output_image, center, radius, color, -1)  # Filled circle\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3309b0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"New_img = occlusions(Frames[100], 1)\\n\\ncv2.imshow('Original Image', Frames[100])\\ncv2.imshow('Image with Occlusions', cv2.cvtColor(New_img,cv2.COLOR_BGR2RGB))\\ncv2.imshow('Image with Occlusions1', New_img)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"New_img = occlusions(Frames[100], 1)\n",
    "\n",
    "cv2.imshow('Original Image', Frames[100])\n",
    "cv2.imshow('Image with Occlusions', cv2.cvtColor(New_img,cv2.COLOR_BGR2RGB))\n",
    "cv2.imshow('Image with Occlusions1', New_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c02d68",
   "metadata": {},
   "source": [
    "# Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "722318f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(I):\n",
    "    cv2.imshow('I', I)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59151e8e",
   "metadata": {},
   "source": [
    "# Read Images in a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beb235c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(directory_path):\n",
    "    images = []\n",
    "    # List all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the file has a PNG extension\n",
    "        if filename.lower().endswith('.png'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Read the image using OpenCV\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)  # cv2.IMREAD_UNCHANGED to keep the alpha channel if present\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "            else:\n",
    "                print(f\"Failed to read image: {file_path}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330b447",
   "metadata": {},
   "source": [
    "# Draw Random Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f94f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_lines(image, num_lines):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "\n",
    "    for _ in range(num_lines):\n",
    "        # Generate random start point\n",
    "        start_point = (random.randint(0, width-1), random.randint(0, height-1))\n",
    "        \n",
    "        # Generate a random angle and length for the line\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "        length = random.randint(1, min(width, height) // 2)  # Limit length to half of the smallest dimension\n",
    "        \n",
    "        # Calculate the end point using the angle and length\n",
    "        end_point = (int(start_point[0] + length * np.cos(angle)), \n",
    "                     int(start_point[1] + length * np.sin(angle)))\n",
    "        \n",
    "        # Ensure the end point is within the image boundaries\n",
    "        end_point = (min(max(end_point[0], 0), width-1), min(max(end_point[1], 0), height-1))\n",
    "        \n",
    "        # Generate a random color (BGR format)\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        \n",
    "        # Generate a random thickness for the line\n",
    "        thickness = random.randint(1, 10)\n",
    "        \n",
    "        # Draw the line on the image\n",
    "        cv2.line(output_image, start_point, end_point, color, thickness)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d278d4b",
   "metadata": {},
   "source": [
    "# Random Region's Color Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "517ff2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_regions(image, num_regions):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Copy the image to avoid modifying the original\n",
    "    output_image = image.copy()\n",
    "\n",
    "    for _ in range(num_regions):\n",
    "        # Generate random region shape and size\n",
    "        region_shape = random.choice(['rectangle', 'ellipse'])\n",
    "        \n",
    "        if region_shape == 'rectangle':\n",
    "            region_width = random.randint(10, width // 3)\n",
    "            region_height = random.randint(10, height // 3)\n",
    "            top_left_x = random.randint(0, width - region_width)\n",
    "            top_left_y = random.randint(0, height - region_height)\n",
    "            \n",
    "            # Define the region\n",
    "            region = output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width]\n",
    "        \n",
    "        elif region_shape == 'ellipse':\n",
    "            center_x = random.randint(width // 3, width - width // 3)\n",
    "            center_y = random.randint(height // 3, height - height // 3)\n",
    "            axis_length = (random.randint(10, width // 3), random.randint(10, height // 3))\n",
    "            angle = random.randint(0, 360)\n",
    "            start_angle = 0\n",
    "            end_angle = 360\n",
    "\n",
    "            # Create a mask for the ellipse\n",
    "            mask = np.zeros((height, width), dtype=np.uint8)\n",
    "            cv2.ellipse(mask, (center_x, center_y), axis_length, angle, start_angle, end_angle, 255, -1)\n",
    "            \n",
    "            # Extract the region using the mask\n",
    "            region = cv2.bitwise_and(output_image, output_image, mask=mask)\n",
    "\n",
    "        # Change color channels within the region\n",
    "        for channel in range(3):  # Assuming BGR format\n",
    "            # Generate random ranges for the color channel\n",
    "            low = random.randint(0, 255)\n",
    "            high = random.randint(low, 255)\n",
    "            if region_shape == 'rectangle':\n",
    "                region[..., channel] = np.clip(region[..., channel], low, high)\n",
    "            elif region_shape == 'ellipse':\n",
    "                # Apply changes to the region using the mask\n",
    "                channel_region = output_image[..., channel]\n",
    "                channel_region[mask == 255] = np.clip(channel_region[mask == 255], low, high)\n",
    "                output_image[..., channel] = channel_region\n",
    "\n",
    "        if region_shape == 'rectangle':\n",
    "            # Place the modified region back into the image for rectangles\n",
    "            output_image[top_left_y:top_left_y + region_height, top_left_x:top_left_x + region_width] = region\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66716b",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "220ba770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width:  640\n",
      "Height:  360\n",
      "Original FPS:  24.0\n",
      "Frame Count:  4755\n"
     ]
    }
   ],
   "source": [
    "file = 'VDB\\R.mp4'\n",
    "cap = open_vid(file)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Width: \",width)\n",
    "print(\"Height: \",height)\n",
    "print(\"Original FPS: \",original_fps)\n",
    "print(\"Frame Count: \",frame_count)\n",
    "Frames = get_frames(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6264e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  41\n"
     ]
    }
   ],
   "source": [
    "play_frames(Frames[600:1000],24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e9e5e",
   "metadata": {},
   "source": [
    "## With Oclussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c98adc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = cv2.cvtColor(occlusions(F[115],1),cv2.COLOR_BGR2RGB)\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3d90766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  40\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],original_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f036d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  100\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c02779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  20\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bbea20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(Frames[600:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c51b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(Frames[:300],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c796cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(Frames[200:400],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc107df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e5bf92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(Frames[:300]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdab3d5",
   "metadata": {},
   "source": [
    "## With Color Change in Whole Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d3e936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = change_range_colors(F[115],(0,50,100),(250,200,250))\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfe6f12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  41\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],original_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71f507ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  100\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3bd62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  20\n"
     ]
    }
   ],
   "source": [
    "play_frames(F[100:130],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ae323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dce05f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "329c57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ca6ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d429ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(Frames[300:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c930bb7",
   "metadata": {},
   "source": [
    "## With Color Change in Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "737b06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = rnd_regions(F[115],1)\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df37f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07b43550",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0aba147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "738bd260",
   "metadata": {},
   "outputs": [],
   "source": [
    " _ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aba9277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(F[100:130])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb10c5",
   "metadata": {},
   "source": [
    "# With Random Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a00df586",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = Frames.copy()\n",
    "F[115] = rnd_lines(F[115],5)\n",
    "display_frame(F[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "288e8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "865782e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(F[100:130],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dee18c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(F[100:130],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3030d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    " _ = PhaseC(F[100:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4307898",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(F[100:130])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297b8e6",
   "metadata": {},
   "source": [
    "# Manual Alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cdf6bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_png_files('saved_frames')\n",
    "#save_frames(Frames[100:130],\"saved_frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "745171c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = read_images('saved_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13e72158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:  41\n"
     ]
    }
   ],
   "source": [
    "play_frames(K,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "890ea511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640, 4)\n",
      "(360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print(K[15].shape)\n",
    "K[15] = K[15][:,:,:3]\n",
    "print(K[15].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3be144c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFM(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12081709",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFV(K,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7bd646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = OFLK(K,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b185b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    " _ = PhaseC(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0633e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = frame_dif(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f032b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suma de vectores\n",
    "#Usar flechas para ir hacia adelante y atras\n",
    "#CHecar moviemiento de camara en vectores\n",
    "#calcular norma de suma de vectores\n",
    "#Cuales excenas son de acercamiento o alejamiento o que tipo de movimiento de camara\n",
    "#ruido en frames consecutivos\n",
    "#Separar en cada canal de color\n",
    "#Checar movimiento de siluetas\n",
    "#Manipulacion de camara, dif movimientos (horizontal,vertical,etc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
