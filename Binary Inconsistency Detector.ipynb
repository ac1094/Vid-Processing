{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "48f85731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Functions import *\n",
    "import torch.nn.functional as Fun\n",
    "import torch\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b627a7",
   "metadata": {},
   "source": [
    "# Add Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c86ad46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a random inconsistency\n",
    "def AddOneInc1(F):\n",
    "    # Convert to NumPy Array\n",
    "    F = F.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255\n",
    "    # Copy of original array\n",
    "    I = F.astype(np.uint8).copy()\n",
    "    # Random location\n",
    "    x, y = random.randint(0, 2 * I.shape[0] // 3), random.randint(0, 2 * I.shape[1] // 3)\n",
    "    # Random size\n",
    "    l = random.randint(5,I.shape[1]//20)\n",
    "    # Random option\n",
    "    Op = random.randint(0, 5)\n",
    "    if Op == 0:\n",
    "        I[x:x + l, y:y + l] = change_range_colors(I[x:x + l, y:y + l], (random.randint(30, 140), random.randint(30, 140), random.randint(30, 140)), (random.randint(150, 255), random.randint(150, 255), random.randint(150, 255)))\n",
    "    elif Op == 1:\n",
    "        R, G, B = random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)\n",
    "        I[x:x + l, y:y + l] = change_range_colors(I[x:x + l, y:y + l], (R, G, B), (R, G, B))\n",
    "    elif Op == 2:\n",
    "        Thick = random.randint(1, 10)\n",
    "        l2 = random.randint(5, I.shape[1]//15)\n",
    "        I = cv2.line(I, (x, y), (x + l, y + l2), (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)), Thick)\n",
    "    elif Op == 3:\n",
    "        Thick = random.randint(1, 5)\n",
    "        l2 = random.randint(5, I.shape[1]//20)\n",
    "        I = cv2.line(I, (x, y), (x + l, y + l2), (0, 0, 0), Thick)  \n",
    "    elif Op == 4:\n",
    "        I[x:x+l,y:y+l] = I[x:x+l,y:y+l] + np.random.random_integers(-10,10,I[x:x+l,y:y+l].shape)\n",
    "    else:\n",
    "        kernel = np.random.rand(3,3)\n",
    "        I[x:x+l,y:y+l] = cv2.filter2D(I[x:x+l,y:y+l],-1,kernel)\n",
    "    # Convert back to tensor\n",
    "    I_tensor = torch.tensor(I, dtype=torch.float32).permute(2, 0, 1)/255.0\n",
    "    return I_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7a9a9",
   "metadata": {},
   "source": [
    "# Calculate OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "340a1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OF(img1: torch.Tensor, img2: torch.Tensor, alpha: float = 1.0, iterations: int = 100):\n",
    "    assert img1.shape == img2.shape, \"Images must have the same shape\"\n",
    "    # Convert to grayscale to simplify optical flow calculation\n",
    "    def rgb_to_grayscale(img):\n",
    "        return 0.2989 * img[0, :, :] + 0.5870 * img[1, :, :] + 0.1140 * img[2, :, :]\n",
    "\n",
    "    I1 = rgb_to_grayscale(img1)\n",
    "    I2 = rgb_to_grayscale(img2)\n",
    "\n",
    "    # Initialize optical flow vectors (u for x direction, v for y direction)\n",
    "    u = torch.zeros_like(I1, requires_grad=True)\n",
    "    v = torch.zeros_like(I1, requires_grad=True)\n",
    "    \n",
    "    # Define convolution kernels for gradients\n",
    "    kernel_x = torch.tensor([[[[-1, 1], [-1, 1]]]], dtype=torch.float32)\n",
    "    kernel_y = torch.tensor([[[[-1, -1], [1, 1]]]], dtype=torch.float32)\n",
    "\n",
    "    # Compute gradients with padding that maintains the original image size\n",
    "    Ix = Fun.conv2d(I1.unsqueeze(0).unsqueeze(0), kernel_x, padding=(0, 1)).squeeze(0).squeeze(0)\n",
    "    Iy = Fun.conv2d(I1.unsqueeze(0).unsqueeze(0), kernel_y, padding=(1, 0)).squeeze(0).squeeze(0)\n",
    "    It = I2 - I1  # Temporal gradient\n",
    "\n",
    "    # Ensure all tensors have matching dimensions by cropping to the smallest dimensions\n",
    "    min_h = min(Ix.shape[-2], Iy.shape[-2], It.shape[-2], I1.shape[-2])\n",
    "    min_w = min(Ix.shape[-1], Iy.shape[-1], It.shape[-1], I1.shape[-1])\n",
    "\n",
    "    # No additional indexing needed here\n",
    "    Ix = Ix[:min_h, :min_w]\n",
    "    Iy = Iy[:min_h, :min_w]\n",
    "    It = It[:min_h, :min_w]\n",
    "    u = u[:min_h, :min_w]\n",
    "    v = v[:min_h, :min_w]\n",
    "\n",
    "    # Iteratively update the optical flow\n",
    "    for _ in range(iterations):\n",
    "        # Average flow in the neighborhood\n",
    "        u_avg = Fun.avg_pool2d(u.unsqueeze(0).unsqueeze(0), 3, stride=1, padding=1).squeeze(0).squeeze(0)\n",
    "        v_avg = Fun.avg_pool2d(v.unsqueeze(0).unsqueeze(0), 3, stride=1, padding=1).squeeze(0).squeeze(0)\n",
    "        \n",
    "        # Optical flow update step based on Horn-Schunck method\n",
    "        P = Ix * u_avg + Iy * v_avg + It\n",
    "        D = alpha ** 2 + Ix ** 2 + Iy ** 2\n",
    "        \n",
    "        u = u_avg - (Ix * P) / D\n",
    "        v = v_avg - (Iy * P) / D\n",
    "\n",
    "    # Stack u and v to form the flow tensor\n",
    "    flow = torch.stack((u, v), dim=0)\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2976e7",
   "metadata": {},
   "source": [
    "# Calculate Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "35698527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(image, num_bins=256, min_val=0.0, max_val=1.0):\n",
    "    # Rescale the image to the range [0, num_bins]\n",
    "    image_scaled = (image - min_val) / (max_val - min_val) * (num_bins - 1)\n",
    "    # Create bin centers\n",
    "    bin_centers = torch.linspace(0, num_bins - 1, num_bins, device=image.device)\n",
    "    # Expand bin centers for broadcasting\n",
    "    bin_centers = bin_centers.view(1, 1, 1, -1)\n",
    "    # Compute the soft assignment (weights) to each bin using Gaussian kernel\n",
    "    histograms = torch.exp(-(image_scaled.unsqueeze(-1) - bin_centers) ** 2)\n",
    "    # Sum over all pixels to get the histogram\n",
    "    histograms = histograms.sum(dim=[2, 3])  # Sum over height and width\n",
    "    # Normalize the histogram to sum to 1\n",
    "    histograms = histograms / histograms.sum(dim=-1, keepdim=True)\n",
    "    return histograms\n",
    "\n",
    "def histogram_loss(image_gen, image_target, num_bins=256):\n",
    "    # Ensure images are in the range [0, 1]\n",
    "    image_gen = torch.clamp(image_gen, 0.0, 1.0)\n",
    "    image_target = torch.clamp(image_target, 0.0, 1.0)\n",
    "    # Calculate differentiable histograms for generated and target images\n",
    "    hist_gen = hist(image_gen, num_bins=num_bins)\n",
    "    hist_target = hist(image_target, num_bins=num_bins)\n",
    "    # Calculate the histogram difference (L2 norm for histogram loss)\n",
    "    loss = torch.sum((hist_gen - hist_target) ** 2, dim=-1).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed644e",
   "metadata": {},
   "source": [
    "# Calculate Difference in Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "00e5bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_loss(image1, image2):\n",
    "    # Apply 2D Fourier Transform to the images along the height and width dimensions\n",
    "    freq_image1 = torch.fft.fft2(image1*255, dim=(-2, -1))\n",
    "    freq_image2 = torch.fft.fft2(image2*255, dim=(-2, -1))\n",
    "    # Compute the magnitude of the frequencies (ignore the phase for this loss)\n",
    "    mag_image1 = torch.abs(freq_image1)\n",
    "    mag_image2 = torch.abs(freq_image2)\n",
    "    # Compute the loss between the magnitudes of the frequency components\n",
    "    loss = Fun.mse_loss(mag_image1, mag_image2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c13d48",
   "metadata": {},
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "99d89524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinIncModel(nn.Module):\n",
    "    def __init__(self, N, H, W):\n",
    "        super(BinIncModel, self).__init__()\n",
    "        self.N, self.H, self.W = N, H, W\n",
    "        \n",
    "        # Convolutional layers with dilated convolutions and batch normalization\n",
    "        self.conv1 = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.bn1 = nn.BatchNorm3d(16)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=(1, 3, 3), dilation=(1, 2, 2), padding=(0, 2, 2))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.bn2 = nn.BatchNorm3d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        self.bn3 = nn.BatchNorm3d(64)\n",
    "\n",
    "        # Spatial Pyramid Pooling to handle varying sizes\n",
    "        self.spp = SpatialPyramidPooling(output_sizes=[(1, 1), (2, 2), (4, 4)])\n",
    "\n",
    "        # LSTM layer for temporal dependence\n",
    "        self.lstm_input_size = 0  # Initialize dynamically\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=128, batch_first=True)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Permute input for 3D convolutions and calculate difference frames\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        # Convolutional layers with BatchNorm, ReLU, and Max Pooling\n",
    "        x = self.bn1(Fun.relu(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.bn2(Fun.relu(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.bn3(Fun.relu(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Spatial Pyramid Pooling\n",
    "        x = self.spp(x)\n",
    "\n",
    "        # Update the LSTM input size dynamically based on the output of SPP\n",
    "        self.lstm_input_size = x.size(1)  # The size after SPP flattening\n",
    "\n",
    "        # Now reinitialize the LSTM layer with the correct input size\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=128, batch_first=True)\n",
    "\n",
    "        # Pass through LSTM to capture temporal dependencies\n",
    "        x = x.unsqueeze(1)  # Add time dimension\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Take the output of the last LSTM step\n",
    "\n",
    "        # Fully connected layers with Dropout for regularization\n",
    "        x = Fun.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc569b9",
   "metadata": {},
   "source": [
    "# Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "beea5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(path, N, size):\n",
    "    # Find all video files in the specified path\n",
    "    video_files = [f for f in os.listdir(path) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    if not video_files:\n",
    "        raise ValueError(\"No video files found in the specified path.\")\n",
    "    \n",
    "    # Choose a random video file\n",
    "    video_file = random.choice(video_files)\n",
    "    video_path = os.path.join(path, video_file)\n",
    "    \n",
    "    # Initialize the video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # If N is larger than the number of frames in the video, adjust it\n",
    "    if N > total_frames:\n",
    "        raise ValueError(f\"The video has only {total_frames} frames, but {N} frames were requested.\")\n",
    "    \n",
    "    # Select a random starting frame index such that we can capture N consecutive frames\n",
    "    start_frame = random.randint(0, total_frames - N)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    \n",
    "    # Resize transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    frames = []\n",
    "    for _ in range(N):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Convert the frame (BGR to RGB) and apply the resize transform\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb)\n",
    "        frames.append(frame_tensor)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Stack frames and reshape to the desired output shape\n",
    "    frames_tensor = torch.stack(frames).unsqueeze(0)  # Shape (1, N, 3, H, W)\n",
    "    \n",
    "    return frames#_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00538316",
   "metadata": {},
   "source": [
    "# Convert Tensor to Numpy List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4964b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2nl(frames_tensor):\n",
    "    # Remove the batch dimension (1, N, 3, H, W) -> (N, 3, H, W)\n",
    "    frames_tensor = frames_tensor.squeeze(0)\n",
    "    \n",
    "    # Convert each frame tensor to a NumPy array\n",
    "    frame_list = [cv2.cvtColor(frame.permute(1, 2, 0).numpy(),cv2.COLOR_BGR2RGB) for frame in frames_tensor]\n",
    "    \n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a98406",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "827b83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Path, State=None, N=3, Size=(100, 100), Batch=10, Epochs=10, Steps=5, LR=1e-3):\n",
    "    model = BinIncModel(N, Size[0], Size[1])\n",
    "    if State is not None:\n",
    "        model.load_state_dict(State)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    Loss, LossAll = [], [] \n",
    "    LMin = 1e20\n",
    "\n",
    "    for epoch in range(Epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in range(Batch):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            Frames = get_video_frames(Path, N, Size)\n",
    "            Target = torch.tensor([0.0]) if random.random() >= 0.5 else torch.tensor([1.0])\n",
    "\n",
    "            if Target.item() == 1.0:\n",
    "                steps = random.randint(1, Steps)\n",
    "                for s in range(steps):\n",
    "                    Frames[N // 2] = AddOneInc1(Frames[N // 2])\n",
    "            \n",
    "            # Difference Frames\n",
    "            diff_frames = [Frames[i+1] - Frames[i] for i in range(len(Frames) - 1)]\n",
    "            In = torch.stack(diff_frames).unsqueeze(0)  # Shape [1, N-1, C, H, W]\n",
    "\n",
    "            # Forward pass\n",
    "            Pred = model(In).squeeze(0)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = Fun.binary_cross_entropy(Pred, Target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            LossAll.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "            print(f'Batch [{batch+1}/{Batch}], Loss: {loss.item():.6f}', end='\\r')\n",
    "\n",
    "            # Display predictions on the frame\n",
    "            Frame = cv2.cvtColor(Frames[N // 2].permute(1,2,0).numpy(), cv2.COLOR_BGR2RGB)\n",
    "            Frame = cv2.putText(Frame, f'P: {round(Pred.item())}', (0, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)\n",
    "            Frame = cv2.putText(Frame, f'T: {int(Target.item())}', (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1)\n",
    "            cv2.imshow(\"Frame\", Frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        Loss.append(total_loss)\n",
    "        print(f'\\nEpoch [{epoch + 1}/{Epochs}], Loss: {total_loss / Batch:.6f}\\n')\n",
    "        \n",
    "        if total_loss < LMin:\n",
    "            LMin = total_loss\n",
    "            State = model.state_dict()\n",
    "        else:\n",
    "            model.load_state_dict(State)\n",
    "        LR *= 0.9\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "            \n",
    "    return State,model,Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbff028",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0a144bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ab6f0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "State = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "24e5233b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [20/20], Loss: 0.746668\n",
      "Epoch [1/10], Loss: 0.714408\n",
      "\n",
      "Batch [20/20], Loss: 0.675669\n",
      "Epoch [2/10], Loss: 0.685888\n",
      "\n",
      "Batch [20/20], Loss: 0.702868\n",
      "Epoch [3/10], Loss: 0.673241\n",
      "\n",
      "Batch [20/20], Loss: 0.739484\n",
      "Epoch [4/10], Loss: 0.679568\n",
      "\n",
      "Batch [20/20], Loss: 0.726143\n",
      "Epoch [5/10], Loss: 0.695576\n",
      "\n",
      "Batch [20/20], Loss: 0.622998\n",
      "Epoch [6/10], Loss: 0.664638\n",
      "\n",
      "Batch [20/20], Loss: 0.565636\n",
      "Epoch [7/10], Loss: 0.684871\n",
      "\n",
      "Batch [20/20], Loss: 0.793584\n",
      "Epoch [8/10], Loss: 0.720809\n",
      "\n",
      "Batch [20/20], Loss: 0.570150\n",
      "Epoch [9/10], Loss: 0.699210\n",
      "\n",
      "Batch [20/20], Loss: 0.763766\n",
      "Epoch [10/10], Loss: 0.727409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "State,Model,L = train('VDB',Batch=20,State=State,Size=(100,100),N=3,Epochs=10,Steps=5,LR=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "84335404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d791575dc8>]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXyU9bX48c+Z7AkkhOwbBAiEPUACLrgCKi7EBeit1y62eu3vtrbaapdbb7fr7e2i3q62V6vW2qqtWFRwBQKKWhXCEggkQFizkYVA9n2+vz8S2kgDk4SZeWaeOe/Xi9creeaZZw5DOPnO9znf7xFjDEoppezLYXUASimlPEsTvVJK2ZwmeqWUsjlN9EopZXOa6JVSyuY00SullM25TPQi8pSI1IpI8SCP3S8iRkTiz/LccSKyTkRKRGSviGSef8hKKaWGYygj+qeBpWceFJEM4Crg2Dme+wzwkDFmGrAAqB1BjEoppc5DsKsTjDGbzzIS/xnwDeCVwZ4nItOBYGPM+v7rtAwloPj4eJOZOdjLKaWUOptt27bVG2MSBnvMZaIfjIjkA5XGmCIROdtpU4BTIrIamABsAL5ljOk917UzMzMpLCwcSVhKKRWwROTo2R4b9s1YEYkEHgC+6+LUYOBS4H5gPjARuP0s17xLRApFpLCurm64ISmllDqHkVTdTKJvhF4kIkeAdGC7iCSfcV4FsMMYc8gY0wO8DMwb7ILGmMeNMXnGmLyEhEE/eSillBqhYU/dGGN2A4mnv+9P9nnGmPozTt0KxIpIgjGmDlgE6JyMUkp52VDKK58HPgCyRaRCRO44x7l5IvIEQP9c/P1AgYjsBgT4nXvCVkopNVRDqbq51cXjmQO+LgTuHPD9emD2ecSnlFLqPOnKWKWUsjlN9EopZXOa6JVSyges3l7BqsJyj1xbE71SSlnM6TT8bMN+Xt5Z6ZHra6JXSimLfXS4gfKGdlbmZnjk+prolVLKYqsKyxkdHszSmWeuO3UPTfRKKWWh5o5uXi+uZllOKuEhQR55DU30SilloVd3VdPR7eQTeZ6ZtgFN9EopZalVheVMThxFTnqMx15DE71SSlmkrLaZ7cdO8Ym8DM6x5ft500SvlFIWWbWtgiCHcNPcNI++jiZ6pZSyQE+vk9XbK1k0NZGE0WEefS1N9EopZYF39tdR19zJytx0j7+WJnqllLLAC4XlxI8K5cqpia5PPk+a6JVSystOtHRSUFLLzXPTCAnyfBrWRK+UUl720o5KepyGlR6snR9IE71SSnmRMYYXt1WQkzGGKUmjvfKamuiVUsqLdlc2Unq8mU/kef4m7Gma6JVSyotWFVYQFuxgWU6q115TE71SSnlJR3cvr+ys5NqZyUSHh3jtdTXRK6WUl6zbW0NTR4/XbsKepoleKaW8ZFVhOWljIrhoYpxXX1cTvVJKeUHlqXbeK6tnRW46DofnNjAbjMtELyJPiUitiBQP8tj9ImJEJP4cz48WkUoR+fX5BquUso9jJ9r45ou7aO3ssToUr/jrtgqMgRVe2PLgTEMZ0T8NLD3zoIhkAFcBx1w8/0HgnWFHppSytee2HOMvheX84YMjVoficU5nX+38xZPiyBgb6fXXd5nojTGbgYZBHvoZ8A3AnO25IpILJAHrRhqgUsqeCkpqAPjd5kO2H9V/dLiBYw1trPRi7fxAI5qjF5F8oNIYU3SOcxzAI8DXRxibUsqmjp1o40BtC8tyUjnZ1s0fPzxqdUgetWpbOaPDglk6I8WS1x92oheRSOAB4LsuTv0i8LoxpnwI17xLRApFpLCurm64ISml/ExBad9o/r6rpnDZlAQet/Govrmjm9d3V3NDTioRoZ5p/u3KSEb0k4AJQJGIHAHSge0iknzGeRcBd/ef8zDwGRH58WAXNMY8bozJM8bkJSQkjCAkpZQ/2Vhay6SEKDLjo7hn8WQaWrv4k01H9a/9vfm3NdM2MIJEb4zZbYxJNMZkGmMygQpgnjHm+Bnn3WaMGdd/zv3AM8aYb7kjaKWU/2ru6ObDQydYPC0JgNzxsVw6OZ7HNx+irct+o/oXCsvJShzFnIwxlsUwlPLK54EPgGwRqRCRO85xbp6IPOHOAJVS9vLegXq6ew2LBzTcuHfJZE60dvHsh66K+PxLWW1Lf/PvdI82/3Yl2NUJxphbXTyeOeDrQuDOQc55mr4yTaVUgNtQUktMRAi542P/fix3/FguyYrnsc0H+dSF4y2by3a3VdvKvdL82xVdGauU8ppep+HtfbVckZ1A8Bmdle5ZMpn6li6e/cgec/Wnm39fmZ1I4uhwS2PRRK+U8pqd5ac40drFokH6pM7PHMvCrDj+751DtHf1WhCde/29+beFN2FP00SvlPKajaU1BDmEK6YM3hD7nsVTqG/ptMWoflVhBfGjQgf9peZtmuiVUl5TUFJL3vhYYiIH34t9wYSxXDQxjsc2H6Kj239H9SdaOtlQUsNNc7zT/NsV6yNQSgWEipNtlB5vZkl/WeXZ3LNkMnXNnTz3kf9W4Ly8s8qrzb9d0USvlPKKjaW1ACyadu6pjAsnxnHhxLH83zsH/XJUb4xhVWE5OekxZCd7p/m3K5rolVJeUVBSy4T4KCYljHJ57j2Lp1Db3MnzW/xvVF9c2UTp8WafGc2DJnqllBe0dvbwwcETQ74xedGkOC6Y4J+j+hcKy73e/NsVTfRKKY97r6yerl4ni11M2wx0z5LJ1DR18petLvdF9Bmnm38vnZlMTIT3mn+7ooleKeVxBSU1jA4PZn7m2CE/56KJcSzIHMtv3i7zm1H935t/5/rOtA1ooldKeZjTadhYWsflUxKGVWooIn8f1b9Q6B+j+tPNvy+e5N3m367YJtGfaOnkwVf3UlzZaHUoSqkBdlU2Ut/SOaxpm9MunhTH/MxYfvv2QTp7fHtUf7r593ILmn+7YptEHxLs4NmPjvLnrf53l14pO9tYUoNDOOtq2HMREe5ZPIXqxg5eKKzwQHTus7q/+fdKC5p/u2KbRB8dHsLSGcms2VnlN/N5SgWCDSW15I6PJTYqdETPX5gVR+74WH6zqcxnR/VOp2HVtgoummhN829XbJPoAVbmZdDU0cP6vTVWh6KUAqob29lb3fT3JiMjISLcu2Qy1Y0drPLRUf2WI33Nvz8x3/dG82CzRH/RxDjSxkTw4jbf/GFQKtAUlPSthl18nht7XZIVz7xxY/jt2wfp6nG6IzS3eqHQ2ubfrtgq0TscwvJ5abx7oI7jjR1Wh6NUwNtYWsu4sZFkJbpeDXsufRU4U6g81e5zA7nmjm7e2H3c0ubfrtgq0QMsz03HaWD1Dt/6YVAq0LR39fJ+WT2Lpia6pY3eZZPjmZMxhkc3lfnUqP61XdW0d/f6xL7zZ2O7RD8+LooFmWN5sbACY4zV4SgVsN4vq6ezx+lyt8qhOj1XX3mqnb9u952B3KptFWQljmKuhc2/XbFdogdYkZfOofpWth87ZXUoSgWsgtIaRoUFs2DC0FfDunL5lARyfGhUX1bbwrajJ1mZa23zb1dsmeivm5VCREiQz83lKRUojDEUlNRy2ZR4QoPdl2ZEhHsXT6biZDurfWBU/+K2CoIcws3zrG3+7YotE/2osGCum5XCq0VVtug9qZS/Ka5sora5k0VT3TNtM9AV2QnMTo/h15vK6O61blTf0+vkr9sruDI7wfLm3664TPQi8pSI1IpI8SCP3S8iRkTiB3lsjoh8ICJ7RGSXiPyLu4IeihW56TR39rBu73FvvqxSir5pGxG4MjvB7dc+PVdfcbKdl7ZXuv36Q7X5wOnm3761gdlghjKifxpYeuZBEckArgLOtudAG/AZY8yM/uf/XES8drfiggljSY+N8NkFFkrZWUFJLXMzxhA3Kswj178yO9HyUf0LWyuIi/KN5t+uuEz0xpjNQMMgD/0M+AYwaGmLMWa/MeZA/9dVQC3g/l/vZ+FwCCty03n/YD2Vp9q99bJKBbyapg52Vzae12pYV0SEryyazLGGNl7a4f1R/YmWTgpKa7h5rm80/3ZlRBGKSD5QaYwpGuL5C4BQ4OBIXm+kls9Lxxh4yQdu2igVKE73hh3JbpXDsXhaIjPTonl0Uxk9Xh7Vv7yziu5e32n+7cqwE72IRAIPAN8d4vkpwB+BzxljBv3XEJG7RKRQRArr6uqGG9JZZYyN5MKJY3lxm9bUK+UtBSW1pI2JIDvJs42xT+9sefREGy/vrPLoaw3ki82/XRnJiH4SMAEoEpEjQDqwXUSSzzxRRKKB14D/NMZ8eLYLGmMeN8bkGWPyEhLcO7uzMjeDIyfaKDx60q3XVUr9s47uXt4rq2PxNPeshnVlybREZqRG86uNB7w2qj/d/HuFn4zmYQSJ3hiz2xiTaIzJNMZkAhXAPGPMx8pbRCQUeAl4xhizyi3RjsC1s5KJCg3iRb0pq5THfXDwBB3dTo/Ozw8kInxl8WSOnmjjFS+N6ldt62v+ne9Dzb9dGUp55fPAB0C2iFSIyB3nODdPRJ7o//YTwGXA7SKys//PHLdEPQyRocFcPzuFV3dV0dbV4+2XVyqgbCipITI0iAvcuBrWlaunJzE9JZpfe2GuvqO7l5d3VHLNDN9q/u3KUKpubjXGpBhjQowx6caYJ894PNMYU9//daEx5s7+r//U/5w5A/7s9Mxf49xW5GbQ2tXLm8VaU6+Upxhj2Fhay6WT4wkP8d4ujqdH9YfrW1m7y7Oj+vX9zb8/4UfTNmDTlbFnmp8Zy/i4SK2pV8qD9lY3Ud3YwWIPrIZ15erpSUxNHs2vCsrodXqu8OIFH23+7UpAJHoRYcW8dD44dILyhjarw1HKljb2Nxm50oIFRA5H32rZQ/WtrC3yzKi+yoebf7sSEIke4JbcdERgtYVLppWysw2lteRkjCFhtGdWw7py9fRkpiaP5pcbD3hkVP9XH27+7UrAJPq0MREsnBTPi9vLcXrwo51SgaiuuZOi8lMssXA7AIejb67+UF0rr7p5rt7Xm3+7EjCJHvo2OitvaGfLkcF2dFBKjdSm/tWwizy8GtaVpTOSyU4azS8L3DuqP93825e7SJ1LQCX6a2YkMzosWG/KKuVmBaU1pMSEMz0l2tI4To/qD9a18truarddd1VhBaPCgrl2pm82/3YloBJ9RGgQN+Sk8EZxNa2dWlOvlDt0dPfy7gH39YY9X9fOTGZK0ih+5aZRfUtnD6/vrmZZTorPNv92JaASPfRN37R19fK6G3/bKxXIPjrcQFtXr9t6w54vh0P48qLJHKhtccv/89d2VfU3//av2vmBAi7RzxsXy8T4KFZpm0Gl3KKgpIbwEAcX+VBt+XWzUpicOIpfbTxw3sUXLxRWMCkhyqebf7sScIleRFiem86Www0cPdFqdThK+bXTvWEvyUrw6mpYV4IcwpcXT2Z/TQtvnMeK+IN1fc2/P5GX4RPTUiMVcIke4JZ5aTikry5WKTVy+2qaqTzV7vG950fi+lkpTEqI4pcFIx/Vryr0j+bfrgRkok+JieCSyQn8dXul1tQrdR4K+lfD+mI7vaD+Cpx9Nc28uWf4o/qeXier/aT5tysBmeih76Zs5al2Pjx0wupQlPJbBSU1zEqLISnaNxPhDbNTmTjCUf3mA3XUNneyItd/b8KeFrCJ/urpSYwOD9abskqN0ImWTnaUn/LJaZvTghx9vWVLjzezbu/wRvWrCv2n+bcrAZvow0OCyM9J5Y3iapo7uq0ORym/s2lfHcZgyW6Vw7EsJ5WJ8VH8fMPQR/UNrV1sKKnhprlphAb7f5r0/7/BeViRm05Ht5PXdmlNvVLDtbG0hqToMGamWbsa1pW+Cpys/lF9zZCe8/KOSrp7jd/tO382AZ3o52SMIStxFC/q9I1Sw9LV42Tzft9ZDevKstmpTIjvm6s35tyjemMMLxSWM9uPmn+7EtCJXkRYkZtO4dGTHK7XmnqlhmrL4QZaOnt8ftrmtOAgB3dfmcXe6ibWuxjV76nqa/7tzythzxTQiR7g5rl9NfUvbiu3OhSl/MaGkhrCgh0szIq3OpQhu3FOKplxkfzCxaj+hcJyQoMd5M/2n+bfrgR8ok+KDufyKQms3l7p0RZkStmFMYaC0hoWZsX71SZfwUEO7l40mT1VTWzor/8/U0d3L6/srGLpjGRiIv2n+bcrAZ/ooa95eHVjB++X1VsdilI+r6y2hfKGdr8sO7xpTirj4yL5RcH+QUf16/fW0Nje7bf7zp+NJnpgyfREYiJC9KasUkNQ0N9kxJfr588mOMjBl67MoriyiY2l/zyqX7Wtor/5t/9MSQ2FJnogLDiIG+ek8tae4zS2a029UudSUFLD9JRoUmIirA5lRG6em8a4sZH8fMPH5+qrTrXz7oE6ls9LI8jPmn+74jLRi8hTIlIrIsWDPHa/iBgRGfTXn4h8VkQO9P/5rDsC9pQVuel09jjd3mtSKTs52drFtqMnWeKHo/nTQvorcHZXNrJp3z9G9au39zX/tsOWB2cayoj+aWDpmQdFJAO4Cjg22JNEZCzwPeACYAHwPRGJHXGkHjYrLYbspNE6faPUOby9vxangUU+0mRkpG6el0bG2Ah+0T+qN6av+feFE8cyLs7/mn+74jLRG2M2A4N10/4Z8A3gbKUq1wDrjTENxpiTwHoG+YXhK07X1O84doqy2harw1HKJxWU1BI/KozZaTFWh3JeQoIcfOmKLIoqGnl7X11/f4o226yEPdOI5uhFJB+oNMYUneO0NGBgcXpF/zGfddPcvrk5HdUr9c+6e528s7+ORVMTcNhgDvuWeemkx0bw84IDvODnzb9dGXaiF5FI4AHgu65OHeTYoKN/EblLRApFpLCurm64IblNwugwrsxO4KUdFVpTr9QZth5poLmjh0V+shrWldDgvgqcovJTvLSjwq+bf7sykhH9JGACUCQiR4B0YLuIJJ9xXgUw8HNQOjDonU5jzOPGmDxjTF5CQsIIQnKfFbnp1DR1svmAdb9wlPJFBSW1hAY5uHSyfUoPl89LJ21MBE6b3oQ9bdiJ3hiz2xiTaIzJNMZk0pfQ5xljztzs+S3gahGJ7b8Je3X/MZ+2aGoSsZFaU6/UmTaW1nLhpDiiwoKtDsVtQoMd/CB/Bp+cn8G8cf7b/NuVoZRXPg98AGSLSIWI3HGOc/NE5AkAY0wD8CCwtf/Pf/Uf82mhwQ5unJPG+j01NLZpTb1S0Nck+3B9q1+XVZ7NkulJ/Hj5bL/YhXOkhlJ1c6sxJsUYE2KMSTfGPHnG45nGmPr+rwuNMXcOeOwpY0xW/5/fuz98z1iZl05Xr5M1RZVWh6KUT9jow71hlWu6MnYQM1JjmJYSrdM3SvXbUFLD1OTRpMfar8Y8EGiiP4sVuekUVTSyv6bZ6lCUslRjWzeFR0/qaN6PaaI/i5vmpBKsNfVK8fb+WnqdhsV+vho2kGmiP4u4UWEsmprI6u2V9PQ6rQ5HKctsLK1lbFQoczLsW5Vid5roz2FlXgb1LZ28s19r6lVg6ul18va+Oq7MTrTdjo6BRBP9OVyRnUBcVKhO36iAte3oSRrbu/1y73n1D5rozyEkyMFNc9PYUFJDQ2uX1eEo5XUFpbWEBImtVsMGIk30LqzITae717Bmp9bU+7Papg5Otekv6+EqKKnhgglxjA63T//UQKSJ3oVpKdHMTIvmxe06feOvTrZ2cf2v3uPLz++wOhS/cqS+lYN1rTptYwOa6IdgZW4GxZVNlFQ3WR2KGoHvr91DXXMn75XVU9vUYXU4fuPvvWFtsltlINNEPwT5OamEBGlNvT96s7iaV3ZWcdOcVIyBV3dVWx2S3ygoqWFy4ihbdlwKNJrohyA2KpQl05J4eUcl3VpT7zcaWrv4z5eLmZ4SzUMrc5iWEs1a7Qk8JE0d3Ww53MAinbaxBU30Q7QyL50TrV1sKq11fbLyCd99pZjG9m4e+UQOIUEO8nNS2XHsFOUNbVaH5vM276+jx2lYoqthbUET/RBdNjmB+FFhOn3jJ17bVc2ru6q5Z/FkpqVEA7Asp69N3JoiHdW7srGkljGRIczV1bC2oIl+iIKDHNwyL42NpbXUt3RaHY46h/qWTr7zSjGz0mL4f5dP+vvx9NhIcsfHslYT/Tn1Og2b9tVyZXYiwUGaIuxA/xWHYUVuOj1Owys7NVH4KmMM33m5mJaOHh5emfNPiSo/J5XS4826K+k57Dh2kpNt3bpbpY1ooh+GKUmjyUmPYVVhOcZo83Bf9Oquat4oPs69V00mO3n0Pz1+3awUHAJr9Jf1WW0oqSXYIVw2xdr+zcp9NNEP04q8DEqPN7OnSmvqfU1tcwffeaWYnIwx3HXpxEHPSRgdxsKseNYUVekv67PYWFrD/MyxxEToali70EQ/TPmzUwkNcuhNWR9jjOGBl4pp6+rlkZWzzzm3vGx2Ksca2thV0ejFCP1DeUMb+2tadDWszWiiH6aYyBCumpHEKzsr6erRmnpf8crOKtbvreG+q6aQlfjPUzYDXTMzmdAgh1bfDKKgpAZAm4zYjCb6EViZm87Jtm42ltZYHYqib8Oy763Zw9xxY7jzLFM2A8VEhHB5dgKv7qqi16nTNwMVlNYyMSGKCfFRVoei3EgT/QhcOjmBpGitqfcFxhi+/dJuOrp7eXhlzpCbY+TnpFLT1MmWww0ejtB/tHT28OGhEyzWahvbcZnoReQpEakVkeIBxx4UkV0islNE1olI6lme+1MR2SMiJSLySxGxRYuaIIdwy7x0Nu2ro7ZZN8my0urtlWwoqeXr12QzKWHUkJ+3ZFoSkaFBOn0zwLv76+ju1d6wdjSUEf3TwNIzjj1kjJltjJkDvAp898wnicjFwEJgNjATmA9cfl7R+pDl89LpdRpe2aGJwirHGzv4wdo95I2P5XMLJwzruRGhQVw1PYk3iqv1Xku/gtJaosODyR0fa3Uoys1cJnpjzGag4YxjA2sLo4DBJjoNEA6EAmFACGCbSe2sxFHMHTeGVdu0pt4Kxhj+Y/UuunqdPDSMKZuB8nNSOdXWzXtl2hO412nYVFrLFdmJhOhqWNsZ8b+oiPxQRMqB2xhkRG+M+QDYBFT3/3nLGFMy0tfzRStzM9hf08LuSi3T87ZV2yrYtK+Oby6dOuIbh5dOTiAmIoS1Rbp1cVHFKU60dmlZpU2NONEbYx4wxmQAzwJ3n/m4iGQB04B0IA1YJCKXDXYtEblLRApFpLCuzn9GVzfkpBAWrDX13lZ1qp0H1+5lwYSxfPaizBFfJzTYwbUzk1m35zjtXb3uC9APFZTUEOQQLtfVsLbkjs9ozwHLBzl+M/ChMabFGNMCvAFcONgFjDGPG2PyjDF5CQn+84MWHR7C0pnJvLKzio7uwE4U3mKM4Vurd9PjNDy0YjaOEUzZDJSfk0prVy8bA3z76YKSWnLHxzImMtTqUJQHjCjRi8jkAd/mA6WDnHYMuFxEgkUkhL4bsbaauoG+jc4a27spKAnsROEtf9lazub9dfzHdVMZH3f+td4XTIwjcXQYa4oCt/l7xck2So83s0SnbWxrKOWVzwMfANkiUiEidwA/FpFiEdkFXA3c039unog80f/UF4GDwG6gCCgyxqz1xF/CShdPiiclJpxV28qtDsX2Kk628d+vlXDRxDg+dcF4t1wzyCFcPzuFTfvqaOrodss1/c3pZjqLtDesbQW7OsEYc+sgh588y7mFwJ39X/cCXziv6PxAkENYPi+d37xdRk1TB0nR4VaHZEvGGL711904jeGnbpiyGSg/J5Xfv3+Et4qPszIvw23X9RcbSmrJjItkUoKuhrUrraNyg+W56TgNvLQjcD/+e9pzW47xXlk9375uGhlj3dusek7GGDLGRgTk4qnWzh4+OHiCRVOTsMl6RjUITfRuMCE+ivmZsbpPvYeUN7Txw9dKuCQrntsuGOf264sIy2an8reDJwKue9h7ZfV09Tp1ft7mNNG7yYrcdA7WtbKz/JTVodiK02n4xou7cIjw4+WzPDbqzJ+TSq/T8MbuwKqp31hSy+iwYPIyx1odivIgTfRuct2sFMJDHKzSmnq3+tNHR/ng0AkeuH4a6bHunbIZaGpyNFOSRgXU9I3TaSgoreWy7ARCgzUV2Jn+67rJ6PAQrpuZwtoiral3l2Mn2vjR66VcOjmeT873/E3S/JxUth45SeWpdo+/li/YXdlIfUun7lYZADTRu9GK3HSaO3pYt9c2W/pYxuk03P9iEcEO4SfLZ3vlRuGynL5NWF8NkFF9QUkNDoErsjXR250meje6cGIcaWMiWFWoNfXn6w8fHGHL4Qa+s2w6qWMivPKa4+OiyMkYEzDTNwWltcwbF8vYKF0Na3ea6N3I4RCW56bzXlk9h+parA7Hbx2pb+Unb5ZyZXYCK3PTvfra+Tmp7Klq4qDN//2qG9vZU9Wke88HCE30bnbrggyiw0O464/baGwPzJWW56PXabh/VREhQQ5+dIt3pmwGumF2CiKwZqe9R/Wn9/bR3SoDgyZ6N0uJieCxT+dy9EQrX3p2O9292tRiOH7//mEKj57k+8tmkBzj/VXGSdHhXDBhLGt3Vdl6TURBSS0ZYyOYnDj0rlzKf2mi94ALJ8bxPzfP4r2yer63Zo+tE4Y7Haxr4aG39rF4aiK3zEuzLI78nDQO1bWyp6rJ9cl+qL2rl/fL6lmsq2EDhiZ6D1mZl8EXr5jEcx8d48n3Dlsdjs/rdRq+vqqI8JAg/ucWzy2MGoprZyYT7BDW2vSm7PNbjtHZ4+S6WSlWh6K8RBO9B91/dTbXzUrmh6+XsF5LLs/pyfcOsf3YKX6QP8PyjeFio0K5bEoCa4uqcDrt9WmspbOHX28qY2FWHAsm6GrYQKGJ3oMcDuGRlXOYnRbDPX/eQbG2HBxUWW0zD6/bz9XTk7hxTqrV4QB91TdVjR1sO3bS6lDc6ol3D9HQ2sU3rplqdSjKizTRe1hEaBC/+0weYyJCuPMPhRxv7LA6JJ/S0+vkvlW7iAwN4r9vnukzc8ZXTU8iPMRhq+qbEy2d/G7zIa6dmUxOxhirw1FepIneCxKjw3ny9vk0d3Rz5zNbaevqsTokn/G7dw9TVH6K/7pxJomjfWcv/6iwYBZPTSRnfnkAABLASURBVOL13dX02KRy6tFNB2nv7uW+q7OtDkV5mSZ6L5mWEs2v/nUue6uauPfPO2039zsS+2ua+dn6/Vw7M5lls33vxuCynFROtHbxt4MnrA7lvFWcbONPHx5lZW4GWVpSGXA00XvRoqlJfOeG6azbW8NP3hyszW7g6O51ct8LRYwKD+bBm3xnymagK7ITGB0WbIstEX6x4QAI3LNksuuTle1oovey2y/O5NMXjuexzYf485ZjVodjmcfeOcjuykYevHEm8aPCrA5nUOEhQVwzM5m3io/79Y6kB2qa+ev2Cj570Xiv7RukfIsmei8TEb63bDqXT0ngP18u5v2yeqtD8rrS4038ouAA189O4XofnLIZKD8nlebOHt7eV2d1KCP28Lp9RIYG8+9XZFkdirKIJnoLBAc5+NW/zmViQhT//qdtlNXaewOtgU5P2cREhPDgjTOtDseliyfFET8q1G8XT+04dpK39tRw12UTdZfKAKaJ3iLR4SE8+dn5hAY7+PzTW2lo7bI6JK/4zaaD7Klq4r9vmuUXiSc4yMF1s1LYUFJDS6d/VUsZY/jJm6XERYVyxyUTrA5HWUgTvYUyxkby+GfyON7UwRf+WEhnj//OAw/FnqpGfrXxAPk5qSydmWx1OEO2LCeVzh4n6/cetzqUYXn3QD0fHmrgy4uyiAoLtjocZSGXiV5EnhKRWhEpHnDsQRHZJSI7RWSdiAy6nFFExvU/XiIie0Uk032h28O8cbE8sjKHrUdO8h9/3W3bDdC6epzcv2oXYyJD+UH+DKvDGZbccbGkxoSztsh/Goc7nYafvlVKemwEt14wzupwlMWGMqJ/Glh6xrGHjDGzjTFzgFeB757luc/0nzsNWADUjjRQO1uWk8p9V01h9Y5Kfr2xzOpwPOLXm8ooqW7if26eSawfTNkM5HAIy3JS2by/jpN+MsX2enE1xZVNfO2qKYQFB1kdjrKYy0RvjNkMNJxxbOD+rVHAPw1DRWQ6EGyMWd//nBZjTNv5hWtfdy/K4pa5aTyyfr/f3vg7m+LKRh7dVMYtc9O4eob/TNkMtCwnlR6n4Y1i35++6e518si6/WQnjebGOdZt96x8x4jn6EXkhyJSDtzG4CP6KcApEVktIjtE5CER0aHFWYgIP1o+i/mZsdy3qojtNtlMq7Onl/tXFREXFcr3lvnXlM1AM1KjmZgQxZqiSqtDcenFbRUcrm/l/muyCXL43kI05X0jTvTGmAeMMRnAs8Ddg5wSDFwK3A/MByYCtw92LRG5S0QKRaSwrs5/65XPV1hwEI99Oo/k6HDueqaQ8gb//gBU39LJ114oovR4Mz+6ZRYxkSFWhzRiIkJ+TiofHW7w6Y3pOrp7+fmG/cwbN4Yl2iZQ9XNH1c1zwPJBjlcAO4wxh4wxPcDLwLzBLmCMedwYk2eMyUtISHBDSP5rbFQoT90+n64eJ3f8YStNHf7Xd7an18nv3z/MlQ+/zVvFx/naVVNs0YR6WU4qxsCru3x3au0PfztCTVMn31w61Se3lVDWGFGiF5GBG2bkA4Nt3LIViBWR05l7EbB3JK8XaLISR/HbT+VyqK6Vu5/b4Ve7J/7tYD3X/fJdfrB2L3MyxvDmvZfylcX22F9lUsIoZqRG++w9lMb2bn7z9kGuyE7ggolxVoejfMhQyiufBz4AskWkQkTuAH4sIsUisgu4Grin/9w8EXkCwBjTS9+0TYGI7AYE+J2H/h62szArnv++aSab99fxg7V7fb7ssvJUO196djv/+ruPaOvq5bFP5/LM5xeQlTja6tDcKj8nlaKKRo6eaLU6lH/y+OaDNLZ38/VrdBti9XEuV1EYY24d5PCTZzm3ELhzwPfrgdkjji7AfXLBOA7Vt/L45kNMTIjicwt9b3VjR3cvv9t8iEffLsMY+OqSKXzh8omEh9jzvvsNOan86I1S1hZVcfci3/mkUtvUwVPvHSE/J5UZqTFWh6N8jC6X83HfXDqVI/WtPPjqXsbHRbJoqm/MdRtjWL+3hgdf20t5QzvXzkzmgeunkR4baXVoHpU2JoL5mbGs8bFE/6uNZXT3OvnaVVOsDkX5IN0CwccFOYSff3IO01Oj+fJzOyipbnL9JA87WNfCZ3+/lbv+uI2w4CCevfMCfvupXNsn+dPyc1LZX9NC6XHr/y0Ajp5o5fktx/jkggwy46OsDkf5IE30fiAyNJgnPjOfUeHB3PH0VmqbrCnva+ns4Uevl7D055vZcfQk37lhOm/ccykLs+Iticcq181KIcghPtNP9mfr9xMcJHzFhz5hKN+iid5PJMeE8+Rn53OyrZt/e6aQ9i7vbYBmjGH19gqufPhtHtt8iJvmpLHx/iu445IJhAQF3o9Q3KgwFmbFs3ZXleU3yfdWNfFKURWfWziBxGjf6bmrfEvg/S/1YzPTYvjlrXPZVdnI117wTt/Z4spGVvzfB3zthSJSY8J56YsX89DKHBJG+2ZXKG9ZNjuF8oZ2dpSfsjSOh9ftY3RYMP/vskmWxqF8myZ6P3PV9CQeuG4abxQf5+F1+zz2Og2tXXz7pd0s+/V7HKlv5afLZ/PSFxcyd1ysx17Tn1wzM5nQYIel0zdbDjewsbSWf78iy69XHSvP06obP3THJRM4WNfKb94+yIT4KFbmZbjt2j29Tp7bcoxH1u2npbOH2y/O5N4lU4iJ0EQyUHR4CFdmJ/Da7mq+c8N0r+8pY4zhp2+Wkjg6jNsvzvTqayv/o4neD4kI/3XjDMob2vj2S7vJGBvJhW5YCfnRoRN8f+1eSqqbuGhiHN/Pn0F2sr0WPLlTfk4ab+2p4aNDJ7jYyzekN5bWUnj0JD+8eSYRofZcs6DcR6du/FRIkINHb5vHuLGRfOGP2zhUN/K+s8cbO/jK8zv4l8c/pKm9m9/cNo/n/u0CTfIuLJ6WSFRoEGu8vCVCr9Pw0zf3kRkXySfc+GlO2Zcmej8WExHC729fQJBDuOMPhZxqG15TjM6eXn7zdhmLHnmbN/cc5yuLstjwtcu5blaKbog1BOEhQVw9I5k3io/T1eO9/YjWFFWyr6aZr12dHZBVT2r49KfEz42Li+TxT+dSebKdL/xx25ATzsbSGq752WZ++uY+LsmKZ8NXL+drV2frNMAw5eek0tjezeb93tleu6vHyf+u38/0lGhumJXilddU/k8TvQ3kZY7lpytm89HhBh546dx9Z4/Ut/L5p7fy+acLcTiEZz6/gMc/k8e4uMBY1epuC7PiGRMZ4rXpmz9vPUZ5QzvfWJqNQ5uKqCHSm7E2cdPcNA7Vt/LLggNMSIjii1dkfezx1s4eHt1UxhPvHiYkSPj2dVO5/eIJhAbr7/rzERrs4NqZKby8o5K2rh4iQz33X6q1s4dfFpRxwYSxXD4lsPs2qOHRRG8jX10yua/m/c19ZMZFcd2sFIwxrCmq4kevl3K8qYNb5qXxraVTdRWlG+XnpPL8lmMUlNSyLCfVY6/z+/cPU9/SyWOfztV7KGpYNNHbiIjw0xWzqTjZxlf/spPOnl6e31LOlsMNzEyL5tHb5pI7fqzVYdrOggljSYoOY01RlccS/cnWLh575xBXTU8id7wuWlPDo5/bbSY8JIjHP5NHwugwvvqXIg7UNPM/N8/ilS9dokneQ4Icwg2zU3lnXx2N7Z5p/fjbdw7S0tWjTUXUiGiit6H4UWH88Y4L+Po12Wy6/wr+9YJxXl+5GWjyc1Lp6nXyVvFxt1+7urGdp/92hJvnpjElSdc2qOHTRG9TE+Kj+NKVWYyJDLU6lIAwOz2G8XGRHqm++cWGAxhj+OoSbSqiRkYTvVJuICIsm53K3w7WU9vsvn4BB+taWLWtgtsuGE/GWC2BVSOjiV4pN8mfk4rTwOu7qt12zf9dt5+wYAd3L8pyfbJSZ6GJXik3mZI0mqnJo1nrpkS/q+IUr+2u5s5LJxI/KrD3/1fnRxO9Um60LCeVbUdPUnGy7byv9dBb+4iNDOHfLp3ghshUIHOZ6EXkKRGpFZHiAcceFJFdIrJTRNaJyFmLh0UkWkQqReTX7gpaKV+V319Hv7bo/Eb175fV8+6Ber50ZRajw7UXgDo/QxnRPw0sPePYQ8aY2caYOcCrwHfP8fwHgXdGFp5S/iVjbCRzx405r+qb001FUmPC+dSF490YnQpULhO9MWYz0HDGsaYB30YBg+6iJSK5QBKw7jxiVMqv5OekUlLdRFlt84ie/9ae4xRVNHLvkimEh+huour8jXiOXkR+KCLlwG0MMqIXEQfwCPD1kYenlP+5flYKDmFE/WR7ep089NY+JiVEccu8NA9EpwLRiBO9MeYBY0wG8Cxw9yCnfBF43RhT7upaInKXiBSKSGFdnXf29VbKUxKjw7lwYhxriqrOuWX0YFbvqORgXStfvyabYG0qotzEHT9JzwHLBzl+EXC3iBwBHgY+IyI/HuwCxpjHjTF5xpi8hATdflX5v/ycVI6caKO4ssn1yf06unv5+fr95KTHcM2MZA9GpwLNiBK9iEwe8G0+UHrmOcaY24wx44wxmcD9wDPGmG+NKEql/My1M1MICRLWFFUO+Tl/+vAoVY0dfHPpVN2GWLnVUMornwc+ALJFpEJE7gB+LCLFIrILuBq4p//cPBF5wqMRK+UHYiJDuHxKAq/uqsbpdD1909zRzaObyrh0cjwXZ8V7IUIVSFzuR2+MuXWQw0+e5dxC4M5Bjj9NX5mmUgFjWU4qG0pq2XqkgQsmxp3z3N+9e5iTbd26DbHyCL3bo5SHXDU9iYiQIJc19fUtnTzx7iGum5XM7PQxXopOBRJN9Ep5SGRoMIunJfL67mq6e51nPe/XG8vo7HFy39U6mleeoYleKQ/Kz0nlZFs375XVD/p4eUMbz350lJW56UxKGOXl6FSg0ESvlAddnp1AdHgwa8+yeOpnG/YjItyzZPKgjyvlDprolfKgsOAgls5MZt3eGjq6ez/22L7jzby0o5LbL84kJSbCoghVINBEr5SH5eek0dLZw6bS2o8df3jdPkaFBvPvl0+yKDIVKDTRK+VhF02KI35U2Meqb7YdPcn6vTV84fKJxEZpX1/lWZrolfKwIIdww+wUCkprae7oxhjDT94sJX5UKJ9bqE1FlOdpolfKC5blpNDV42Tdnhre2V/HlsMNfHnRZKLCXK5ZVOq86U+ZUl4wb1wsaWMieKWoivrmTtJjI7h1wTirw1IBQkf0SnmBiLAsJ5XN++vYW93EfVdPITRY//sp79CfNKW85HQ/2anJo8nP0aYiynt06kYpL5mWMpp7l0zmyuxEghy6DbHyHk30SnmJiHDvkilWh6ECkE7dKKWUzWmiV0opm9NEr5RSNqeJXimlbE4TvVJK2ZwmeqWUsjlN9EopZXOa6JVSyubEGGN1DB8jInXA0fO4RDwweIPOwKPvxcfp+/Fx+n78gx3ei/HGmITBHvC5RH++RKTQGJNndRy+QN+Lj9P34+P0/fgHu78XOnWjlFI2p4leKaVszo6J/nGrA/Ah+l58nL4fH6fvxz/Y+r2w3Ry9Ukqpj7PjiF4ppdQAtkn0IrJURPaJSJmIfMvqeKwkIhkisklESkRkj4jcY3VMVhORIBHZISKvWh2L1URkjIi8KCKl/T8jF1kdk5VE5Kv9/0+KReR5EQm3OiZ3s0WiF5Eg4FHgWmA6cKuITLc2Kkv1APcZY6YBFwJfCvD3A+AeoMTqIHzEL4A3jTFTgRwC+H0RkTTgK0CeMWYmEAR80tqo3M8WiR5YAJQZYw4ZY7qAPwM3WhyTZYwx1caY7f1fN9P3Hzlgm5SKSDpwPfCE1bFYTUSigcuAJwGMMV3GmFPWRmW5YCBCRIKBSKDK4njczi6JPg0oH/B9BQGc2AYSkUxgLvCRtZFY6ufANwCn1YH4gIlAHfD7/qmsJ0QkyuqgrGKMqQQeBo4B1UCjMWadtVG5n10S/WCdlgO+nEhERgF/Be41xjRZHY8VROQGoNYYs83qWHxEMDAP+K0xZi7QCgTsPS0RiaXv0/8EIBWIEpFPWRuV+9kl0VcAGQO+T8eGH7+GQ0RC6EvyzxpjVlsdj4UWAvkicoS+Kb1FIvIna0OyVAVQYYw5/QnvRfoSf6BaAhw2xtQZY7qB1cDFFsfkdnZJ9FuBySIyQURC6buZssbimCwjIkLfHGyJMeZ/rY7HSsaY/zDGpBtjMun7udhojLHdiG2ojDHHgXIRye4/tBjYa2FIVjsGXCgikf3/bxZjw5vTwVYH4A7GmB4RuRt4i7675k8ZY/ZYHJaVFgKfBnaLyM7+Y982xrxuYUzKd3wZeLZ/UHQI+JzF8VjGGPORiLwIbKevWm0HNlwlqytjlVLK5uwydaOUUuosNNErpZTNaaJXSimb00SvlFI2p4leKaVsThO9UkrZnCZ6pZSyOU30Sillc/8fxKqnUvasfVcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "361d99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction(video, model, model_state, N, H, W):\n",
    "    # Load the model state\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    outputs = []\n",
    "    # Iterate over the video in steps of N frames\n",
    "    num_frames = len(video)\n",
    "    for i in range(0, num_frames - N + 1):\n",
    "        # Extract the stack of frames\n",
    "        frame_stack = video[i:i + N]  # Shape: (N, H, W, C)\n",
    "        # Convert to numpy array and add batch dimension\n",
    "        frame_stack = np.array(frame_stack)  # Shape: (N, H, W, C)\n",
    "        # Rearrange to match the model's expected input shape: (batch, N, C, H, W)\n",
    "        # In our case, the frame_stack shape should be (1, N, 3, H, W) where 3 is the number of channels (RGB)\n",
    "        frame_stack = np.transpose(frame_stack, (0, 3, 1, 2))  # Shape: (N, C, H, W)\n",
    "        frame_stack = np.expand_dims(frame_stack, axis=0)  # Shape: (1, N, C, H, W)\n",
    "        # Convert to a PyTorch tensor\n",
    "        frame_stack = torch.tensor(frame_stack, dtype=torch.float32)\n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            output = model(frame_stack)\n",
    "        # Append the output to the list\n",
    "        outputs.append(int(round(output.item())))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0571b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = open_vid(\"AI Gen/movie.mp4\")\n",
    "Video = get_frames(cap)\n",
    "VI = torch.from_numpy(Video[5]).permute(2,0,1).unsqueeze(0)\n",
    "VI = AddOneInc1(VI)\n",
    "Video[5] = cv2.cvtColor(VI.permute(1, 2, 0).numpy(),cv2.COLOR_BGR2RGB)\n",
    "display_frame(Video[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "922b12a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video = [cv2.resize(i,(100,100)) for i in Video[:15]]\n",
    "Preds = process_video(Video,Model,State,3,100,100)\n",
    "Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "17afa431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction(Vid,Model,State,N,Size):\n",
    "    model = BinIncModel(N,Size(0),Size(1))\n",
    "    P = []\n",
    "    V = [torch.tensor(cv2.resize(i,(320,320),interpolation=cv2.INTER_AREA),\n",
    "                              dtype=torch.float32).permute(2,0,1).unsqueeze(0)/255.0 for i in Vid]\n",
    "    \n",
    "    N = len(kt)//2\n",
    "    for f in range(len(V) - 2 * N):\n",
    "        first, current, last = f, f + N // 2, f + N\n",
    "        Pred = ObjFun(V[first:last], V[current], k, kt, kb)\n",
    "        P.append(cv2.resize((Pred[0] * 255).squeeze(0).permute(1, 2, 0).detach().cpu().numpy().astype(np.uint8),\n",
    "                                           (Vid[f].shape[1], Vid[f].shape[0]), interpolation=cv2.INTER_AREA))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVid = Prediction(Video,Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThroughFrames(Video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12865008",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThroughFrames(PVid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add detail error, MSE of full image only minimizes general pixel distribution\n",
    "##Add more training examples\n",
    "##Add N previous and N post current inconsistence image\n",
    "##Add optical flow, frequencies or other features for temporal consistency\n",
    "##Different kernel sizes\n",
    "##Add Gaisian Noise\n",
    "##Reconstruct image with kernel middle between encoder and decofer\n",
    "##Use data with less loss value, selection\n",
    "##How to combine data with less error and with more error?\n",
    "##Localize area and correct error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6aa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deformaciones\n",
    "#parches de colores, OF ventana\n",
    "#self attention mechanism\n",
    "#image processing transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e2da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
