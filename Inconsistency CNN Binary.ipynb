{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022a9c34",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ac1094/Vid-Processing/blob/main/Inconsistency_Detector1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5d874",
   "metadata": {},
   "source": [
    "# Binary Inconsistency Detector DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fece1d16",
   "metadata": {
    "id": "a48ed841"
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Functions import *\n",
    "from ConsistencyIndexes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e006a9f",
   "metadata": {},
   "source": [
    "## Resize Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5caf623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = 100,200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f394f",
   "metadata": {},
   "source": [
    "## CNN for 9 channel input and single value output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "56f04498",
   "metadata": {
    "id": "6fcb9d30"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as Fun\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=9, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 12 * 25, 256)  # Assuming input size (9, 100, 200) and 3 pooling layers\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(Fun.sigmoid(self.conv1(x)))\n",
    "        x = self.pool(Fun.sigmoid(self.conv2(x)))\n",
    "        x = self.pool(Fun.sigmoid(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 12 * 25)  # Flattening\n",
    "        x = Fun.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Define the Training Function\n",
    "def train_cnn(model, train_inputs, train_targets, epochs=10, batch_size=16, lr=0.001):\n",
    "    # Convert inputs and targets to tensors\n",
    "    inputs = torch.stack(train_inputs)\n",
    "    targets = torch.tensor(train_targets).float().view(-1, 1)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = TensorDataset(inputs, targets)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x_batch, y_batch) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "    print(\"Training complete\")\n",
    "\n",
    "# Define the Prediction Function\n",
    "def predict_cnn(model, test_inputs):\n",
    "    model.eval()\n",
    "    inputs = torch.stack(test_inputs)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    predictions = (outputs > 0.5).int()  # Convert to binary output\n",
    "    return predictions.view(-1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71626294",
   "metadata": {},
   "source": [
    "## Read the images, Add Inconsistencies and create moved frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e25ecefa",
   "metadata": {
    "id": "f68c1bc4"
   },
   "outputs": [],
   "source": [
    "Frames = read_images(\"saved_frames\")\n",
    "F,_ = AddInc(Frames,3)\n",
    "F = [cv2.resize(f,(w,h),interpolation=cv2.INTER_AREA) for f in F]\n",
    "F0 = np.asarray(F[:-2],dtype=np.uint8)\n",
    "F2 = np.asarray(F[2:],dtype=np.uint8)\n",
    "F = np.asarray(F[1:-1],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c78bee",
   "metadata": {},
   "source": [
    "## Create input of past, present and future frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7fc15174",
   "metadata": {
    "id": "4781bcc8"
   },
   "outputs": [],
   "source": [
    "Input = [np.asarray((F0[i][:,:,0],F0[i][:,:,1],F0[i][:,:,2],\n",
    "                    F[i][:,:,0],F[i][:,:,1],F[i][:,:,2],\n",
    "                    F2[i][:,:,0],F2[i][:,:,1],F2[i][:,:,2],\n",
    "                     )) for i in range(len(F))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c2fd6910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b7b05c3",
    "outputId": "c3113465-9644-4040-9631-fe4c03fada05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 100, 200)\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "print(Input[0].shape)\n",
    "print(len(Input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb378970",
   "metadata": {},
   "source": [
    "## Create list of torch arrays as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f898631a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf8a9813",
    "outputId": "3b55daf3-386d-4d1f-dc3c-eac72d6da673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 torch.Size([9, 100, 200])\n"
     ]
    }
   ],
   "source": [
    "input_arrays = [torch.tensor(i,dtype=torch.float32) for i in Input[:40]]\n",
    "print(len(input_arrays),input_arrays[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c7381",
   "metadata": {},
   "source": [
    "## Create list of target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0e797a4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a1aa97f",
    "outputId": "468f8980-8bc1-4c91-d5bb-674256cfa4a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "target_arrays = [1 if i%3==0 and i!=0 else 0 for i in range(len(Input[:40]))]\n",
    "print(target_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f3984",
   "metadata": {},
   "source": [
    "## Instance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "58bf2620",
   "metadata": {
    "id": "a1e3367e"
   },
   "outputs": [],
   "source": [
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ce47b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "554860c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7a858cf",
    "outputId": "5e67054c-125a-4782-9cd2-4aaac482fb18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.124044\n",
      "Epoch 2/10, Loss: 0.529941\n",
      "Epoch 3/10, Loss: 1.904245\n",
      "Epoch 4/10, Loss: 1.732984\n",
      "Epoch 5/10, Loss: 0.803431\n",
      "Epoch 6/10, Loss: 0.399431\n",
      "Epoch 7/10, Loss: 0.669811\n",
      "Epoch 8/10, Loss: 1.110191\n",
      "Epoch 9/10, Loss: 0.383389\n",
      "Epoch 10/10, Loss: 0.566384\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "train_cnn(model, input_arrays, target_arrays, epochs=10, batch_size=16, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9705cf0",
   "metadata": {},
   "source": [
    "## Predict Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "218b79f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4bd6eeb",
    "outputId": "9dc266e6-baaa-4d6c-e6e6-719c0a989a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predicted_output = predict_cnn(model,input_arrays)\n",
    "print(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48216069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
