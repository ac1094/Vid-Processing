{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366dc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "964d075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attention = self.conv(x)  # Shape: (batch_size, 1, 300, 300)\n",
    "        attention = torch.sigmoid(attention)\n",
    "        return x * attention  # Element-wise multiplication\n",
    "\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=17, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.attention = AttentionLayer(in_channels=32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))  # Shape: (batch_size, 16, 300, 300)\n",
    "        x = torch.relu(self.conv2(x))  # Shape: (batch_size, 32, 300, 300)\n",
    "        x = self.attention(x)          # Shape: (batch_size, 32, 300, 300)\n",
    "        x = torch.relu(self.conv3(x))  # Shape: (batch_size, 64, 300, 300)\n",
    "        x = torch.sigmoid(self.conv4(x))  # Shape: (batch_size, 1, 300, 300)\n",
    "        return x\n",
    "\n",
    "def train_model(model, input_arrays, target_arrays, epochs=10, batch_size=32, learning_rate=0.001):\n",
    "    # Convert input and target arrays to tensors and stack them\n",
    "    inputs = torch.stack([torch.tensor(arr, dtype=torch.float32) for arr in input_arrays])\n",
    "    targets = torch.stack([torch.tensor(arr, dtype=torch.float32) for arr in target_arrays])\n",
    "    \n",
    "    # Create a DataLoader for batching\n",
    "    dataset = TensorDataset(inputs, targets)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        for i, (batch_inputs, batch_targets) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Print loss for the epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "\n",
    "def predict(model, input_array):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        input_tensor = torch.tensor(input_array, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "        output = model(input_tensor)\n",
    "    return output.squeeze(0).numpy()  # Remove batch dimension and convert to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7add3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = read_images(\"saved_frames\")\n",
    "F[3] = F[3][:,:,:3]\n",
    "F[6] = F[6][:,:,:3]\n",
    "F[9] = F[9][:,:,:3]\n",
    "F[14] = F[14][:,:,:3]\n",
    "F = F[:15]\n",
    "D = np.asarray([abs(F[i]-F[i+1]) for i in range(len(F)-1)],dtype=np.uint8)\n",
    "D0 = np.asarray(D[:-1],dtype=np.uint8)\n",
    "D2 = np.asarray(D[1:],dtype=np.uint8)\n",
    "down = 0\n",
    "up = 255\n",
    "B = np.asarray([abs(cv2.Canny(cv2.cvtColor(F[i],cv2.COLOR_BGR2GRAY),down,up)-cv2.Canny(cv2.cvtColor(F[i+1],cv2.COLOR_BGR2GRAY),down,up)) for i in range(len(F)-1)],dtype=np.uint8)\n",
    "B0 = np.asarray(B[:-1],dtype=np.uint8)\n",
    "B2 = np.asarray(B[1:],dtype=np.uint8)\n",
    "F0 = np.asarray(F[:-2],dtype=np.uint8)\n",
    "F2 = np.asarray(F[2:],dtype=np.uint8) \n",
    "F = np.asarray(F[1:-1],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abe47afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = [np.asarray((F0[i][:,:,0],F0[i][:,:,1],F0[i][:,:,2],\n",
    "                    F[i][:,:,0],F[i][:,:,1],F[i][:,:,2],\n",
    "                    F2[i][:,:,0],F2[i][:,:,1],F2[i][:,:,2],\n",
    "                    D0[i][:,:,0],D0[i][:,:,1],D0[i][:,:,2],\n",
    "                    D2[i][:,:,0],D2[i][:,:,1],D2[i][:,:,2],\n",
    "                    B0[i],\n",
    "                    B2[i])) for i in range(len(F))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0bc7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 320, 640)\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(Input[0].shape)\n",
    "print(len(Input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "018ff8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_frame(Input[1][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "443941fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arrays = [torch.tensor(i) for i in Input[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c9bbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_arrays = [torch.zeros(320,640) for _ in range(len(Input)-1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66583897",
   "metadata": {},
   "outputs": [],
   "source": [
    "Masks = read_images(\"Masks\")\n",
    "Masks = [cv2.cvtColor(m[:,:,:3],cv2.COLOR_RGB2GRAY) for m in Masks]\n",
    "target_arrays[3] = Masks[0]\n",
    "target_arrays[6] = Masks[1]\n",
    "target_arrays[9] = Masks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe5a7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfang\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Wolfang\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 588.0404\n",
      "Epoch [2/20], Loss: 1143.2579\n",
      "Epoch [3/20], Loss: 512.0490\n",
      "Epoch [4/20], Loss: 574.0169\n",
      "Epoch [5/20], Loss: 512.0231\n",
      "Epoch [6/20], Loss: 512.0068\n",
      "Epoch [7/20], Loss: 511.9993\n",
      "Epoch [8/20], Loss: 1217.5575\n",
      "Epoch [9/20], Loss: 1143.0240\n",
      "Epoch [10/20], Loss: 511.9527\n",
      "Epoch [11/20], Loss: 511.9406\n",
      "Epoch [12/20], Loss: 1217.3653\n",
      "Epoch [13/20], Loss: 511.9080\n",
      "Epoch [14/20], Loss: 511.8850\n",
      "Epoch [15/20], Loss: 648.2791\n",
      "Epoch [16/20], Loss: 511.8465\n",
      "Epoch [17/20], Loss: 1142.6051\n",
      "Epoch [18/20], Loss: 586.2489\n",
      "Epoch [19/20], Loss: 586.2169\n",
      "Epoch [20/20], Loss: 511.7410\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "model = ANNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6914b2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfang\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Wolfang\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 638.2362\n",
      "Epoch [2/20], Loss: 638.2362\n",
      "Epoch [3/20], Loss: 638.2361\n",
      "Epoch [4/20], Loss: 638.2361\n",
      "Epoch [5/20], Loss: 638.2361\n",
      "Epoch [6/20], Loss: 638.2361\n",
      "Epoch [7/20], Loss: 638.2362\n",
      "Epoch [8/20], Loss: 638.2362\n",
      "Epoch [9/20], Loss: 638.2361\n",
      "Epoch [10/20], Loss: 638.2362\n",
      "Epoch [11/20], Loss: 638.2361\n",
      "Epoch [12/20], Loss: 638.2361\n",
      "Epoch [13/20], Loss: 638.2361\n",
      "Epoch [14/20], Loss: 638.2361\n",
      "Epoch [15/20], Loss: 638.2361\n",
      "Epoch [16/20], Loss: 638.2361\n",
      "Epoch [17/20], Loss: 638.2361\n",
      "Epoch [18/20], Loss: 638.2362\n",
      "Epoch [19/20], Loss: 638.2362\n",
      "Epoch [20/20], Loss: 638.2362\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "train_model(model, input_arrays, target_arrays, epochs=20, batch_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbc9b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfang\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "test_input_array = torch.tensor(Input[-1])  # Simulate a single input array\n",
    "predicted_output = predict(model, test_input_array)\n",
    "print(predicted_output.shape)  # Expected output shape: (300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcb4d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_frame(Input[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1da21de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_frame(predicted_output.reshape(320,640).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f702447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
